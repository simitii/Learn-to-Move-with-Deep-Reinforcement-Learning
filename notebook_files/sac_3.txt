2018-05-15 20:28:47.715837 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #0 | Skipping eval for now.
2018-05-15 20:28:47.716035 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #0 | Epoch Duration: 39.1291184425354
2018-05-15 20:28:47.716106 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #0 | Started Training: True
2018-05-15 20:29:23.179024 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #1 | Epoch Duration: 35.46282386779785
2018-05-15 20:29:23.179247 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #1 | Started Training: True
2018-05-15 20:29:57.809656 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #2 | Epoch Duration: 34.630260705947876
2018-05-15 20:29:57.809877 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #2 | Started Training: True
2018-05-15 20:30:32.589342 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #3 | Epoch Duration: 34.7793083190918
2018-05-15 20:30:32.589576 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #3 | Started Training: True
2018-05-15 20:31:06.938547 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #4 | Epoch Duration: 34.34880876541138
2018-05-15 20:31:06.941311 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #4 | Started Training: True
2018-05-15 20:31:41.781288 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #5 | Epoch Duration: 34.83976912498474
2018-05-15 20:31:41.781557 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #5 | Started Training: True
2018-05-15 20:32:15.854665 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #6 | Epoch Duration: 34.072940826416016
2018-05-15 20:32:15.858419 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #6 | Started Training: True
2018-05-15 20:32:50.539368 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #7 | Epoch Duration: 34.68074417114258
2018-05-15 20:32:50.539586 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #7 | Started Training: True
2018-05-15 20:33:25.751034 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #8 | Epoch Duration: 35.21130132675171
2018-05-15 20:33:25.751239 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #8 | Started Training: True
2018-05-15 20:34:00.668088 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #9 | Epoch Duration: 34.91669273376465
2018-05-15 20:34:00.668385 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #9 | Started Training: True
2018-05-15 20:34:38.014624 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #10 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          0.000184816
VF Loss                        144.004
Policy Loss                    144.116
Q Predictions Mean              -0.0552731
Q Predictions Std                0.00504291
Q Predictions Max               -0.00105953
Q Predictions Min               -0.0583316
V Predictions Mean              -0.0455343
V Predictions Std                0.00449915
V Predictions Max                0.000126086
V Predictions Min               -0.0483718
Log Pis Mean                   -11.9789
Log Pis Std                      0.857154
Log Pis Max                     -9.91832
Log Pis Min                    -14.1374
Policy mu Mean                  -0.00100579
Policy mu Std                    0.0100314
Policy mu Max                    0.0258197
Policy mu Min                   -0.0160229
Policy log std Mean              0.00572105
Policy log std Std               0.0113939
Policy log std Max               0.0273259
Policy log std Min              -0.0106658
Test Rewards Mean               -0.00238447
Test Rewards Std                 0.00386045
Test Rewards Max                 0.00540348
Test Rewards Min                -0.0127279
Test Returns Mean               -0.673612
Test Returns Std                 0.019431
Test Returns Max                -0.64756
Test Returns Min                -0.695227
Test Actions Mean               -0.00299294
Test Actions Std                 0.0536734
Test Actions Max                 0.114159
Test Actions Min                -0.112489
Num Paths                        7
Exploration Rewards Mean        -0.00659136
Exploration Rewards Std          0.00763576
Exploration Rewards Max          0.00658811
Exploration Rewards Min         -0.0210625
Exploration Returns Mean        -0.79473
Exploration Returns Std          0.00628639
Exploration Returns Max         -0.785443
Exploration Returns Min         -0.805047
Exploration Actions Mean        -0.000383688
Exploration Actions Std          0.586534
Exploration Actions Max          0.998318
Exploration Actions Min         -0.997746
AverageReturn                   -0.673612
Number of train steps total  10844
Number of env steps total    11000
Number of rollouts total        83
Train Time (s)                  20.0627
(Previous) Eval Time (s)         2.85e-06
Sample Time (s)                 14.6346
Epoch Time (s)                  34.6973
Total Train Time (s)           639.962
Epoch                           10
---------------------------  ---------------
2018-05-15 20:38:48.773825 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #10 | Epoch Duration: 288.1052713394165
2018-05-15 20:38:48.773931 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #10 | Started Training: True
2018-05-15 20:39:24.427085 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #11 | Epoch Duration: 35.65305042266846
2018-05-15 20:39:24.427362 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #11 | Started Training: True
2018-05-15 20:39:58.830183 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #12 | Epoch Duration: 34.402658224105835
2018-05-15 20:39:58.830468 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #12 | Started Training: True
2018-05-15 20:40:33.025655 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #13 | Epoch Duration: 34.195051431655884
2018-05-15 20:40:33.026591 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #13 | Started Training: True
2018-05-15 20:41:08.413544 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #14 | Epoch Duration: 35.38676881790161
2018-05-15 20:41:08.413751 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #14 | Started Training: True
2018-05-15 20:41:43.111310 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #15 | Epoch Duration: 34.69740009307861
2018-05-15 20:41:43.111534 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #15 | Started Training: True
2018-05-15 20:42:17.134540 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #16 | Epoch Duration: 34.02288293838501
2018-05-15 20:42:17.134763 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #16 | Started Training: True
2018-05-15 20:43:00.314718 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #17 | Epoch Duration: 43.17979383468628
2018-05-15 20:43:00.314970 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #17 | Started Training: True
2018-05-15 20:43:45.004002 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #18 | Epoch Duration: 44.68889904022217
2018-05-15 20:43:45.004246 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #18 | Started Training: True
2018-05-15 20:44:25.109837 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #19 | Epoch Duration: 40.105467319488525
2018-05-15 20:44:25.113241 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #19 | Started Training: True
2018-05-15 20:45:03.071110 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #20 | Collecting samples for evaluation
---------------------------  --------------
QF Loss                         31.3351
VF Loss                          2.73546
Policy Loss                     -8.23318
Q Predictions Mean             104.986
Q Predictions Std                9.67848
Q Predictions Max              112.78
Q Predictions Min               51.3359
V Predictions Mean             118.113
V Predictions Std                9.09332
V Predictions Max              127.136
V Predictions Min               76.3229
Log Pis Mean                   -12.1514
Log Pis Std                      0.750627
Log Pis Max                     -8.15448
Log Pis Min                    -13.8937
Policy mu Mean                   0.00223725
Policy mu Std                    0.0963938
Policy mu Max                    1.11823
Policy mu Min                   -0.852771
Policy log std Mean             -0.144573
Policy log std Std               0.0207317
Policy log std Max              -0.00408744
Policy log std Min              -0.3972
Test Rewards Mean               -0.00287329
Test Rewards Std                 0.00388947
Test Rewards Max                 0.00447639
Test Rewards Min                -0.0122293
Test Returns Mean               -0.649939
Test Returns Std                 0.00469408
Test Returns Max                -0.6423
Test Returns Min                -0.656725
Test Actions Mean               -0.0220047
Test Actions Std                 0.0738604
Test Actions Max                 0.0591511
Test Actions Min                -0.224447
Num Paths                        9
Exploration Rewards Mean        -0.00660072
Exploration Rewards Std          0.00759316
Exploration Rewards Max          0.00595009
Exploration Rewards Min         -0.0214302
Exploration Returns Mean        -0.793553
Exploration Returns Std          0.00816448
Exploration Returns Max         -0.780593
Exploration Returns Min         -0.803473
Exploration Actions Mean        -0.00753921
Exploration Actions Std          0.588728
Exploration Actions Max          0.996184
Exploration Actions Min         -0.997952
AverageReturn                   -0.649939
Number of train steps total  20844
Number of env steps total    21000
Number of rollouts total       168
Train Time (s)                  19.7599
(Previous) Eval Time (s)         2.26e-06
Sample Time (s)                 15.305
Epoch Time (s)                  35.0649
Total Train Time (s)          1267.41
Epoch                           20
---------------------------  --------------
2018-05-15 20:49:16.428665 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #20 | Epoch Duration: 291.3152389526367
2018-05-15 20:49:16.428775 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #20 | Started Training: True
2018-05-15 20:49:52.598187 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #21 | Epoch Duration: 36.169312953948975
2018-05-15 20:49:52.598438 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #21 | Started Training: True
2018-05-15 20:50:29.993951 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #22 | Epoch Duration: 37.395384788513184
2018-05-15 20:50:29.994164 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #22 | Started Training: True
2018-05-15 20:52:41.481377 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #23 | Epoch Duration: 131.48709678649902
2018-05-15 20:52:41.481625 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #23 | Started Training: True
2018-05-15 20:55:33.639603 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #24 | Epoch Duration: 172.15785670280457
2018-05-15 20:55:33.639846 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #24 | Started Training: True
2018-05-15 20:58:29.588788 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #25 | Epoch Duration: 175.94881010055542
2018-05-15 20:58:29.589035 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #25 | Started Training: True
2018-05-15 21:01:26.922133 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #26 | Epoch Duration: 177.33294820785522
2018-05-15 21:01:26.922395 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #26 | Started Training: True
2018-05-15 21:04:21.460972 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #27 | Epoch Duration: 174.53842329978943
2018-05-15 21:04:21.461217 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #27 | Started Training: True
2018-05-15 21:07:15.038507 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #28 | Epoch Duration: 173.5771565437317
2018-05-15 21:07:15.038752 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #28 | Started Training: True
2018-05-15 21:10:11.889306 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #29 | Epoch Duration: 176.85042572021484
2018-05-15 21:10:11.889511 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #29 | Started Training: True
2018-05-15 21:10:50.377167 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #30 | Collecting samples for evaluation
---------------------------  --------------
QF Loss                          3.76908
VF Loss                         17.4727
Policy Loss                     30.76
Q Predictions Mean             199.61
Q Predictions Std               38.002
Q Predictions Max              239.87
Q Predictions Min                9.94101
V Predictions Mean             209.6
V Predictions Std               37.5498
V Predictions Max              252.47
V Predictions Min               53.933
Log Pis Mean                   -12.1335
Log Pis Std                      0.747238
Log Pis Max                     -6.42484
Log Pis Min                    -13.6614
Policy mu Mean                  -0.017253
Policy mu Std                    0.113621
Policy mu Max                    0.936876
Policy mu Min                   -0.790054
Policy log std Mean             -0.14094
Policy log std Std               0.0259334
Policy log std Max               0.0809386
Policy log std Min              -0.430709
Test Rewards Mean               -0.00428899
Test Rewards Std                 0.00438289
Test Rewards Max                 0.00314012
Test Rewards Min                -0.0106132
Test Returns Mean               -0.635996
Test Returns Std                 0.00284255
Test Returns Max                -0.631721
Test Returns Min                -0.639778
Test Actions Mean               -0.040229
Test Actions Std                 0.115684
Test Actions Max                 0.104514
Test Actions Min                -0.368379
Num Paths                        6
Exploration Rewards Mean        -0.00660189
Exploration Rewards Std          0.00752426
Exploration Rewards Max          0.00461919
Exploration Rewards Min         -0.0212183
Exploration Returns Mean        -0.787826
Exploration Returns Std          0.0122845
Exploration Returns Max         -0.769076
Exploration Returns Min         -0.80449
Exploration Actions Mean        -0.0214791
Exploration Actions Std          0.588332
Exploration Actions Max          0.997871
Exploration Actions Min         -0.99803
AverageReturn                   -0.635996
Number of train steps total  30844
Number of env steps total    31000
Number of rollouts total       250
Train Time (s)                  20.2223
(Previous) Eval Time (s)         2.156e-06
Sample Time (s)                 15.2384
Epoch Time (s)                  35.4607
Total Train Time (s)          2820.45
Epoch                           30
---------------------------  --------------
2018-05-15 21:15:09.705244 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #30 | Epoch Duration: 297.81562781333923
2018-05-15 21:15:09.705351 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #30 | Started Training: True
2018-05-15 21:15:44.654981 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #31 | Epoch Duration: 34.94953536987305
2018-05-15 21:15:44.655175 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #31 | Started Training: True
2018-05-15 21:16:19.512009 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #32 | Epoch Duration: 34.85672187805176
2018-05-15 21:16:19.514500 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #32 | Started Training: True
2018-05-15 21:16:54.100088 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #33 | Epoch Duration: 34.585367918014526
2018-05-15 21:16:54.100300 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #33 | Started Training: True
2018-05-15 21:17:28.469586 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #34 | Epoch Duration: 34.36917328834534
2018-05-15 21:17:28.469794 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #34 | Started Training: True
2018-05-15 21:18:03.876726 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #35 | Epoch Duration: 35.40681576728821
2018-05-15 21:18:03.876928 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #35 | Started Training: True
2018-05-15 21:18:38.810231 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #36 | Epoch Duration: 34.9331841468811
2018-05-15 21:18:38.810520 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #36 | Started Training: True
2018-05-15 21:19:13.134977 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #37 | Epoch Duration: 34.324273347854614
2018-05-15 21:19:13.135946 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #37 | Started Training: True
2018-05-15 21:19:46.663101 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #38 | Epoch Duration: 33.52693819999695
2018-05-15 21:19:46.663371 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #38 | Started Training: True
2018-05-15 21:20:21.796220 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #39 | Epoch Duration: 35.13267993927002
2018-05-15 21:20:21.796487 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #39 | Started Training: True
2018-05-15 21:20:59.748573 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #40 | Collecting samples for evaluation
---------------------------  --------------
QF Loss                          4.43611
VF Loss                          3.93596
Policy Loss                     15.1764
Q Predictions Mean             285.506
Q Predictions Std               69.4416
Q Predictions Max              340.146
Q Predictions Min                5.5861
V Predictions Mean             296.549
V Predictions Std               69.4468
V Predictions Max              351.772
V Predictions Min               20.5471
Log Pis Mean                   -12.0347
Log Pis Std                      0.715038
Log Pis Max                     -9.91863
Log Pis Min                    -13.9641
Policy mu Mean                  -0.0396855
Policy mu Std                    0.116903
Policy mu Max                    0.412221
Policy mu Min                   -0.466995
Policy log std Mean             -0.137063
Policy log std Std               0.0129344
Policy log std Max               0.00703733
Policy log std Min              -0.217381
Test Rewards Mean               -0.00556437
Test Rewards Std                 0.0048694
Test Rewards Max                 0.00120582
Test Rewards Min                -0.0150262
Test Returns Mean               -0.654741
Test Returns Std                 0.00583957
Test Returns Max                -0.646948
Test Returns Min                -0.663575
Test Actions Mean               -0.0346241
Test Actions Std                 0.120686
Test Actions Max                 0.131917
Test Actions Min                -0.279726
Num Paths                        7
Exploration Rewards Mean        -0.00669305
Exploration Rewards Std          0.00749213
Exploration Rewards Max          0.00441057
Exploration Rewards Min         -0.0211744
Exploration Returns Mean        -0.78978
Exploration Returns Std          0.00887055
Exploration Returns Max         -0.776825
Exploration Returns Min         -0.805504
Exploration Actions Mean        -0.0274522
Exploration Actions Std          0.596232
Exploration Actions Max          0.998809
Exploration Actions Min         -0.99723
AverageReturn                   -0.654741
Number of train steps total  40844
Number of env steps total    41000
Number of rollouts total       334
Train Time (s)                  20.3517
(Previous) Eval Time (s)         3.008e-06
Sample Time (s)                 14.3488
Epoch Time (s)                  34.7005
Total Train Time (s)          3450.22
Epoch                           40
---------------------------  --------------
2018-05-15 21:25:39.673342 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #40 | Epoch Duration: 317.87670159339905
2018-05-15 21:25:39.673449 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #40 | Started Training: True
2018-05-15 21:26:14.907929 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #41 | Epoch Duration: 35.23438787460327
2018-05-15 21:26:14.908135 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #41 | Started Training: True
2018-05-15 21:26:49.747194 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #42 | Epoch Duration: 34.83894109725952
2018-05-15 21:26:49.747465 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #42 | Started Training: True
2018-05-15 21:27:24.354047 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #43 | Epoch Duration: 34.606425523757935
2018-05-15 21:27:24.354256 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #43 | Started Training: True
2018-05-15 21:27:59.737575 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #44 | Epoch Duration: 35.38318228721619
2018-05-15 21:27:59.737781 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #44 | Started Training: True
2018-05-15 21:28:33.744632 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #45 | Epoch Duration: 34.00673174858093
2018-05-15 21:28:33.746894 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #45 | Started Training: True
2018-05-15 21:29:08.086580 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #46 | Epoch Duration: 34.33951210975647
2018-05-15 21:29:08.090163 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #46 | Started Training: True
2018-05-15 21:29:42.817486 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #47 | Epoch Duration: 34.72712540626526
2018-05-15 21:29:42.818427 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #47 | Started Training: True
2018-05-15 21:30:17.294962 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #48 | Epoch Duration: 34.47634816169739
2018-05-15 21:30:17.295180 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #48 | Started Training: True
2018-05-15 21:30:52.434169 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #49 | Epoch Duration: 35.13882327079773
2018-05-15 21:30:52.437268 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #49 | Started Training: True
2018-05-15 21:31:30.418823 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #50 | Collecting samples for evaluation
---------------------------  --------------
QF Loss                          7.39039
VF Loss                          3.22451
Policy Loss                      6.75471
Q Predictions Mean             343.253
Q Predictions Std              103.651
Q Predictions Max              438.35
Q Predictions Min               -1.90269
V Predictions Mean             355.123
V Predictions Std              103.653
V Predictions Max              450.972
V Predictions Min               12.7159
Log Pis Mean                   -12.2293
Log Pis Std                      0.823592
Log Pis Max                     -9.75174
Log Pis Min                    -14.5178
Policy mu Mean                  -0.0333245
Policy mu Std                    0.113057
Policy mu Max                    0.215547
Policy mu Min                   -0.299333
Policy log std Mean             -0.13021
Policy log std Std               0.0160134
Policy log std Max              -0.0652432
Policy log std Min              -0.167945
Test Rewards Mean               -0.00534841
Test Rewards Std                 0.00492049
Test Rewards Max                 0.00256841
Test Rewards Min                -0.0129821
Test Returns Mean               -0.618632
Test Returns Std                 0.00338529
Test Returns Max                -0.612965
Test Returns Min                -0.622557
Test Actions Mean               -0.0478578
Test Actions Std                 0.146393
Test Actions Max                 0.157511
Test Actions Min                -0.388157
Num Paths                        8
Exploration Rewards Mean        -0.00676527
Exploration Rewards Std          0.00743809
Exploration Rewards Max          0.00477017
Exploration Rewards Min         -0.021221
Exploration Returns Mean        -0.795765
Exploration Returns Std          0.00795614
Exploration Returns Max         -0.786386
Exploration Returns Min         -0.806588
Exploration Actions Mean        -0.0346459
Exploration Actions Std          0.588934
Exploration Actions Max          0.998848
Exploration Actions Min         -0.997594
AverageReturn                   -0.618632
Number of train steps total  50844
Number of env steps total    51000
Number of rollouts total       419
Train Time (s)                  19.9912
(Previous) Eval Time (s)         2.327e-06
Sample Time (s)                 14.5653
Epoch Time (s)                  34.5565
Total Train Time (s)          4099.32
Epoch                           50
---------------------------  --------------
2018-05-15 21:36:28.980303 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #50 | Epoch Duration: 336.5428776741028
2018-05-15 21:36:28.980411 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #50 | Started Training: True
2018-05-15 21:37:03.594879 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #51 | Epoch Duration: 34.61436700820923
2018-05-15 21:37:03.595159 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #51 | Started Training: True
2018-05-15 21:37:37.976629 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #52 | Epoch Duration: 34.381303787231445
2018-05-15 21:37:37.976905 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #52 | Started Training: True
2018-05-15 21:38:12.449806 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #53 | Epoch Duration: 34.472734212875366
2018-05-15 21:38:12.450018 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #53 | Started Training: True
2018-05-15 21:38:47.182938 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #54 | Epoch Duration: 34.73275804519653
2018-05-15 21:38:47.183141 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #54 | Started Training: True
2018-05-15 21:39:21.854926 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #55 | Epoch Duration: 34.67166757583618
2018-05-15 21:39:21.855202 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #55 | Started Training: True
2018-05-15 21:39:56.210139 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #56 | Epoch Duration: 34.3547785282135
2018-05-15 21:39:56.210348 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #56 | Started Training: True
2018-05-15 21:40:30.977324 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #57 | Epoch Duration: 34.76683044433594
2018-05-15 21:40:30.977557 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #57 | Started Training: True
2018-05-15 21:41:05.236771 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #58 | Epoch Duration: 34.25909423828125
2018-05-15 21:41:05.236995 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #58 | Started Training: True
2018-05-15 21:41:39.801748 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #59 | Epoch Duration: 34.564634561538696
2018-05-15 21:41:39.801959 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #59 | Started Training: True
2018-05-15 21:42:18.594190 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #60 | Collecting samples for evaluation
---------------------------  --------------
QF Loss                          5.95957
VF Loss                          4.89391
Policy Loss                     18.7944
Q Predictions Mean             393.042
Q Predictions Std              127.186
Q Predictions Max              504.627
Q Predictions Min                2.25237
V Predictions Mean             403.814
V Predictions Std              127.347
V Predictions Max              516.387
V Predictions Min               10.6873
Log Pis Mean                   -12.0349
Log Pis Std                      1.04228
Log Pis Max                     -9.66616
Log Pis Min                    -16.2091
Policy mu Mean                  -0.0455917
Policy mu Std                    0.13846
Policy mu Max                    0.374236
Policy mu Min                   -0.393386
Policy log std Mean             -0.139576
Policy log std Std               0.0159342
Policy log std Max              -0.0378048
Policy log std Min              -0.177152
Test Rewards Mean               -0.00491727
Test Rewards Std                 0.00488026
Test Rewards Max                 0.00291829
Test Rewards Min                -0.0126441
Test Returns Mean               -0.623264
Test Returns Std                 0.00279217
Test Returns Max                -0.618151
Test Returns Min                -0.628295
Test Actions Mean               -0.0391892
Test Actions Std                 0.114083
Test Actions Max                 0.131296
Test Actions Min                -0.31629
Num Paths                        6
Exploration Rewards Mean        -0.00654969
Exploration Rewards Std          0.0074685
Exploration Rewards Max          0.00560266
Exploration Rewards Min         -0.0214929
Exploration Returns Mean        -0.792512
Exploration Returns Std          0.00798788
Exploration Returns Max         -0.779219
Exploration Returns Min         -0.802539
Exploration Actions Mean        -0.0337541
Exploration Actions Std          0.591161
Exploration Actions Max          0.998549
Exploration Actions Min         -0.998903
AverageReturn                   -0.623264
Number of train steps total  60844
Number of env steps total    61000
Number of rollouts total       504
Train Time (s)                  20.0316
(Previous) Eval Time (s)         1.991e-06
Sample Time (s)                 15.0675
Epoch Time (s)                  35.0991
Total Train Time (s)          4724.99
Epoch                           60
---------------------------  --------------
2018-05-15 21:46:54.847569 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #60 | Epoch Duration: 315.04547238349915
2018-05-15 21:46:54.847676 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #60 | Started Training: True
2018-05-15 21:47:29.161484 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #61 | Epoch Duration: 34.31370997428894
2018-05-15 21:47:29.161732 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #61 | Started Training: True
2018-05-15 21:48:03.482597 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #62 | Epoch Duration: 34.32072615623474
2018-05-15 21:48:03.486815 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #62 | Started Training: True
2018-05-15 21:48:38.222853 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #63 | Epoch Duration: 34.73579692840576
2018-05-15 21:48:38.223061 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #63 | Started Training: True
2018-05-15 21:49:12.985972 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #64 | Epoch Duration: 34.76279306411743
2018-05-15 21:49:12.986222 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #64 | Started Training: True
2018-05-15 21:49:46.945153 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #65 | Epoch Duration: 33.95879817008972
2018-05-15 21:49:46.945403 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #65 | Started Training: True
2018-05-15 21:50:21.402371 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #66 | Epoch Duration: 34.45683526992798
2018-05-15 21:50:21.402598 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #66 | Started Training: True
2018-05-15 21:50:55.530622 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #67 | Epoch Duration: 34.127849102020264
2018-05-15 21:50:55.533868 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #67 | Started Training: True
2018-05-15 21:51:29.819041 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #68 | Epoch Duration: 34.284961462020874
2018-05-15 21:51:29.820248 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #68 | Started Training: True
2018-05-15 21:52:03.622321 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #69 | Epoch Duration: 33.801889181137085
2018-05-15 21:52:03.622557 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #69 | Started Training: True
2018-05-15 21:52:42.880082 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #70 | Collecting samples for evaluation
---------------------------  --------------
QF Loss                          4.84885
VF Loss                          1.89118
Policy Loss                      3.64833
Q Predictions Mean             431.072
Q Predictions Std              159.738
Q Predictions Max              571.993
Q Predictions Min                3.16727
V Predictions Mean             443.076
V Predictions Std              159.765
V Predictions Max              586.808
V Predictions Min               13.0937
Log Pis Mean                   -12.1171
Log Pis Std                      0.724869
Log Pis Max                    -10.5267
Log Pis Min                    -14.4609
Policy mu Mean                  -0.0371355
Policy mu Std                    0.119395
Policy mu Max                    0.264709
Policy mu Min                   -0.351265
Policy log std Mean             -0.130841
Policy log std Std               0.0146543
Policy log std Max              -0.0492839
Policy log std Min              -0.170053
Test Rewards Mean               -0.00337145
Test Rewards Std                 0.00435303
Test Rewards Max                 0.00502562
Test Rewards Min                -0.0131465
Test Returns Mean               -0.661365
Test Returns Std                 0.00435188
Test Returns Max                -0.653934
Test Returns Min                -0.668081
Test Actions Mean               -0.0343617
Test Actions Std                 0.0865285
Test Actions Max                 0.142268
Test Actions Min                -0.272637
Num Paths                        8
Exploration Rewards Mean        -0.00666876
Exploration Rewards Std          0.00749425
Exploration Rewards Max          0.00493716
Exploration Rewards Min         -0.0214783
Exploration Returns Mean        -0.796083
Exploration Returns Std          0.00845392
Exploration Returns Max         -0.784646
Exploration Returns Min         -0.812625
Exploration Actions Mean        -0.0299954
Exploration Actions Std          0.592147
Exploration Actions Max          0.997013
Exploration Actions Min         -0.999114
AverageReturn                   -0.661365
Number of train steps total  70844
Number of env steps total    71000
Number of rollouts total       589
Train Time (s)                  20.2253
(Previous) Eval Time (s)         2.134e-06
Sample Time (s)                 15.044
Epoch Time (s)                  35.2694
Total Train Time (s)          5355.51
Epoch                           70
---------------------------  --------------
2018-05-15 21:57:25.573072 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #70 | Epoch Duration: 321.95036935806274
2018-05-15 21:57:25.573179 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #70 | Started Training: True
2018-05-15 21:58:00.089990 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #71 | Epoch Duration: 34.516708850860596
2018-05-15 21:58:00.090259 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #71 | Started Training: True
2018-05-15 21:58:34.469204 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #72 | Epoch Duration: 34.378772020339966
2018-05-15 21:58:34.469412 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #72 | Started Training: True
2018-05-15 21:59:08.454443 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #73 | Epoch Duration: 33.984907388687134
2018-05-15 21:59:08.454710 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #73 | Started Training: True
2018-05-15 21:59:44.194915 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #74 | Epoch Duration: 35.74004292488098
2018-05-15 21:59:44.196448 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #74 | Started Training: True
2018-05-15 22:00:18.961956 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #75 | Epoch Duration: 34.76531958580017
2018-05-15 22:00:18.962162 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #75 | Started Training: True
2018-05-15 22:00:53.597364 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #76 | Epoch Duration: 34.63505220413208
2018-05-15 22:00:53.597575 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #76 | Started Training: True
2018-05-15 22:01:29.360797 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #77 | Epoch Duration: 35.763065814971924
2018-05-15 22:01:29.361043 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #77 | Started Training: True
2018-05-15 22:02:03.963997 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #78 | Epoch Duration: 34.60283303260803
2018-05-15 22:02:03.964724 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #78 | Started Training: True
2018-05-15 22:02:39.283146 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #79 | Epoch Duration: 35.31822872161865
2018-05-15 22:02:39.283439 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #79 | Started Training: True
2018-05-15 22:03:19.224583 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #80 | Collecting samples for evaluation
---------------------------  --------------
QF Loss                          6.19115
VF Loss                          3.85236
Policy Loss                    -10.5937
Q Predictions Mean             476.325
Q Predictions Std              164.704
Q Predictions Max              637.46
Q Predictions Min               22.348
V Predictions Mean             489.445
V Predictions Std              164.686
V Predictions Max              655.639
V Predictions Min               37.1843
Log Pis Mean                   -12.2093
Log Pis Std                      0.739547
Log Pis Max                    -10.2771
Log Pis Min                    -15.0996
Policy mu Mean                  -0.0314041
Policy mu Std                    0.0930567
Policy mu Max                    0.26133
Policy mu Min                   -0.3011
Policy log std Mean             -0.136607
Policy log std Std               0.0123261
Policy log std Max              -0.0681545
Policy log std Min              -0.175386
Test Rewards Mean                0.00295587
Test Rewards Std                 0.00573221
Test Rewards Max                 0.0190158
Test Rewards Min                -0.00507096
Test Returns Mean                0.491518
Test Returns Std                 0.0148418
Test Returns Max                 0.505882
Test Returns Min                 0.472374
Test Actions Mean               -0.0285743
Test Actions Std                 0.0583178
Test Actions Max                 0.0730946
Test Actions Min                -0.307623
Num Paths                        7
Exploration Rewards Mean        -0.00663743
Exploration Rewards Std          0.00768347
Exploration Rewards Max          0.00598987
Exploration Rewards Min         -0.0211932
Exploration Returns Mean        -0.799337
Exploration Returns Std          0.00655526
Exploration Returns Max         -0.789752
Exploration Returns Min         -0.808302
Exploration Actions Mean        -0.00525516
Exploration Actions Std          0.589834
Exploration Actions Max          0.997274
Exploration Actions Min         -0.997515
AverageReturn                    0.491518
Number of train steps total  80844
Number of env steps total    81000
Number of rollouts total       671
Train Time (s)                  20.9442
(Previous) Eval Time (s)         3.427e-06
Sample Time (s)                 14.8929
Epoch Time (s)                  35.8371
Total Train Time (s)          5940.33
Epoch                           80
---------------------------  --------------
2018-05-15 22:07:10.591589 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #80 | Epoch Duration: 271.30799865722656
2018-05-15 22:07:10.591694 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #80 | Started Training: True
2018-05-15 22:07:45.993323 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #81 | Epoch Duration: 35.401530265808105
2018-05-15 22:07:45.995421 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #81 | Started Training: True
2018-05-15 22:08:21.183650 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #82 | Epoch Duration: 35.18804860115051
2018-05-15 22:08:21.184750 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #82 | Started Training: True
2018-05-15 22:08:55.717818 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #83 | Epoch Duration: 34.53291654586792
2018-05-15 22:08:55.720330 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #83 | Started Training: True
2018-05-15 22:10:49.132090 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #84 | Epoch Duration: 113.41160249710083
2018-05-15 22:10:49.132341 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #84 | Started Training: True
2018-05-15 22:11:54.312054 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #85 | Epoch Duration: 65.17958521842957
2018-05-15 22:11:54.312317 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #85 | Started Training: True
2018-05-15 22:12:30.837763 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #86 | Epoch Duration: 36.525320529937744
2018-05-15 22:12:30.839831 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #86 | Started Training: True
2018-05-15 22:13:08.009518 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #87 | Epoch Duration: 37.169517278671265
2018-05-15 22:13:08.009731 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #87 | Started Training: True
2018-05-15 22:13:43.776852 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #88 | Epoch Duration: 35.76697587966919
2018-05-15 22:13:43.777066 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #88 | Started Training: True
2018-05-15 22:14:20.411958 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #89 | Epoch Duration: 36.6347336769104
2018-05-15 22:14:20.412232 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #89 | Started Training: True
2018-05-15 22:15:02.040482 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #90 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          4.37311
VF Loss                          3.72384
Policy Loss                     16.0598
Q Predictions Mean             463.463
Q Predictions Std              190.927
Q Predictions Max              682.597
Q Predictions Min               31.4484
V Predictions Mean             474.447
V Predictions Std              191.036
V Predictions Max              694.473
V Predictions Min               41.4947
Log Pis Mean                   -12.3082
Log Pis Std                      0.568414
Log Pis Max                    -10.6962
Log Pis Min                    -14.5514
Policy mu Mean                  -0.0131828
Policy mu Std                    0.0480448
Policy mu Max                    0.192122
Policy mu Min                   -0.221772
Policy log std Mean             -0.127833
Policy log std Std               0.00938553
Policy log std Max              -0.0870516
Policy log std Min              -0.168988
Test Rewards Mean                0.00346953
Test Rewards Std                 0.0012834
Test Rewards Max                 0.00648995
Test Rewards Min                 0.000558017
Test Returns Mean                0.271157
Test Returns Std                 0.00182214
Test Returns Max                 0.274728
Test Returns Min                 0.268819
Test Actions Mean               -0.00446431
Test Actions Std                 0.0479278
Test Actions Max                 0.123117
Test Actions Min                -0.112179
Num Paths                       11
Exploration Rewards Mean        -0.0065644
Exploration Rewards Std          0.00766932
Exploration Rewards Max          0.00729635
Exploration Rewards Min         -0.0211348
Exploration Returns Mean        -0.799663
Exploration Returns Std          0.00922829
Exploration Returns Max         -0.786143
Exploration Returns Min         -0.815899
Exploration Actions Mean         0.00224218
Exploration Actions Std          0.588993
Exploration Actions Max          0.998985
Exploration Actions Min         -0.998182
AverageReturn                    0.271157
Number of train steps total  90844
Number of env steps total    91000
Number of rollouts total       757
Train Time (s)                  21.1467
(Previous) Eval Time (s)         2.763e-06
Sample Time (s)                 16.236
Epoch Time (s)                  37.3827
Total Train Time (s)          6785.66
Epoch                           90
---------------------------  ---------------
2018-05-15 22:21:16.137572 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #90 | Epoch Duration: 415.72518587112427
2018-05-15 22:21:16.137689 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #90 | Started Training: True
2018-05-15 22:24:07.184040 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #91 | Epoch Duration: 171.0462520122528
2018-05-15 22:24:07.184280 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #91 | Started Training: True
2018-05-15 22:26:58.120278 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #92 | Epoch Duration: 170.93587255477905
2018-05-15 22:26:58.120544 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #92 | Started Training: True
2018-05-15 22:29:36.966454 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #93 | Epoch Duration: 158.84579157829285
2018-05-15 22:29:36.966671 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #93 | Started Training: True
2018-05-15 22:30:13.847452 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #94 | Epoch Duration: 36.88061594963074
2018-05-15 22:30:13.850145 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #94 | Started Training: True
2018-05-15 22:30:50.149259 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #95 | Epoch Duration: 36.29896092414856
2018-05-15 22:30:50.149472 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #95 | Started Training: True
2018-05-15 22:31:26.722524 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #96 | Epoch Duration: 36.57290506362915
2018-05-15 22:31:26.723597 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #96 | Started Training: True
2018-05-15 22:32:03.246093 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #97 | Epoch Duration: 36.52234768867493
2018-05-15 22:32:03.246299 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #97 | Started Training: True
2018-05-15 22:32:40.161209 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #98 | Epoch Duration: 36.914724826812744
2018-05-15 22:32:40.161417 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #98 | Started Training: True
2018-05-15 22:34:49.196210 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #99 | Epoch Duration: 129.0346384048462
2018-05-15 22:34:49.196490 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #99 | Started Training: True
2018-05-15 22:37:47.126524 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #100 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           5.83836
VF Loss                           4.13398
Policy Loss                     -14.7689
Q Predictions Mean              489.458
Q Predictions Std               219.878
Q Predictions Max               723.18
Q Predictions Min                27.8889
V Predictions Mean              503.038
V Predictions Std               220.199
V Predictions Max               737.389
V Predictions Min                39.7174
Log Pis Mean                    -12.3266
Log Pis Std                       0.524402
Log Pis Max                     -11.0811
Log Pis Min                     -14.0389
Policy mu Mean                    0.000222342
Policy mu Std                     0.0577857
Policy mu Max                     0.247239
Policy mu Min                    -0.203416
Policy log std Mean              -0.129508
Policy log std Std                0.00820032
Policy log std Max               -0.0913326
Policy log std Min               -0.149289
Test Rewards Mean                 0.00405638
Test Rewards Std                  0.0032361
Test Rewards Max                  0.0119157
Test Rewards Min                 -0.000527052
Test Returns Mean                 0.596288
Test Returns Std                  0.00086381
Test Returns Max                  0.597207
Test Returns Min                  0.595146
Test Actions Mean                 6.14199e-05
Test Actions Std                  0.0764583
Test Actions Max                  0.271848
Test Actions Min                 -0.139704
Num Paths                         8
Exploration Rewards Mean         -0.00656358
Exploration Rewards Std           0.00765545
Exploration Rewards Max           0.00741085
Exploration Rewards Min          -0.0210101
Exploration Returns Mean         -0.796654
Exploration Returns Std           0.0118405
Exploration Returns Max          -0.781913
Exploration Returns Min          -0.818209
Exploration Actions Mean         -0.00130022
Exploration Actions Std           0.589848
Exploration Actions Max           0.998485
Exploration Actions Min          -0.997338
AverageReturn                     0.596288
Number of train steps total  100844
Number of env steps total    101000
Number of rollouts total        840
Train Time (s)                   84.3615
(Previous) Eval Time (s)          2.7e-06
Sample Time (s)                  88.6897
Epoch Time (s)                  173.051
Total Train Time (s)           7949.4
Epoch                           100
---------------------------  ----------------
2018-05-15 22:40:40.108545 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #100 | Epoch Duration: 350.91192722320557
2018-05-15 22:40:40.108660 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #100 | Started Training: True
2018-05-15 22:43:34.082501 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #101 | Epoch Duration: 173.9737401008606
2018-05-15 22:43:34.082753 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #101 | Started Training: True
2018-05-15 22:46:28.651008 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #102 | Epoch Duration: 174.56812119483948
2018-05-15 22:46:28.651256 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #102 | Started Training: True
2018-05-15 22:49:22.613765 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #103 | Epoch Duration: 173.9623782634735
2018-05-15 22:49:22.613978 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #103 | Started Training: True
2018-05-15 22:50:05.030288 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #104 | Epoch Duration: 42.416157484054565
2018-05-15 22:50:05.030528 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #104 | Started Training: True
2018-05-15 22:50:41.732922 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #105 | Epoch Duration: 36.70221662521362
2018-05-15 22:50:41.733193 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #105 | Started Training: True
2018-05-15 22:51:18.073265 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #106 | Epoch Duration: 36.33990478515625
2018-05-15 22:51:18.074411 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #106 | Started Training: True
2018-05-15 22:51:54.579288 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #107 | Epoch Duration: 36.504693269729614
2018-05-15 22:51:54.579550 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #107 | Started Training: True
2018-05-15 22:52:31.241999 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #108 | Epoch Duration: 36.66228437423706
2018-05-15 22:52:31.244373 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #108 | Started Training: True
2018-05-15 22:53:08.583999 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #109 | Epoch Duration: 37.339463233947754
2018-05-15 22:53:08.584270 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #109 | Started Training: True
2018-05-15 22:54:50.193524 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #110 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           8.2895
VF Loss                          13.1471
Policy Loss                      39.422
Q Predictions Mean              525.234
Q Predictions Std               226.104
Q Predictions Max               757.672
Q Predictions Min                 9.87535
V Predictions Mean              534.268
V Predictions Std               226.523
V Predictions Max               766.556
V Predictions Min                16.6195
Log Pis Mean                    -12.089
Log Pis Std                       0.730998
Log Pis Max                     -10.682
Log Pis Min                     -14.1909
Policy mu Mean                    0.0147086
Policy mu Std                     0.092739
Policy mu Max                     0.468196
Policy mu Min                    -0.271604
Policy log std Mean              -0.133363
Policy log std Std                0.0118268
Policy log std Max               -0.0437766
Policy log std Min               -0.161654
Test Rewards Mean                 8.64512e-06
Test Rewards Std                  0.00321692
Test Rewards Max                  0.00769023
Test Rewards Min                 -0.00725101
Test Returns Mean                 0.00123872
Test Returns Std                  0.0140528
Test Returns Max                  0.0272852
Test Returns Min                 -0.0149496
Test Actions Mean                 0.0197358
Test Actions Std                  0.112157
Test Actions Max                  0.424972
Test Actions Min                 -0.153436
Num Paths                         9
Exploration Rewards Mean         -0.00665645
Exploration Rewards Std           0.00777323
Exploration Rewards Max           0.00783572
Exploration Rewards Min          -0.0212617
Exploration Returns Mean         -0.803951
Exploration Returns Std           0.00826721
Exploration Returns Max          -0.792254
Exploration Returns Min          -0.818266
Exploration Actions Mean          0.0130523
Exploration Actions Std           0.590997
Exploration Actions Max           0.998737
Exploration Actions Min          -0.999252
AverageReturn                     0.00123872
Number of train steps total  110844
Number of env steps total    111000
Number of rollouts total        922
Train Time (s)                   48.151
(Previous) Eval Time (s)          2.319e-06
Sample Time (s)                  48.6688
Epoch Time (s)                   96.8198
Total Train Time (s)           9161.17
Epoch                           110
---------------------------  ----------------
2018-05-15 23:00:52.098762 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #110 | Epoch Duration: 463.5143623352051
2018-05-15 23:00:52.098885 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #110 | Started Training: True
2018-05-15 23:02:32.558635 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #111 | Epoch Duration: 100.4596483707428
2018-05-15 23:02:32.560786 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #111 | Started Training: True
2018-05-15 23:03:08.778691 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #112 | Epoch Duration: 36.21773886680603
2018-05-15 23:03:08.779821 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #112 | Started Training: True
2018-05-15 23:03:45.522495 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #113 | Epoch Duration: 36.742499113082886
2018-05-15 23:03:45.522716 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #113 | Started Training: True
2018-05-15 23:04:21.655423 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #114 | Epoch Duration: 36.132543325424194
2018-05-15 23:04:21.655632 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #114 | Started Training: True
2018-05-15 23:04:57.455188 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #115 | Epoch Duration: 35.799389123916626
2018-05-15 23:04:57.455467 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #115 | Started Training: True
2018-05-15 23:05:34.446977 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #116 | Epoch Duration: 36.991365909576416
2018-05-15 23:05:34.447193 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #116 | Started Training: True
2018-05-15 23:07:04.080052 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #117 | Epoch Duration: 89.6326973438263
2018-05-15 23:07:04.082532 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #117 | Started Training: True
2018-05-15 23:09:59.332660 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #118 | Epoch Duration: 175.24995398521423
2018-05-15 23:09:59.332907 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #118 | Started Training: True
2018-05-15 23:12:53.182597 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #119 | Epoch Duration: 173.84956216812134
2018-05-15 23:12:53.182841 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #119 | Started Training: True
2018-05-15 23:15:55.700725 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #120 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           8.50652
VF Loss                           7.24141
Policy Loss                      24.2949
Q Predictions Mean              538.602
Q Predictions Std               226.638
Q Predictions Max               799.416
Q Predictions Min                11.0527
V Predictions Mean              549.026
V Predictions Std               227.018
V Predictions Max               808.842
V Predictions Min                20.4595
Log Pis Mean                    -12.1447
Log Pis Std                       0.734865
Log Pis Max                     -10.0893
Log Pis Min                     -14.0582
Policy mu Mean                    0.0172043
Policy mu Std                     0.117691
Policy mu Max                     0.453745
Policy mu Min                    -0.433816
Policy log std Mean              -0.135289
Policy log std Std                0.013717
Policy log std Max               -0.0468805
Policy log std Min               -0.180144
Test Rewards Mean                 0.00214942
Test Rewards Std                  0.00179702
Test Rewards Max                  0.00809342
Test Rewards Min                 -7.955e-05
Test Returns Mean                 0.231063
Test Returns Std                  0.00136826
Test Returns Max                  0.233634
Test Returns Min                  0.228577
Test Actions Mean                 0.0151336
Test Actions Std                  0.118189
Test Actions Max                  0.379153
Test Actions Min                 -0.160068
Num Paths                         9
Exploration Rewards Mean         -0.00661722
Exploration Rewards Std           0.00777922
Exploration Rewards Max           0.00724163
Exploration Rewards Min          -0.0210727
Exploration Returns Mean         -0.800684
Exploration Returns Std           0.00976656
Exploration Returns Max          -0.785535
Exploration Returns Min          -0.817879
Exploration Actions Mean          0.0164229
Exploration Actions Std           0.594793
Exploration Actions Max           0.998052
Exploration Actions Min          -0.998347
AverageReturn                     0.231063
Number of train steps total  120844
Number of env steps total    121000
Number of rollouts total       1004
Train Time (s)                   85.317
(Previous) Eval Time (s)          2.707e-06
Sample Time (s)                  92.0056
Epoch Time (s)                  177.323
Total Train Time (s)          10437.9
Epoch                           120
---------------------------  ---------------
2018-05-15 23:22:09.099296 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #120 | Epoch Duration: 555.9163439273834
2018-05-15 23:22:09.099407 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #120 | Started Training: True
2018-05-15 23:22:46.193670 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #121 | Epoch Duration: 37.09416675567627
2018-05-15 23:22:46.194793 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #121 | Started Training: True
2018-05-15 23:23:23.608779 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #122 | Epoch Duration: 37.41383600234985
2018-05-15 23:23:23.608988 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #122 | Started Training: True
2018-05-15 23:26:08.835835 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #123 | Epoch Duration: 165.22668933868408
2018-05-15 23:26:08.838127 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #123 | Started Training: True
2018-05-15 23:29:07.296165 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #124 | Epoch Duration: 178.45786786079407
2018-05-15 23:29:07.296407 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #124 | Started Training: True
2018-05-15 23:32:03.083433 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #125 | Epoch Duration: 175.78689312934875
2018-05-15 23:32:03.083662 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #125 | Started Training: True
2018-05-15 23:34:58.409614 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #126 | Epoch Duration: 175.32581186294556
2018-05-15 23:34:58.409861 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #126 | Started Training: True
2018-05-15 23:37:51.461724 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #127 | Epoch Duration: 173.05172634124756
2018-05-15 23:37:51.461976 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #127 | Started Training: True
2018-05-15 23:40:49.822400 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #128 | Epoch Duration: 178.36027765274048
2018-05-15 23:40:49.822650 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #128 | Started Training: True
2018-05-15 23:43:47.172485 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #129 | Epoch Duration: 177.34970092773438
2018-05-15 23:43:47.172740 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #129 | Started Training: True
2018-05-15 23:46:49.570208 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #130 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           8.72517
VF Loss                           8.38933
Policy Loss                     -28.1079
Q Predictions Mean              514.074
Q Predictions Std               254.03
Q Predictions Max               822.581
Q Predictions Min                -3.03917
V Predictions Mean              528.804
V Predictions Std               254.264
V Predictions Max               842.64
V Predictions Min                 8.62375
Log Pis Mean                    -12.1023
Log Pis Std                       0.712767
Log Pis Max                     -10.2947
Log Pis Min                     -13.9365
Policy mu Mean                    0.0150976
Policy mu Std                     0.113539
Policy mu Max                     0.39907
Policy mu Min                    -0.479186
Policy log std Mean              -0.135634
Policy log std Std                0.0129703
Policy log std Max               -0.0301288
Policy log std Min               -0.176234
Test Rewards Mean                 0.00274205
Test Rewards Std                  0.00182592
Test Rewards Max                  0.00891621
Test Rewards Min                  0.000611522
Test Returns Mean                 0.260495
Test Returns Std                  0.00229174
Test Returns Max                  0.263763
Test Returns Min                  0.256894
Test Actions Mean                 0.011273
Test Actions Std                  0.129227
Test Actions Max                  0.340734
Test Actions Min                 -0.205617
Num Paths                         8
Exploration Rewards Mean         -0.0064983
Exploration Rewards Std           0.00770119
Exploration Rewards Max           0.00780488
Exploration Rewards Min          -0.0210487
Exploration Returns Mean         -0.796854
Exploration Returns Std           0.0045609
Exploration Returns Max          -0.792931
Exploration Returns Min          -0.805546
Exploration Actions Mean          0.00915717
Exploration Actions Std           0.589185
Exploration Actions Max           0.99709
Exploration Actions Min          -0.999869
AverageReturn                     0.260495
Number of train steps total  130844
Number of env steps total    131000
Number of rollouts total       1088
Train Time (s)                   88.9273
(Previous) Eval Time (s)          2.285e-06
Sample Time (s)                  88.1514
Epoch Time (s)                  177.079
Total Train Time (s)          12279.9
Epoch                           130
---------------------------  ----------------
2018-05-15 23:52:51.311750 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #130 | Epoch Duration: 544.1389002799988
2018-05-15 23:52:51.311864 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #130 | Started Training: True
2018-05-15 23:55:46.628196 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #131 | Epoch Duration: 175.31623697280884
2018-05-15 23:55:46.628436 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #131 | Started Training: True
2018-05-15 23:58:41.421362 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #132 | Epoch Duration: 174.79280185699463
2018-05-15 23:58:41.421609 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #132 | Started Training: True
2018-05-16 00:01:39.762888 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #133 | Epoch Duration: 178.3411421775818
2018-05-16 00:01:39.765295 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #133 | Started Training: True
2018-05-16 00:04:38.366689 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #134 | Epoch Duration: 178.60119462013245
2018-05-16 00:04:38.366940 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #134 | Started Training: True
2018-05-16 00:07:34.604197 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #135 | Epoch Duration: 176.23711609840393
2018-05-16 00:07:34.604453 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #135 | Started Training: True
2018-05-16 00:10:04.649794 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #136 | Epoch Duration: 150.04520678520203
2018-05-16 00:10:04.649994 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #136 | Started Training: True
2018-05-16 00:10:41.779777 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #137 | Epoch Duration: 37.12966704368591
2018-05-16 00:10:41.781832 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #137 | Started Training: True
2018-05-16 00:11:18.106570 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #138 | Epoch Duration: 36.324583530426025
2018-05-16 00:11:18.106782 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #138 | Started Training: True
2018-05-16 00:11:55.050487 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #139 | Epoch Duration: 36.943541049957275
2018-05-16 00:11:55.050724 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #139 | Started Training: True
2018-05-16 00:12:36.786418 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #140 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           6.15274
VF Loss                           3.67636
Policy Loss                      14.5971
Q Predictions Mean              545.48
Q Predictions Std               246.868
Q Predictions Max               846.456
Q Predictions Min                17.0819
V Predictions Mean              556.66
V Predictions Std               246.803
V Predictions Max               855.216
V Predictions Min                29.0482
Log Pis Mean                    -12.1123
Log Pis Std                       0.733945
Log Pis Max                     -10.478
Log Pis Min                     -14.1154
Policy mu Mean                    0.00683649
Policy mu Std                     0.116439
Policy mu Max                     0.382141
Policy mu Min                    -0.210366
Policy log std Mean              -0.136814
Policy log std Std                0.0123238
Policy log std Max               -0.0752631
Policy log std Min               -0.164009
Test Rewards Mean                 0.00350258
Test Rewards Std                  0.00189796
Test Rewards Max                  0.0078877
Test Rewards Min                 -0.000474441
Test Returns Mean                 0.384583
Test Returns Std                  0.0151222
Test Returns Max                  0.406313
Test Returns Min                  0.363441
Test Actions Mean                -0.0115884
Test Actions Std                  0.107011
Test Actions Max                  0.250014
Test Actions Min                 -0.24069
Num Paths                         7
Exploration Rewards Mean         -0.00652561
Exploration Rewards Std           0.00771434
Exploration Rewards Max           0.00802282
Exploration Rewards Min          -0.02093
Exploration Returns Mean         -0.798921
Exploration Returns Std           0.010519
Exploration Returns Max          -0.786455
Exploration Returns Min          -0.818537
Exploration Actions Mean         -0.00856065
Exploration Actions Std           0.593839
Exploration Actions Max           0.997828
Exploration Actions Min          -0.998978
AverageReturn                     0.384583
Number of train steps total  140844
Number of env steps total    141000
Number of rollouts total       1166
Train Time (s)                   20.4895
(Previous) Eval Time (s)          2.203e-06
Sample Time (s)                  15.9012
Epoch Time (s)                   36.3907
Total Train Time (s)          13764.6
Epoch                           140
---------------------------  ----------------
2018-05-16 00:17:36.203857 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #140 | Epoch Duration: 341.1530177593231
2018-05-16 00:17:36.203992 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #140 | Started Training: True
2018-05-16 00:20:34.689449 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #141 | Epoch Duration: 178.48534321784973
2018-05-16 00:20:34.689695 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #141 | Started Training: True
2018-05-16 00:23:29.735672 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #142 | Epoch Duration: 175.04584097862244
2018-05-16 00:23:29.735923 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #142 | Started Training: True
2018-05-16 00:26:24.905107 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #143 | Epoch Duration: 175.16903591156006
2018-05-16 00:26:24.905815 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #143 | Started Training: True
2018-05-16 00:27:49.356382 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #144 | Epoch Duration: 84.45041131973267
2018-05-16 00:27:49.356642 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #144 | Started Training: True
2018-05-16 00:28:26.386708 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #145 | Epoch Duration: 37.02990007400513
2018-05-16 00:28:26.387844 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #145 | Started Training: True
2018-05-16 00:29:02.597820 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #146 | Epoch Duration: 36.209784507751465
2018-05-16 00:29:02.598937 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #146 | Started Training: True
2018-05-16 00:29:39.773584 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #147 | Epoch Duration: 37.17449355125427
2018-05-16 00:29:39.773793 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #147 | Started Training: True
2018-05-16 00:30:17.438900 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #148 | Epoch Duration: 37.66495227813721
2018-05-16 00:30:17.439684 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #148 | Started Training: True
2018-05-16 00:30:53.378922 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #149 | Epoch Duration: 35.93908667564392
2018-05-16 00:30:53.379127 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #149 | Started Training: True
2018-05-16 00:32:41.922024 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #150 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           8.0385
VF Loss                           3.14811
Policy Loss                       4.95598
Q Predictions Mean              515.548
Q Predictions Std               247.891
Q Predictions Max               857.794
Q Predictions Min                -2.09434
V Predictions Mean              527.565
V Predictions Std               247.055
V Predictions Max               874.071
V Predictions Min                12.1206
Log Pis Mean                    -12.224
Log Pis Std                       0.69536
Log Pis Max                     -10.6485
Log Pis Min                     -14.3481
Policy mu Mean                   -0.00313905
Policy mu Std                     0.100134
Policy mu Max                     0.293732
Policy mu Min                    -0.350797
Policy log std Mean              -0.135707
Policy log std Std                0.0154593
Policy log std Max               -0.0250778
Policy log std Min               -0.192973
Test Rewards Mean                 0.00381279
Test Rewards Std                  0.00222976
Test Rewards Max                  0.00747006
Test Rewards Min                 -0.000627535
Test Returns Mean                 0.392336
Test Returns Std                  0.0141225
Test Returns Max                  0.422429
Test Returns Min                  0.372319
Test Actions Mean                -0.0173473
Test Actions Std                  0.105196
Test Actions Max                  0.338612
Test Actions Min                 -0.272253
Num Paths                         8
Exploration Rewards Mean         -0.00658409
Exploration Rewards Std           0.0076503
Exploration Rewards Max           0.00597543
Exploration Rewards Min          -0.0209182
Exploration Returns Mean         -0.798321
Exploration Returns Std           0.00908072
Exploration Returns Max          -0.780949
Exploration Returns Min          -0.811641
Exploration Actions Mean          0.00116164
Exploration Actions Std           0.593536
Exploration Actions Max           0.999281
Exploration Actions Min          -0.997467
AverageReturn                     0.392336
Number of train steps total  150844
Number of env steps total    151000
Number of rollouts total       1249
Train Time (s)                   52.1827
(Previous) Eval Time (s)          2.037e-06
Sample Time (s)                  50.4041
Epoch Time (s)                  102.587
Total Train Time (s)          14943.5
Epoch                           150
---------------------------  ----------------
2018-05-16 00:37:15.396196 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #150 | Epoch Duration: 382.0169231891632
2018-05-16 00:37:15.396311 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #150 | Started Training: True
2018-05-16 00:40:13.383293 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #151 | Epoch Duration: 177.98688197135925
2018-05-16 00:40:13.383547 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #151 | Started Training: True
2018-05-16 00:43:04.845606 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #152 | Epoch Duration: 171.46192955970764
2018-05-16 00:43:04.845821 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #152 | Started Training: True
2018-05-16 00:44:46.441974 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #153 | Epoch Duration: 101.59603643417358
2018-05-16 00:44:46.442201 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #153 | Started Training: True
2018-05-16 00:45:23.483192 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #154 | Epoch Duration: 37.04081416130066
2018-05-16 00:45:23.483472 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #154 | Started Training: True
2018-05-16 00:45:59.869192 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #155 | Epoch Duration: 36.38555836677551
2018-05-16 00:45:59.869400 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #155 | Started Training: True
2018-05-16 00:46:36.752028 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #156 | Epoch Duration: 36.882473945617676
2018-05-16 00:46:36.753231 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #156 | Started Training: True
2018-05-16 00:47:13.438655 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #157 | Epoch Duration: 36.685240268707275
2018-05-16 00:47:13.438869 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #157 | Started Training: True
2018-05-16 00:47:49.854460 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #158 | Epoch Duration: 36.415422439575195
2018-05-16 00:47:49.858626 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #158 | Started Training: True
2018-05-16 00:49:28.271519 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #159 | Epoch Duration: 98.41266679763794
2018-05-16 00:49:28.271799 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #159 | Started Training: True
2018-05-16 00:52:34.316563 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #160 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          87.0911
VF Loss                           3.48237
Policy Loss                      -1.68831
Q Predictions Mean              538.014
Q Predictions Std               242.426
Q Predictions Max               868.045
Q Predictions Min                -3.96681
V Predictions Mean              550.458
V Predictions Std               241.831
V Predictions Max               877.553
V Predictions Min                 8.81139
Log Pis Mean                    -12.2161
Log Pis Std                       0.647599
Log Pis Max                     -10.5269
Log Pis Min                     -13.8982
Policy mu Mean                   -0.0150932
Policy mu Std                     0.097878
Policy mu Max                     0.445648
Policy mu Min                    -0.465472
Policy log std Mean              -0.130249
Policy log std Std                0.0151874
Policy log std Max               -0.0422306
Policy log std Min               -0.188734
Test Rewards Mean                 0.00389851
Test Rewards Std                  0.00658871
Test Rewards Max                  0.0150885
Test Rewards Min                 -0.00331586
Test Returns Mean                 0.508755
Test Returns Std                  0.00268268
Test Returns Max                  0.512603
Test Returns Min                  0.504704
Test Actions Mean                -0.042823
Test Actions Std                  0.129286
Test Actions Max                  0.398059
Test Actions Min                 -0.318158
Num Paths                         8
Exploration Rewards Mean         -0.00656218
Exploration Rewards Std           0.00757855
Exploration Rewards Max           0.00533908
Exploration Rewards Min          -0.0208029
Exploration Returns Mean         -0.800586
Exploration Returns Std           0.00604089
Exploration Returns Max          -0.789328
Exploration Returns Min          -0.807766
Exploration Actions Mean         -0.0132031
Exploration Actions Std           0.592572
Exploration Actions Max           0.998559
Exploration Actions Min          -0.996815
AverageReturn                     0.508755
Number of train steps total  160844
Number of env steps total    161000
Number of rollouts total       1332
Train Time (s)                   88.6173
(Previous) Eval Time (s)          3.36e-06
Sample Time (s)                  91.2738
Epoch Time (s)                  179.891
Total Train Time (s)          16104.2
Epoch                           160
---------------------------  ---------------
2018-05-16 00:56:36.311748 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #160 | Epoch Duration: 428.0397951602936
2018-05-16 00:56:36.311855 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #160 | Started Training: True
2018-05-16 00:59:29.618758 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #161 | Epoch Duration: 173.30680632591248
2018-05-16 00:59:29.619011 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #161 | Started Training: True
2018-05-16 01:02:17.436980 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #162 | Epoch Duration: 167.81783485412598
2018-05-16 01:02:17.437254 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #162 | Started Training: True
2018-05-16 01:02:54.253447 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #163 | Epoch Duration: 36.81603455543518
2018-05-16 01:02:54.253662 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #163 | Started Training: True
2018-05-16 01:03:31.519194 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #164 | Epoch Duration: 37.26537275314331
2018-05-16 01:03:31.519469 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #164 | Started Training: True
2018-05-16 01:04:07.775860 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #165 | Epoch Duration: 36.25622582435608
2018-05-16 01:04:07.778158 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #165 | Started Training: True
2018-05-16 01:04:43.828944 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #166 | Epoch Duration: 36.05063819885254
2018-05-16 01:04:43.829200 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #166 | Started Training: True
2018-05-16 01:05:19.135916 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #167 | Epoch Duration: 35.306581020355225
2018-05-16 01:05:19.136186 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #167 | Started Training: True
2018-05-16 01:06:35.032120 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #168 | Epoch Duration: 75.8957736492157
2018-05-16 01:06:35.032333 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #168 | Started Training: True
2018-05-16 01:09:34.215448 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #169 | Epoch Duration: 179.18299651145935
2018-05-16 01:09:34.215712 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #169 | Started Training: True
2018-05-16 01:12:38.074200 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #170 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                        3683.52
VF Loss                          10.2073
Policy Loss                     -22.9945
Q Predictions Mean              512.634
Q Predictions Std               260.527
Q Predictions Max              1537.17
Q Predictions Min                24.1812
V Predictions Mean              546.142
V Predictions Std               386.263
V Predictions Max              3914.23
V Predictions Min                38.4062
Log Pis Mean                    -11.3993
Log Pis Std                       9.17313
Log Pis Max                      91.6903
Log Pis Min                     -14.4019
Policy mu Mean                   -0.0281906
Policy mu Std                     0.309692
Policy mu Max                     3.88599
Policy mu Min                    -4.43668
Policy log std Mean              -0.142933
Policy log std Std                0.0697292
Policy log std Max                0.110894
Policy log std Min               -1.63771
Test Rewards Mean                 0.00373856
Test Rewards Std                  0.00737058
Test Rewards Max                  0.0212404
Test Rewards Min                 -0.00365704
Test Returns Mean                 0.547432
Test Returns Std                  0.00814413
Test Returns Max                  0.561073
Test Returns Min                  0.534398
Test Actions Mean                -0.0487231
Test Actions Std                  0.282085
Test Actions Max                  0.832106
Test Actions Min                 -0.759356
Num Paths                         7
Exploration Rewards Mean         -0.00648539
Exploration Rewards Std           0.00746543
Exploration Rewards Max           0.00549423
Exploration Rewards Min          -0.0208507
Exploration Returns Mean         -0.787512
Exploration Returns Std           0.00871676
Exploration Returns Max          -0.774922
Exploration Returns Min          -0.799609
Exploration Actions Mean         -0.0186563
Exploration Actions Std           0.586864
Exploration Actions Max           0.999391
Exploration Actions Min          -0.99809
AverageReturn                     0.547432
Number of train steps total  170844
Number of env steps total    171000
Number of rollouts total       1412
Train Time (s)                   87.6453
(Previous) Eval Time (s)          2.958e-06
Sample Time (s)                  89.8506
Epoch Time (s)                  177.496
Total Train Time (s)          17670.9
Epoch                           170
---------------------------  ---------------
2018-05-16 01:22:43.225934 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #170 | Epoch Duration: 789.0100972652435
2018-05-16 01:22:43.226048 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #170 | Started Training: True
2018-05-16 01:25:37.428310 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #171 | Epoch Duration: 174.20216250419617
2018-05-16 01:25:37.428557 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #171 | Started Training: True
2018-05-16 01:28:38.458626 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #172 | Epoch Duration: 181.02994203567505
2018-05-16 01:28:38.458880 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #172 | Started Training: True
2018-05-16 01:31:34.049518 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #173 | Epoch Duration: 175.590500831604
2018-05-16 01:31:34.049780 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #173 | Started Training: True
2018-05-16 01:34:32.618396 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #174 | Epoch Duration: 178.56848978996277
2018-05-16 01:34:32.618667 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #174 | Started Training: True
2018-05-16 01:37:25.644787 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #175 | Epoch Duration: 173.02599263191223
2018-05-16 01:37:25.645052 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #175 | Started Training: True
2018-05-16 01:40:23.735411 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #176 | Epoch Duration: 178.0902223587036
2018-05-16 01:40:23.735673 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #176 | Started Training: True
2018-05-16 01:42:37.324461 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #177 | Epoch Duration: 133.58866262435913
2018-05-16 01:42:37.325124 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #177 | Started Training: True
2018-05-16 01:43:13.660089 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #178 | Epoch Duration: 36.33477473258972
2018-05-16 01:43:13.661420 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #178 | Started Training: True
2018-05-16 01:43:50.386188 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #179 | Epoch Duration: 36.724512338638306
2018-05-16 01:43:50.386489 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #179 | Started Training: True
2018-05-16 01:44:32.644138 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #180 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           7.65238
VF Loss                           4.15942
Policy Loss                       0.185013
Q Predictions Mean              517.107
Q Predictions Std               253.666
Q Predictions Max               875.017
Q Predictions Min                 4.08458
V Predictions Mean              529.562
V Predictions Std               253.733
V Predictions Max               885.029
V Predictions Min                17.9318
Log Pis Mean                    -12.2327
Log Pis Std                       0.707515
Log Pis Max                      -9.63075
Log Pis Min                     -15.0254
Policy mu Mean                   -0.0151819
Policy mu Std                     0.108084
Policy mu Max                     0.563941
Policy mu Min                    -0.502298
Policy log std Mean              -0.133637
Policy log std Std                0.0132772
Policy log std Max               -0.065143
Policy log std Min               -0.205692
Test Rewards Mean                -0.00323658
Test Rewards Std                  0.0015504
Test Rewards Max                  0.000626053
Test Rewards Min                 -0.00521773
Test Returns Mean                -0.13688
Test Returns Std                  0.00453854
Test Returns Max                 -0.131445
Test Returns Min                 -0.154101
Test Actions Mean                -0.0177377
Test Actions Std                  0.152384
Test Actions Max                  0.425048
Test Actions Min                 -0.32186
Num Paths                         9
Exploration Rewards Mean         -0.00644379
Exploration Rewards Std           0.00759148
Exploration Rewards Max           0.0071714
Exploration Rewards Min          -0.0209163
Exploration Returns Mean         -0.793302
Exploration Returns Std           0.0147998
Exploration Returns Max          -0.763798
Exploration Returns Min          -0.819534
Exploration Actions Mean         -0.00388006
Exploration Actions Std           0.590832
Exploration Actions Max           0.998342
Exploration Actions Min          -0.998381
AverageReturn                    -0.13688
Number of train steps total  180844
Number of env steps total    181000
Number of rollouts total       1492
Train Time (s)                   19.9624
(Previous) Eval Time (s)          2.978e-06
Sample Time (s)                  16.1451
Epoch Time (s)                   36.1075
Total Train Time (s)          19463.2
Epoch                           180
---------------------------  ----------------
2018-05-16 01:52:35.800200 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #180 | Epoch Duration: 525.4135339260101
2018-05-16 01:52:35.800314 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #180 | Started Training: True
2018-05-16 01:54:00.452382 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #181 | Epoch Duration: 84.65196323394775
2018-05-16 01:54:00.452591 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #181 | Started Training: True
2018-05-16 01:54:37.079579 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #182 | Epoch Duration: 36.62681818008423
2018-05-16 01:54:37.079871 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #182 | Started Training: True
2018-05-16 01:55:13.638202 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #183 | Epoch Duration: 36.55800771713257
2018-05-16 01:55:13.639000 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #183 | Started Training: True
2018-05-16 01:55:50.078790 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #184 | Epoch Duration: 36.43921208381653
2018-05-16 01:55:50.079060 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #184 | Started Training: True
2018-05-16 01:56:26.273582 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #185 | Epoch Duration: 36.194358825683594
2018-05-16 01:56:26.273832 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #185 | Started Training: True
2018-05-16 01:57:03.439889 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #186 | Epoch Duration: 37.165935039520264
2018-05-16 01:57:03.440139 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #186 | Started Training: True
2018-05-16 01:58:41.869873 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #187 | Epoch Duration: 98.42959952354431
2018-05-16 01:58:41.870124 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #187 | Started Training: True
2018-05-16 02:01:38.763216 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #188 | Epoch Duration: 176.89295482635498
2018-05-16 02:01:38.765399 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #188 | Started Training: True
2018-05-16 02:04:35.873818 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #189 | Epoch Duration: 177.10826110839844
2018-05-16 02:04:35.874078 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #189 | Started Training: True
2018-05-16 02:07:37.644809 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #190 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           9.23077
VF Loss                           5.52617
Policy Loss                      16.0896
Q Predictions Mean              485.788
Q Predictions Std               265.462
Q Predictions Max               866.561
Q Predictions Min                10.5592
V Predictions Mean              497.011
V Predictions Std               265.698
V Predictions Max               877.158
V Predictions Min                18.4818
Log Pis Mean                    -12.0869
Log Pis Std                       0.843046
Log Pis Max                      -9.90004
Log Pis Min                     -14.4014
Policy mu Mean                   -0.00718025
Policy mu Std                     0.122107
Policy mu Max                     0.745381
Policy mu Min                    -0.556591
Policy log std Mean              -0.130214
Policy log std Std                0.018124
Policy log std Max                0.0102687
Policy log std Min               -0.318873
Test Rewards Mean                 0.00504919
Test Rewards Std                  0.00303687
Test Rewards Max                  0.00897985
Test Rewards Min                  1.4284e-05
Test Returns Mean                 0.470033
Test Returns Std                  0.0146697
Test Returns Max                  0.494736
Test Returns Min                  0.443266
Test Actions Mean                -0.0119341
Test Actions Std                  0.17123
Test Actions Max                  0.474732
Test Actions Min                 -0.353219
Num Paths                         8
Exploration Rewards Mean         -0.00636794
Exploration Rewards Std           0.00760956
Exploration Rewards Max           0.00711527
Exploration Rewards Min          -0.0207658
Exploration Returns Mean         -0.7944
Exploration Returns Std           0.00706114
Exploration Returns Max          -0.784807
Exploration Returns Min          -0.808352
Exploration Actions Mean         -0.0105335
Exploration Actions Std           0.592011
Exploration Actions Max           0.999011
Exploration Actions Min          -0.998028
AverageReturn                     0.470033
Number of train steps total  190844
Number of env steps total    191000
Number of rollouts total       1572
Train Time (s)                   86.0677
(Previous) Eval Time (s)          2.649e-06
Sample Time (s)                  89.0629
Epoch Time (s)                  175.131
Total Train Time (s)          20568.5
Epoch                           190
---------------------------  ---------------
2018-05-16 02:11:01.367207 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #190 | Epoch Duration: 385.4930109977722
2018-05-16 02:11:01.367328 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #190 | Started Training: True
2018-05-16 02:13:08.034253 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #191 | Epoch Duration: 126.66682052612305
2018-05-16 02:13:08.034492 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #191 | Started Training: True
2018-05-16 02:13:44.225323 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #192 | Epoch Duration: 36.190656423568726
2018-05-16 02:13:44.225533 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #192 | Started Training: True
2018-05-16 02:14:20.724651 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #193 | Epoch Duration: 36.49899220466614
2018-05-16 02:14:20.724936 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #193 | Started Training: True
2018-05-16 02:14:57.679140 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #194 | Epoch Duration: 36.954012393951416
2018-05-16 02:14:57.679410 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #194 | Started Training: True
2018-05-16 02:15:34.378851 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #195 | Epoch Duration: 36.6992712020874
2018-05-16 02:15:34.379922 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #195 | Started Training: True
2018-05-16 02:16:11.412062 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #196 | Epoch Duration: 37.03190541267395
2018-05-16 02:16:11.412354 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #196 | Started Training: True
2018-05-16 02:17:45.680573 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #197 | Epoch Duration: 94.2680516242981
2018-05-16 02:17:45.680833 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #197 | Started Training: True
2018-05-16 02:20:47.016196 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #198 | Epoch Duration: 181.33522987365723
2018-05-16 02:20:47.016450 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #198 | Started Training: True
2018-05-16 02:23:44.119312 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #199 | Epoch Duration: 177.10273385047913
2018-05-16 02:23:44.122403 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #199 | Started Training: True
2018-05-16 02:26:47.507913 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #200 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           9.16556
VF Loss                           3.91651
Policy Loss                       3.80399
Q Predictions Mean              552.366
Q Predictions Std               251.258
Q Predictions Max               868.189
Q Predictions Min                -5.62836
V Predictions Mean              564.448
V Predictions Std               251.405
V Predictions Max               879.747
V Predictions Min                 9.11576
Log Pis Mean                    -12.1656
Log Pis Std                       0.817982
Log Pis Max                     -10.0551
Log Pis Min                     -14.7782
Policy mu Mean                   -0.00282666
Policy mu Std                     0.115827
Policy mu Max                     0.475145
Policy mu Min                    -0.569695
Policy log std Mean              -0.132382
Policy log std Std                0.0184322
Policy log std Max               -0.050791
Policy log std Min               -0.29244
Test Rewards Mean                 0.00571206
Test Rewards Std                  0.00413545
Test Rewards Max                  0.0138618
Test Rewards Min                 -5.5413e-05
Test Returns Mean                 0.66006
Test Returns Std                  0.036291
Test Returns Max                  0.685098
Test Returns Min                  0.56125
Test Actions Mean                 0.00597703
Test Actions Std                  0.243165
Test Actions Max                  0.762886
Test Actions Min                 -0.472961
Num Paths                         7
Exploration Rewards Mean         -0.0062516
Exploration Rewards Std           0.00753213
Exploration Rewards Max           0.00657623
Exploration Rewards Min          -0.0210648
Exploration Returns Mean         -0.79306
Exploration Returns Std           0.00527035
Exploration Returns Max          -0.785921
Exploration Returns Min          -0.802616
Exploration Actions Mean          0.000215799
Exploration Actions Std           0.593546
Exploration Actions Max           0.995728
Exploration Actions Min          -0.996972
AverageReturn                     0.66006
Number of train steps total  200844
Number of env steps total    201000
Number of rollouts total       1650
Train Time (s)                   86.5331
(Previous) Eval Time (s)          2.814e-06
Sample Time (s)                  89.9725
Epoch Time (s)                  176.506
Total Train Time (s)          21689.8
Epoch                           200
---------------------------  ----------------
2018-05-16 02:29:42.882114 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #200 | Epoch Duration: 358.75951528549194
2018-05-16 02:29:42.882260 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #200 | Started Training: True
2018-05-16 02:32:43.618182 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #201 | Epoch Duration: 180.7357861995697
2018-05-16 02:32:43.621393 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #201 | Started Training: True
2018-05-16 02:33:56.831977 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #202 | Epoch Duration: 73.21039986610413
2018-05-16 02:33:56.832188 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #202 | Started Training: True
2018-05-16 02:34:32.299081 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #203 | Epoch Duration: 35.466771841049194
2018-05-16 02:34:32.301334 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #203 | Started Training: True
2018-05-16 02:35:08.910827 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #204 | Epoch Duration: 36.609286308288574
2018-05-16 02:35:08.911101 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #204 | Started Training: True
2018-05-16 02:35:45.106115 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #205 | Epoch Duration: 36.19484758377075
2018-05-16 02:35:45.106327 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #205 | Started Training: True
2018-05-16 02:36:22.468392 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #206 | Epoch Duration: 37.36186861991882
2018-05-16 02:36:22.470778 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #206 | Started Training: True
2018-05-16 02:36:59.065918 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #207 | Epoch Duration: 36.594942808151245
2018-05-16 02:36:59.066140 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #207 | Started Training: True
2018-05-16 02:39:26.138473 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #208 | Epoch Duration: 147.07221698760986
2018-05-16 02:39:26.138733 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #208 | Started Training: True
2018-05-16 02:42:23.853644 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #209 | Epoch Duration: 177.71477890014648
2018-05-16 02:42:23.853862 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #209 | Started Training: True
2018-05-16 02:45:26.756567 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #210 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                          10.744
VF Loss                           4.43074
Policy Loss                     -10.7408
Q Predictions Mean              485.155
Q Predictions Std               265.998
Q Predictions Max               869.758
Q Predictions Min                 4.65283
V Predictions Mean              498.317
V Predictions Std               266.576
V Predictions Max               882.067
V Predictions Min                15.14
Log Pis Mean                    -11.9684
Log Pis Std                       0.639223
Log Pis Max                     -10.5055
Log Pis Min                     -14.1041
Policy mu Mean                    0.000149781
Policy mu Std                     0.116097
Policy mu Max                     0.59733
Policy mu Min                    -0.46764
Policy log std Mean              -0.134923
Policy log std Std                0.0168794
Policy log std Max               -0.038227
Policy log std Min               -0.200549
Test Rewards Mean                 0.00497239
Test Rewards Std                  0.0029752
Test Rewards Max                  0.0118331
Test Rewards Min                  0.00057906
Test Returns Mean                 0.556908
Test Returns Std                  0.000541208
Test Returns Max                  0.557686
Test Returns Min                  0.555862
Test Actions Mean                 0.0204603
Test Actions Std                  0.287462
Test Actions Max                  0.702746
Test Actions Min                 -0.591071
Num Paths                         9
Exploration Rewards Mean         -0.00612161
Exploration Rewards Std           0.00752866
Exploration Rewards Max           0.00839052
Exploration Rewards Min          -0.0208049
Exploration Returns Mean         -0.79581
Exploration Returns Std           0.0105177
Exploration Returns Max          -0.781713
Exploration Returns Min          -0.815089
Exploration Actions Mean          0.0130084
Exploration Actions Std           0.592777
Exploration Actions Max           0.998637
Exploration Actions Min          -0.997875
AverageReturn                     0.556908
Number of train steps total  210844
Number of env steps total    211000
Number of rollouts total       1728
Train Time (s)                   85.2235
(Previous) Eval Time (s)          2.323e-06
Sample Time (s)                  90.5359
Epoch Time (s)                  175.759
Total Train Time (s)          22847.1
Epoch                           210
---------------------------  ----------------
2018-05-16 02:49:00.420581 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #210 | Epoch Duration: 396.5666072368622
2018-05-16 02:49:00.420736 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #210 | Started Training: True
2018-05-16 02:52:04.131979 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #211 | Epoch Duration: 183.71111631393433
2018-05-16 02:52:04.132190 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #211 | Started Training: True
2018-05-16 02:53:02.963141 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #212 | Epoch Duration: 58.830830097198486
2018-05-16 02:53:02.963392 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #212 | Started Training: True
2018-05-16 02:53:39.631202 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #213 | Epoch Duration: 36.66766929626465
2018-05-16 02:53:39.631416 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #213 | Started Training: True
2018-05-16 02:54:15.538743 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #214 | Epoch Duration: 35.907209396362305
2018-05-16 02:54:15.539742 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #214 | Started Training: True
2018-05-16 02:54:51.918960 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #215 | Epoch Duration: 36.379050731658936
2018-05-16 02:54:51.919903 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #215 | Started Training: True
2018-05-16 02:55:29.038636 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #216 | Epoch Duration: 37.11857867240906
2018-05-16 02:55:29.038914 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #216 | Started Training: True
2018-05-16 02:56:05.483161 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #217 | Epoch Duration: 36.444087266922
2018-05-16 02:56:05.483365 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #217 | Started Training: True
2018-05-16 02:56:42.069598 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #218 | Epoch Duration: 36.586114168167114
2018-05-16 02:56:42.070458 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #218 | Started Training: True
2018-05-16 02:59:32.214788 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #219 | Epoch Duration: 170.14413022994995
2018-05-16 02:59:32.215043 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #219 | Started Training: True
2018-05-16 03:02:39.315729 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #220 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           6.29673
VF Loss                           3.16123
Policy Loss                       4.89618
Q Predictions Mean              510.456
Q Predictions Std               258.087
Q Predictions Max               874.605
Q Predictions Min                16.4734
V Predictions Mean              522.794
V Predictions Std               258.382
V Predictions Max               887.495
V Predictions Min                27.3489
Log Pis Mean                    -11.9906
Log Pis Std                       0.877451
Log Pis Max                      -9.41189
Log Pis Min                     -14.2513
Policy mu Mean                    0.0177897
Policy mu Std                     0.160337
Policy mu Max                     0.907955
Policy mu Min                    -0.602427
Policy log std Mean              -0.142776
Policy log std Std                0.0228638
Policy log std Max               -0.0639315
Policy log std Min               -0.405358
Test Rewards Mean                 0.00537083
Test Rewards Std                  0.00481304
Test Rewards Max                  0.0162016
Test Rewards Min                 -0.00130136
Test Returns Mean                 0.600936
Test Returns Std                  0.0659547
Test Returns Max                  0.68174
Test Returns Min                  0.45545
Test Actions Mean                -0.0264828
Test Actions Std                  0.232505
Test Actions Max                  0.716754
Test Actions Min                 -0.610597
Num Paths                         8
Exploration Rewards Mean         -0.00597694
Exploration Rewards Std           0.00750585
Exploration Rewards Max           0.00713704
Exploration Rewards Min          -0.021018
Exploration Returns Mean         -0.797921
Exploration Returns Std           0.0111323
Exploration Returns Max          -0.77731
Exploration Returns Min          -0.814658
Exploration Actions Mean          0.0121025
Exploration Actions Std           0.59405
Exploration Actions Max           0.99859
Exploration Actions Min          -0.998537
AverageReturn                     0.600936
Number of train steps total  220844
Number of env steps total    221000
Number of rollouts total       1806
Train Time (s)                   87.3634
(Previous) Eval Time (s)          3.248e-06
Sample Time (s)                  92.479
Epoch Time (s)                  179.842
Total Train Time (s)          23852.2
Epoch                           220
---------------------------  ---------------
2018-05-16 03:05:45.711725 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #220 | Epoch Duration: 373.4965522289276
2018-05-16 03:05:45.711844 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #220 | Started Training: True
2018-05-16 03:08:43.773604 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #221 | Epoch Duration: 178.06165194511414
2018-05-16 03:08:43.773812 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #221 | Started Training: True
2018-05-16 03:11:44.518746 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #222 | Epoch Duration: 180.74481511116028
2018-05-16 03:11:44.520828 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #222 | Started Training: True
2018-05-16 03:14:05.231129 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #223 | Epoch Duration: 140.710125207901
2018-05-16 03:14:05.231978 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #223 | Started Training: True
2018-05-16 03:14:41.596203 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #224 | Epoch Duration: 36.364025354385376
2018-05-16 03:14:41.598413 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #224 | Started Training: True
2018-05-16 03:15:17.963776 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #225 | Epoch Duration: 36.36516332626343
2018-05-16 03:15:17.965097 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #225 | Started Training: True
2018-05-16 03:15:54.278814 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #226 | Epoch Duration: 36.31353163719177
2018-05-16 03:15:54.279084 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #226 | Started Training: True
2018-05-16 03:16:31.030582 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #227 | Epoch Duration: 36.75133681297302
2018-05-16 03:16:31.030787 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #227 | Started Training: True
2018-05-16 03:17:07.700855 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #228 | Epoch Duration: 36.669936418533325
2018-05-16 03:17:07.701523 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #228 | Started Training: True
2018-05-16 03:17:43.802464 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #229 | Epoch Duration: 36.10074543952942
2018-05-16 03:17:43.802714 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #229 | Started Training: True
2018-05-16 03:18:27.179607 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #230 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           8.45697
VF Loss                           3.38178
Policy Loss                      -4.80251
Q Predictions Mean              556.488
Q Predictions Std               240.608
Q Predictions Max               885.737
Q Predictions Min                 2.60014
V Predictions Mean              569.357
V Predictions Std               240.945
V Predictions Max               891.518
V Predictions Min                12.4596
Log Pis Mean                    -11.9137
Log Pis Std                       1.00958
Log Pis Max                      -8.38926
Log Pis Min                     -14.3389
Policy mu Mean                    0.0199506
Policy mu Std                     0.170702
Policy mu Max                     0.793761
Policy mu Min                    -0.588872
Policy log std Mean              -0.142048
Policy log std Std                0.0237523
Policy log std Max               -0.0794876
Policy log std Min               -0.274807
Test Rewards Mean                 0.00179136
Test Rewards Std                  0.0038126
Test Rewards Max                  0.0138555
Test Rewards Min                 -0.00171195
Test Returns Mean                 0.116965
Test Returns Std                  0.238227
Test Returns Max                  0.657444
Test Returns Min                 -0.00750696
Test Actions Mean                -0.0208803
Test Actions Std                  0.262948
Test Actions Max                  0.732328
Test Actions Min                 -0.669964
Num Paths                         9
Exploration Rewards Mean         -0.00618681
Exploration Rewards Std           0.00750893
Exploration Rewards Max           0.0065352
Exploration Rewards Min          -0.021248
Exploration Returns Mean         -0.807723
Exploration Returns Std           0.0117749
Exploration Returns Max          -0.794461
Exploration Returns Min          -0.836349
Exploration Actions Mean          0.0215079
Exploration Actions Std           0.594034
Exploration Actions Max           0.997412
Exploration Actions Min          -0.998206
AverageReturn                     0.116965
Number of train steps total  230844
Number of env steps total    231000
Number of rollouts total       1883
Train Time (s)                   20.0036
(Previous) Eval Time (s)          2.432e-06
Sample Time (s)                  16.1762
Epoch Time (s)                   36.1797
Total Train Time (s)          24938.5
Epoch                           230
---------------------------  ---------------
2018-05-16 03:23:52.186457 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #230 | Epoch Duration: 368.3836131095886
2018-05-16 03:23:52.186610 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #230 | Started Training: True
2018-05-16 03:26:48.571070 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #231 | Epoch Duration: 176.38433265686035
2018-05-16 03:26:48.571288 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #231 | Started Training: True
2018-05-16 03:29:45.957786 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #232 | Epoch Duration: 177.38637781143188
2018-05-16 03:29:45.958043 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #232 | Started Training: True
2018-05-16 03:31:20.506642 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #233 | Epoch Duration: 94.5484561920166
2018-05-16 03:31:20.506940 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #233 | Started Training: True
2018-05-16 03:31:57.021917 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #234 | Epoch Duration: 36.514814615249634
2018-05-16 03:31:57.022608 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #234 | Started Training: True
2018-05-16 03:32:33.147550 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #235 | Epoch Duration: 36.12480902671814
2018-05-16 03:32:33.147838 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #235 | Started Training: True
2018-05-16 03:33:09.652969 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #236 | Epoch Duration: 36.504953145980835
2018-05-16 03:33:09.653251 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #236 | Started Training: True
2018-05-16 03:33:44.910654 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #237 | Epoch Duration: 35.25722885131836
2018-05-16 03:33:44.910902 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #237 | Started Training: True
2018-05-16 03:34:21.707429 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #238 | Epoch Duration: 36.796388387680054
2018-05-16 03:34:21.707698 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #238 | Started Training: True
2018-05-16 03:34:57.125870 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #239 | Epoch Duration: 35.417996406555176
2018-05-16 03:34:57.128104 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #239 | Started Training: True
2018-05-16 03:37:59.555672 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #240 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          13.9176
VF Loss                           4.14896
Policy Loss                      -3.19128
Q Predictions Mean              528.76
Q Predictions Std               246.251
Q Predictions Max               879.497
Q Predictions Min                14.335
V Predictions Mean              541.533
V Predictions Std               246.741
V Predictions Max               894.26
V Predictions Min                24.8247
Log Pis Mean                    -11.7878
Log Pis Std                       0.961401
Log Pis Max                      -8.30014
Log Pis Min                     -13.8868
Policy mu Mean                    0.039279
Policy mu Std                     0.166004
Policy mu Max                     0.768291
Policy mu Min                    -0.583834
Policy log std Mean              -0.139806
Policy log std Std                0.0215714
Policy log std Max               -0.0721422
Policy log std Min               -0.279673
Test Rewards Mean                 0.00244275
Test Rewards Std                  0.00667032
Test Rewards Max                  0.0162764
Test Rewards Min                 -0.00347387
Test Returns Mean                 0.237835
Test Returns Std                  0.260903
Test Returns Max                  0.442522
Test Returns Min                 -0.122363
Test Actions Mean                -0.0346077
Test Actions Std                  0.201603
Test Actions Max                  0.586387
Test Actions Min                 -0.481335
Num Paths                         9
Exploration Rewards Mean         -0.00613882
Exploration Rewards Std           0.00753858
Exploration Rewards Max           0.00670921
Exploration Rewards Min          -0.0212055
Exploration Returns Mean         -0.800775
Exploration Returns Std           0.0066809
Exploration Returns Max          -0.7928
Exploration Returns Min          -0.809498
Exploration Actions Mean          0.0201484
Exploration Actions Std           0.593349
Exploration Actions Max           0.998244
Exploration Actions Min          -0.996168
AverageReturn                     0.237835
Number of train steps total  240844
Number of env steps total    241000
Number of rollouts total       1959
Train Time (s)                   85.5081
(Previous) Eval Time (s)          2.557e-06
Sample Time (s)                  89.2609
Epoch Time (s)                  174.769
Total Train Time (s)          26210.1
Epoch                           240
---------------------------  ---------------
2018-05-16 03:45:04.073894 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #240 | Epoch Duration: 606.9456186294556
2018-05-16 03:45:04.074002 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #240 | Started Training: True
2018-05-16 03:45:41.067190 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #241 | Epoch Duration: 36.9930956363678
2018-05-16 03:45:41.067400 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #241 | Started Training: True
2018-05-16 03:46:16.810304 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #242 | Epoch Duration: 35.74274730682373
2018-05-16 03:46:16.812114 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #242 | Started Training: True
2018-05-16 03:46:52.578897 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #243 | Epoch Duration: 35.76660203933716
2018-05-16 03:46:52.582415 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #243 | Started Training: True
2018-05-16 03:47:28.870510 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #244 | Epoch Duration: 36.28789567947388
2018-05-16 03:47:28.871204 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #244 | Started Training: True
2018-05-16 03:48:04.659610 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #245 | Epoch Duration: 35.78818893432617
2018-05-16 03:48:04.659922 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #245 | Started Training: True
2018-05-16 03:49:09.096315 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #246 | Epoch Duration: 64.43621683120728
2018-05-16 03:49:09.097660 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #246 | Started Training: True
2018-05-16 03:52:08.250662 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #247 | Epoch Duration: 179.1528024673462
2018-05-16 03:52:08.251943 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #247 | Started Training: True
2018-05-16 03:55:08.235175 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #248 | Epoch Duration: 179.9830505847931
2018-05-16 03:55:08.235385 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #248 | Started Training: True
2018-05-16 03:58:09.506033 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #249 | Epoch Duration: 181.27052903175354
2018-05-16 03:58:09.506296 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #249 | Started Training: True
2018-05-16 04:01:14.137079 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #250 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           7.83115
VF Loss                           4.35387
Policy Loss                      10.4284
Q Predictions Mean              544.905
Q Predictions Std               257.502
Q Predictions Max               880.886
Q Predictions Min                -1.89439
V Predictions Mean              556.665
V Predictions Std               257.777
V Predictions Max               891.654
V Predictions Min                10.9713
Log Pis Mean                    -11.9739
Log Pis Std                       1.10012
Log Pis Max                      -8.24056
Log Pis Min                     -14.847
Policy mu Mean                    0.0369332
Policy mu Std                     0.193175
Policy mu Max                     0.792455
Policy mu Min                    -0.51103
Policy log std Mean              -0.144894
Policy log std Std                0.0260562
Policy log std Max               -0.066955
Policy log std Min               -0.296798
Test Rewards Mean                -0.0013433
Test Rewards Std                  0.00446385
Test Rewards Max                  0.0160507
Test Rewards Min                 -0.00506321
Test Returns Mean                -0.0889099
Test Returns Std                  0.194384
Test Returns Max                  0.430908
Test Returns Min                 -0.179545
Test Actions Mean                -0.01797
Test Actions Std                  0.154896
Test Actions Max                  0.346386
Test Actions Min                 -0.365133
Num Paths                         7
Exploration Rewards Mean         -0.00603708
Exploration Rewards Std           0.00753026
Exploration Rewards Max           0.00734989
Exploration Rewards Min          -0.0208747
Exploration Returns Mean         -0.802932
Exploration Returns Std           0.0110091
Exploration Returns Max          -0.781945
Exploration Returns Min          -0.814969
Exploration Actions Mean          0.0235081
Exploration Actions Std           0.595057
Exploration Actions Max           0.998105
Exploration Actions Min          -0.9993
AverageReturn                    -0.0889099
Number of train steps total  250844
Number of env steps total    251000
Number of rollouts total       2034
Train Time (s)                   84.5782
(Previous) Eval Time (s)          2.795e-06
Sample Time (s)                  92.2635
Epoch Time (s)                  176.842
Total Train Time (s)          27553.4
Epoch                           250
---------------------------  ---------------
2018-05-16 04:07:27.555212 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #250 | Epoch Duration: 558.0485398769379
2018-05-16 04:07:27.555323 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #250 | Started Training: True
2018-05-16 04:08:04.338778 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #251 | Epoch Duration: 36.783347606658936
2018-05-16 04:08:04.338989 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #251 | Started Training: True
2018-05-16 04:08:46.704184 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #252 | Epoch Duration: 42.36503863334656
2018-05-16 04:08:46.704447 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #252 | Started Training: True
2018-05-16 04:11:42.148062 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #253 | Epoch Duration: 175.4434792995453
2018-05-16 04:11:42.148274 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #253 | Started Training: True
2018-05-16 04:14:40.276263 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #254 | Epoch Duration: 178.12787222862244
2018-05-16 04:14:40.276515 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #254 | Started Training: True
2018-05-16 04:17:37.990981 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #255 | Epoch Duration: 177.71433091163635
2018-05-16 04:17:37.991225 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #255 | Started Training: True
2018-05-16 04:20:36.659763 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #256 | Epoch Duration: 178.66837358474731
2018-05-16 04:20:36.659981 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #256 | Started Training: True
2018-05-16 04:23:33.544824 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #257 | Epoch Duration: 176.88467121124268
2018-05-16 04:23:33.545089 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #257 | Started Training: True
2018-05-16 04:26:36.136826 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #258 | Epoch Duration: 182.59160709381104
2018-05-16 04:26:36.137067 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #258 | Started Training: True
2018-05-16 04:29:33.287154 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #259 | Epoch Duration: 177.14996337890625
2018-05-16 04:29:33.287412 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #259 | Started Training: True
2018-05-16 04:32:40.883583 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #260 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           7.97637
VF Loss                           4.47151
Policy Loss                       0.49615
Q Predictions Mean              568.653
Q Predictions Std               254.96
Q Predictions Max               886.535
Q Predictions Min                 2.6732
V Predictions Mean              581.115
V Predictions Std               255.228
V Predictions Max               892.842
V Predictions Min                12.4119
Log Pis Mean                    -12.0372
Log Pis Std                       1.04722
Log Pis Max                      -9.77316
Log Pis Min                     -15.7283
Policy mu Mean                    0.0304073
Policy mu Std                     0.163696
Policy mu Max                     0.734041
Policy mu Min                    -0.570588
Policy log std Mean              -0.141036
Policy log std Std                0.0194946
Policy log std Max               -0.0608036
Policy log std Min               -0.24763
Test Rewards Mean                -0.00319802
Test Rewards Std                  0.00169867
Test Rewards Max                  0.000599018
Test Rewards Min                 -0.00587641
Test Returns Mean                -0.118919
Test Returns Std                  0.0013757
Test Returns Max                 -0.115812
Test Returns Min                 -0.122396
Test Actions Mean                -0.0443386
Test Actions Std                  0.236553
Test Actions Max                  0.593979
Test Actions Min                 -0.570269
Num Paths                         7
Exploration Rewards Mean         -0.00599568
Exploration Rewards Std           0.00741454
Exploration Rewards Max           0.0066443
Exploration Rewards Min          -0.0209406
Exploration Returns Mean         -0.794
Exploration Returns Std           0.00658106
Exploration Returns Max          -0.782498
Exploration Returns Min          -0.802207
Exploration Actions Mean          0.0100112
Exploration Actions Std           0.595785
Exploration Actions Max           0.99866
Exploration Actions Min          -0.998992
AverageReturn                    -0.118919
Number of train steps total  260844
Number of env steps total    261000
Number of rollouts total       2108
Train Time (s)                   88.6151
(Previous) Eval Time (s)          2.98e-06
Sample Time (s)                  90.499
Epoch Time (s)                  179.114
Total Train Time (s)          29537.3
Epoch                           260
---------------------------  ----------------
2018-05-16 04:40:31.756306 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #260 | Epoch Duration: 658.4687705039978
2018-05-16 04:40:31.756419 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #260 | Started Training: True
2018-05-16 04:43:27.978767 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #261 | Epoch Duration: 176.22225069999695
2018-05-16 04:43:27.979018 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #261 | Started Training: True
2018-05-16 04:46:27.738172 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #262 | Epoch Duration: 179.75901865959167
2018-05-16 04:46:27.739405 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #262 | Started Training: True
2018-05-16 04:49:28.351470 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #263 | Epoch Duration: 180.6118516921997
2018-05-16 04:49:28.353769 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #263 | Started Training: True
2018-05-16 04:52:28.471002 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #264 | Epoch Duration: 180.11703634262085
2018-05-16 04:52:28.471255 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #264 | Started Training: True
2018-05-16 04:54:08.003784 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #265 | Epoch Duration: 99.53239297866821
2018-05-16 04:54:08.006446 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #265 | Started Training: True
2018-05-16 04:54:44.480957 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #266 | Epoch Duration: 36.47430729866028
2018-05-16 04:54:44.481170 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #266 | Started Training: True
2018-05-16 04:55:20.595312 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #267 | Epoch Duration: 36.11398458480835
2018-05-16 04:55:20.595521 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #267 | Started Training: True
2018-05-16 04:55:56.947358 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #268 | Epoch Duration: 36.35171675682068
2018-05-16 04:55:56.947628 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #268 | Started Training: True
2018-05-16 04:56:32.408029 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #269 | Epoch Duration: 35.460235357284546
2018-05-16 04:56:32.408304 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #269 | Started Training: True
2018-05-16 04:57:17.446893 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #270 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          15.7611
VF Loss                          21.8815
Policy Loss                      46.6516
Q Predictions Mean              521.35
Q Predictions Std               255.85
Q Predictions Max               878.068
Q Predictions Min                24.3157
V Predictions Mean              530.241
V Predictions Std               257.131
V Predictions Max               887.948
V Predictions Min                34.9863
Log Pis Mean                    -11.9665
Log Pis Std                       1.22544
Log Pis Max                      -8.66059
Log Pis Min                     -15.0721
Policy mu Mean                    0.042787
Policy mu Std                     0.195878
Policy mu Max                     0.787607
Policy mu Min                    -0.659566
Policy log std Mean              -0.141123
Policy log std Std                0.0192348
Policy log std Max               -0.0586475
Policy log std Min               -0.262862
Test Rewards Mean                 0.00101976
Test Rewards Std                  0.00608564
Test Rewards Max                  0.0175112
Test Rewards Min                 -0.00407455
Test Returns Mean                 0.0797765
Test Returns Std                  0.261016
Test Returns Max                  0.475726
Test Returns Min                 -0.111782
Test Actions Mean                -0.015243
Test Actions Std                  0.195684
Test Actions Max                  0.537907
Test Actions Min                 -0.486081
Num Paths                         8
Exploration Rewards Mean         -0.00597872
Exploration Rewards Std           0.00748781
Exploration Rewards Max           0.00793335
Exploration Rewards Min          -0.0209464
Exploration Returns Mean         -0.787696
Exploration Returns Std           0.00542584
Exploration Returns Max          -0.778432
Exploration Returns Min          -0.795333
Exploration Actions Mean          0.0187394
Exploration Actions Std           0.594827
Exploration Actions Max           0.998041
Exploration Actions Min          -0.99903
AverageReturn                     0.0797765
Number of train steps total  270844
Number of env steps total    271000
Number of rollouts total       2182
Train Time (s)                   20.6756
(Previous) Eval Time (s)          3.061e-06
Sample Time (s)                  16.1304
Epoch Time (s)                   36.806
Total Train Time (s)          30997.2
Epoch                           270
---------------------------  ---------------
2018-05-16 05:04:51.889846 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #270 | Epoch Duration: 499.48138880729675
2018-05-16 05:04:51.889955 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #270 | Started Training: True
2018-05-16 05:05:28.201180 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #271 | Epoch Duration: 36.31112289428711
2018-05-16 05:05:28.201450 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #271 | Started Training: True
2018-05-16 05:06:05.165606 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #272 | Epoch Duration: 36.96399283409119
2018-05-16 05:06:05.165860 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #272 | Started Training: True
2018-05-16 05:06:41.449805 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #273 | Epoch Duration: 36.28382182121277
2018-05-16 05:06:41.450077 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #273 | Started Training: True
2018-05-16 05:07:17.837974 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #274 | Epoch Duration: 36.38773155212402
2018-05-16 05:07:17.838249 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #274 | Started Training: True
2018-05-16 05:07:54.742618 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #275 | Epoch Duration: 36.90420913696289
2018-05-16 05:07:54.742833 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #275 | Started Training: True
2018-05-16 05:08:49.587160 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #276 | Epoch Duration: 54.844157218933105
2018-05-16 05:08:49.588212 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #276 | Started Training: True
2018-05-16 05:11:47.684293 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #277 | Epoch Duration: 178.09589648246765
2018-05-16 05:11:47.684551 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #277 | Started Training: True
2018-05-16 05:14:43.428904 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #278 | Epoch Duration: 175.74421167373657
2018-05-16 05:14:43.429147 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #278 | Started Training: True
2018-05-16 05:17:38.988592 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #279 | Epoch Duration: 175.55931663513184
2018-05-16 05:17:38.988848 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #279 | Started Training: True
2018-05-16 05:20:46.086872 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #280 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          31.6816
VF Loss                          33.8334
Policy Loss                      -4.12113
Q Predictions Mean              554.746
Q Predictions Std               263.764
Q Predictions Max               884.049
Q Predictions Min                -7.41234
V Predictions Mean              567.878
V Predictions Std               263.026
V Predictions Max               895.146
V Predictions Min                 7.30037
Log Pis Mean                    -11.7246
Log Pis Std                       1.29252
Log Pis Max                      -7.96922
Log Pis Min                     -14.9857
Policy mu Mean                    0.038312
Policy mu Std                     0.209799
Policy mu Max                     0.837498
Policy mu Min                    -0.665207
Policy log std Mean              -0.149413
Policy log std Std                0.029442
Policy log std Max               -0.0444571
Policy log std Min               -0.330606
Test Rewards Mean                -0.00127742
Test Rewards Std                  0.00421761
Test Rewards Max                  0.0176601
Test Rewards Min                 -0.00502854
Test Returns Mean                -0.0883813
Test Returns Std                  0.195129
Test Returns Max                  0.433024
Test Returns Min                 -0.183687
Test Actions Mean                -0.00280143
Test Actions Std                  0.20903
Test Actions Max                  0.64151
Test Actions Min                 -0.734499
Num Paths                         8
Exploration Rewards Mean         -0.00614888
Exploration Rewards Std           0.00750608
Exploration Rewards Max           0.00625252
Exploration Rewards Min          -0.0212154
Exploration Returns Mean         -0.793974
Exploration Returns Std           0.00882068
Exploration Returns Max          -0.775198
Exploration Returns Min          -0.805395
Exploration Actions Mean          0.0265017
Exploration Actions Std           0.593406
Exploration Actions Max           0.998077
Exploration Actions Min          -0.998321
AverageReturn                    -0.0883813
Number of train steps total  280844
Number of env steps total    281000
Number of rollouts total       2259
Train Time (s)                   88.4099
(Previous) Eval Time (s)          2.754e-06
Sample Time (s)                  90.1838
Epoch Time (s)                  178.594
Total Train Time (s)          32525.1
Epoch                           280
---------------------------  ---------------
2018-05-16 05:30:20.024455 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #280 | Epoch Duration: 761.0354950428009
2018-05-16 05:30:20.024570 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #280 | Started Training: True
2018-05-16 05:33:20.398607 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #281 | Epoch Duration: 180.37393736839294
2018-05-16 05:33:20.398867 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #281 | Started Training: True
2018-05-16 05:36:22.859433 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #282 | Epoch Duration: 182.4604229927063
2018-05-16 05:36:22.859690 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #282 | Started Training: True
2018-05-16 05:39:22.243035 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #283 | Epoch Duration: 179.38321328163147
2018-05-16 05:39:22.243288 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #283 | Started Training: True
2018-05-16 05:42:24.629544 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #284 | Epoch Duration: 182.3861277103424
2018-05-16 05:42:24.632784 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #284 | Started Training: True
2018-05-16 05:45:20.686769 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #285 | Epoch Duration: 176.05379056930542
2018-05-16 05:45:20.690908 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #285 | Started Training: True
2018-05-16 05:48:15.300250 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #286 | Epoch Duration: 174.6090977191925
2018-05-16 05:48:15.300502 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #286 | Started Training: True
2018-05-16 05:50:43.259659 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #287 | Epoch Duration: 147.9590322971344
2018-05-16 05:50:43.259934 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #287 | Started Training: True
2018-05-16 05:51:19.546715 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #288 | Epoch Duration: 36.286609172821045
2018-05-16 05:51:19.549165 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #288 | Started Training: True
2018-05-16 05:51:54.497536 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #289 | Epoch Duration: 34.94821834564209
2018-05-16 05:51:54.497740 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #289 | Started Training: True
2018-05-16 05:52:39.480211 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #290 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           6.27188
VF Loss                          12.1659
Policy Loss                     -26.8253
Q Predictions Mean              564.703
Q Predictions Std               252.464
Q Predictions Max               883.652
Q Predictions Min                24.147
V Predictions Mean              579.32
V Predictions Std               253.524
V Predictions Max               894.627
V Predictions Min                35.9804
Log Pis Mean                    -11.9203
Log Pis Std                       0.837632
Log Pis Max                      -9.41824
Log Pis Min                     -13.9494
Policy mu Mean                    0.0477846
Policy mu Std                     0.167902
Policy mu Max                     0.758714
Policy mu Min                    -0.570695
Policy log std Mean              -0.146276
Policy log std Std                0.0211023
Policy log std Max               -0.0344005
Policy log std Min               -0.299165
Test Rewards Mean                -0.00363534
Test Rewards Std                  0.00195896
Test Rewards Max                  0.000617946
Test Rewards Min                 -0.00651135
Test Returns Mean                -0.174497
Test Returns Std                  0.0109227
Test Returns Max                 -0.160163
Test Returns Min                 -0.196784
Test Actions Mean                -0.0535407
Test Actions Std                  0.241395
Test Actions Max                  0.479469
Test Actions Min                 -0.61663
Num Paths                         9
Exploration Rewards Mean         -0.00612467
Exploration Rewards Std           0.00756105
Exploration Rewards Max           0.00788369
Exploration Rewards Min          -0.0213817
Exploration Returns Mean         -0.794846
Exploration Returns Std           0.0106583
Exploration Returns Max          -0.777156
Exploration Returns Min          -0.809421
Exploration Actions Mean          0.0133806
Exploration Actions Std           0.597829
Exploration Actions Max           0.998162
Exploration Actions Min          -0.998144
AverageReturn                    -0.174497
Number of train steps total  290844
Number of env steps total    291000
Number of rollouts total       2335
Train Time (s)                   20.7534
(Previous) Eval Time (s)          1.887e-06
Sample Time (s)                  15.7463
Epoch Time (s)                   36.4996
Total Train Time (s)          34396.1
Epoch                           290
---------------------------  ----------------
2018-05-16 06:01:31.261161 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #290 | Epoch Duration: 576.7633159160614
2018-05-16 06:01:31.261275 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #290 | Started Training: True
2018-05-16 06:02:17.437709 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #291 | Epoch Duration: 46.17633819580078
2018-05-16 06:02:17.437927 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #291 | Started Training: True
2018-05-16 06:02:54.082581 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #292 | Epoch Duration: 36.64450120925903
2018-05-16 06:02:54.082786 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #292 | Started Training: True
2018-05-16 06:03:30.210781 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #293 | Epoch Duration: 36.12787365913391
2018-05-16 06:03:30.211052 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #293 | Started Training: True
2018-05-16 06:04:06.792654 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #294 | Epoch Duration: 36.58107042312622
2018-05-16 06:04:06.793391 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #294 | Started Training: True
2018-05-16 06:04:42.949542 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #295 | Epoch Duration: 36.1559796333313
2018-05-16 06:04:42.949760 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #295 | Started Training: True
2018-05-16 06:05:19.377099 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #296 | Epoch Duration: 36.426886558532715
2018-05-16 06:05:19.377371 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #296 | Started Training: True
2018-05-16 06:06:36.621374 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #297 | Epoch Duration: 77.24384069442749
2018-05-16 06:06:36.621636 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #297 | Started Training: True
2018-05-16 06:09:37.146405 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #298 | Epoch Duration: 180.5246353149414
2018-05-16 06:09:37.146660 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #298 | Started Training: True
2018-05-16 06:12:37.019200 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #299 | Epoch Duration: 179.87241578102112
2018-05-16 06:12:37.019459 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #299 | Started Training: True
2018-05-16 06:15:45.685652 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #300 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           7.36125
VF Loss                           3.50272
Policy Loss                      14.9503
Q Predictions Mean              474.846
Q Predictions Std               278.115
Q Predictions Max               877.164
Q Predictions Min                 3.54155
V Predictions Mean              485.871
V Predictions Std               277.963
V Predictions Max               889.835
V Predictions Min                11.8085
Log Pis Mean                    -11.8627
Log Pis Std                       0.909953
Log Pis Max                      -8.81924
Log Pis Min                     -15.1128
Policy mu Mean                    0.0183235
Policy mu Std                     0.155266
Policy mu Max                     0.72574
Policy mu Min                    -0.654796
Policy log std Mean              -0.136433
Policy log std Std                0.0199889
Policy log std Max               -0.0542697
Policy log std Min               -0.285723
Test Rewards Mean                -0.00285491
Test Rewards Std                  0.00163266
Test Rewards Max                  0.000612795
Test Rewards Min                 -0.00533783
Test Returns Mean                -0.123713
Test Returns Std                  0.00171733
Test Returns Max                 -0.121217
Test Returns Min                 -0.127233
Test Actions Mean                -0.0426086
Test Actions Std                  0.218261
Test Actions Max                  0.462364
Test Actions Min                 -0.567131
Num Paths                         7
Exploration Rewards Mean         -0.00611711
Exploration Rewards Std           0.00753712
Exploration Rewards Max           0.00726244
Exploration Rewards Min          -0.0214633
Exploration Returns Mean         -0.789981
Exploration Returns Std           0.00883547
Exploration Returns Max          -0.775932
Exploration Returns Min          -0.802585
Exploration Actions Mean          0.0120394
Exploration Actions Std           0.594077
Exploration Actions Max           0.998683
Exploration Actions Min          -0.998192
AverageReturn                    -0.123713
Number of train steps total  300844
Number of env steps total    301000
Number of rollouts total       2412
Train Time (s)                   89.7472
(Previous) Eval Time (s)          2.918e-06
Sample Time (s)                  89.9067
Epoch Time (s)                  179.654
Total Train Time (s)          35739.6
Epoch                           300
---------------------------  ----------------
2018-05-16 06:23:55.005903 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #300 | Epoch Duration: 677.9863169193268
2018-05-16 06:23:55.006014 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #300 | Started Training: True
2018-05-16 06:26:56.010291 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #301 | Epoch Duration: 181.00417613983154
2018-05-16 06:26:56.010567 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #301 | Started Training: True
2018-05-16 06:29:51.784874 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #302 | Epoch Duration: 175.77417087554932
2018-05-16 06:29:51.785140 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #302 | Started Training: True
2018-05-16 06:32:49.762189 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #303 | Epoch Duration: 177.97692680358887
2018-05-16 06:32:49.762458 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #303 | Started Training: True
2018-05-16 06:35:47.021290 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #304 | Epoch Duration: 177.25869512557983
2018-05-16 06:35:47.021545 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #304 | Started Training: True
2018-05-16 06:38:44.608476 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #305 | Epoch Duration: 177.58680939674377
2018-05-16 06:38:44.608721 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #305 | Started Training: True
2018-05-16 06:41:42.067829 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #306 | Epoch Duration: 177.45898151397705
2018-05-16 06:41:42.069273 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #306 | Started Training: True
2018-05-16 06:44:34.976195 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #307 | Epoch Duration: 172.9067325592041
2018-05-16 06:44:34.976417 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #307 | Started Training: True
2018-05-16 06:47:37.093989 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #308 | Epoch Duration: 182.11739587783813
2018-05-16 06:47:37.094359 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #308 | Started Training: True
2018-05-16 06:48:14.411155 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #309 | Epoch Duration: 37.31653928756714
2018-05-16 06:48:14.411367 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #309 | Started Training: True
2018-05-16 06:48:59.060107 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #310 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           5.95261
VF Loss                           2.56511
Policy Loss                      -8.35792
Q Predictions Mean              553.935
Q Predictions Std               252.051
Q Predictions Max               891.038
Q Predictions Min                -1.83655
V Predictions Mean              567.084
V Predictions Std               251.413
V Predictions Max               905.275
V Predictions Min                13.0756
Log Pis Mean                    -12.0351
Log Pis Std                       1.06246
Log Pis Max                      -6.47693
Log Pis Min                     -14.7039
Policy mu Mean                    0.0102151
Policy mu Std                     0.157758
Policy mu Max                     0.791039
Policy mu Min                    -0.681996
Policy log std Mean              -0.138819
Policy log std Std                0.0196409
Policy log std Max               -0.0646515
Policy log std Min               -0.284051
Test Rewards Mean                -0.00366193
Test Rewards Std                  0.00193341
Test Rewards Max                  0.000596697
Test Rewards Min                 -0.00637683
Test Returns Mean                -0.151751
Test Returns Std                  0.00341168
Test Returns Max                 -0.147031
Test Returns Min                 -0.15779
Test Actions Mean                -0.0349155
Test Actions Std                  0.219723
Test Actions Max                  0.493702
Test Actions Min                 -0.545782
Num Paths                         8
Exploration Rewards Mean         -0.00619925
Exploration Rewards Std           0.00756922
Exploration Rewards Max           0.00701365
Exploration Rewards Min          -0.0212083
Exploration Returns Mean         -0.798153
Exploration Returns Std           0.00812853
Exploration Returns Max          -0.783461
Exploration Returns Min          -0.808379
Exploration Actions Mean          0.0125578
Exploration Actions Std           0.593129
Exploration Actions Max           0.997024
Exploration Actions Min          -0.998419
AverageReturn                    -0.151751
Number of train steps total  310844
Number of env steps total    311000
Number of rollouts total       2488
Train Time (s)                   20.3851
(Previous) Eval Time (s)          1.905e-06
Sample Time (s)                  15.3491
Epoch Time (s)                   35.7342
Total Train Time (s)          37780.1
Epoch                           310
---------------------------  ----------------
2018-05-16 06:57:55.747163 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #310 | Epoch Duration: 581.335643529892
2018-05-16 06:57:55.747277 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #310 | Started Training: True
2018-05-16 07:01:50.188682 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #311 | Epoch Duration: 234.4413046836853
2018-05-16 07:01:50.188929 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #311 | Started Training: True
2018-05-16 07:04:20.781829 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #312 | Epoch Duration: 150.5927655696869
2018-05-16 07:04:20.782030 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #312 | Started Training: True
2018-05-16 07:04:58.595728 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #313 | Epoch Duration: 37.81354022026062
2018-05-16 07:04:58.599198 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #313 | Started Training: True
2018-05-16 07:05:36.746803 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #314 | Epoch Duration: 38.14742350578308
2018-05-16 07:05:36.747021 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #314 | Started Training: True
2018-05-16 07:06:15.059675 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #315 | Epoch Duration: 38.3124942779541
2018-05-16 07:06:15.062481 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #315 | Started Training: True
2018-05-16 07:06:53.481279 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #316 | Epoch Duration: 38.41856932640076
2018-05-16 07:06:53.483878 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #316 | Started Training: True
2018-05-16 07:07:31.769845 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #317 | Epoch Duration: 38.28574728965759
2018-05-16 07:07:31.770094 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #317 | Started Training: True
2018-05-16 07:08:49.963337 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #318 | Epoch Duration: 78.1931083202362
2018-05-16 07:08:49.963620 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #318 | Started Training: True
2018-05-16 07:11:59.197873 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #319 | Epoch Duration: 189.23407316207886
2018-05-16 07:11:59.198127 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #319 | Started Training: True
2018-05-16 07:15:08.923304 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #320 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           4.57664
VF Loss                           1.95428
Policy Loss                      -8.10363
Q Predictions Mean              505.633
Q Predictions Std               269.582
Q Predictions Max               889.021
Q Predictions Min                23.7964
V Predictions Mean              518.681
V Predictions Std               269.725
V Predictions Max               899.551
V Predictions Min                38.0596
Log Pis Mean                    -12.0544
Log Pis Std                       0.876896
Log Pis Max                      -7.79595
Log Pis Min                     -14.6677
Policy mu Mean                    0.0238335
Policy mu Std                     0.14092
Policy mu Max                     0.878482
Policy mu Min                    -0.600839
Policy log std Mean              -0.139371
Policy log std Std                0.0140607
Policy log std Max               -0.086525
Policy log std Min               -0.266655
Test Rewards Mean                 0.00296244
Test Rewards Std                  0.00569143
Test Rewards Max                  0.0158188
Test Rewards Min                 -0.00433253
Test Returns Mean                 0.438441
Test Returns Std                  0.00355883
Test Returns Max                  0.442421
Test Returns Min                  0.432137
Test Actions Mean                -0.0825286
Test Actions Std                  0.279646
Test Actions Max                  0.642393
Test Actions Min                 -0.871607
Num Paths                         8
Exploration Rewards Mean         -0.00615994
Exploration Rewards Std           0.00754562
Exploration Rewards Max           0.00623255
Exploration Rewards Min          -0.0213922
Exploration Returns Mean         -0.800022
Exploration Returns Std           0.00701244
Exploration Returns Max          -0.792063
Exploration Returns Min          -0.813236
Exploration Actions Mean          0.00648435
Exploration Actions Std           0.594003
Exploration Actions Max           0.998019
Exploration Actions Min          -0.996171
AverageReturn                     0.438441
Number of train steps total  320844
Number of env steps total    321000
Number of rollouts total       2565
Train Time (s)                   88.3175
(Previous) Eval Time (s)          2.858e-06
Sample Time (s)                  91.8991
Epoch Time (s)                  180.217
Total Train Time (s)          39073.8
Epoch                           320
---------------------------  ---------------
2018-05-16 07:19:29.631365 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #320 | Epoch Duration: 450.43312668800354
2018-05-16 07:19:29.631478 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #320 | Started Training: True
2018-05-16 07:22:57.059756 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #321 | Epoch Duration: 207.4281702041626
2018-05-16 07:22:57.060036 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #321 | Started Training: True
2018-05-16 07:23:56.395153 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #322 | Epoch Duration: 59.33495330810547
2018-05-16 07:23:56.396201 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #322 | Started Training: True
2018-05-16 07:24:34.683573 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #323 | Epoch Duration: 38.28722548484802
2018-05-16 07:24:34.683816 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #323 | Started Training: True
2018-05-16 07:25:12.870937 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #324 | Epoch Duration: 38.18698287010193
2018-05-16 07:25:12.875538 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #324 | Started Training: True
2018-05-16 07:25:49.112967 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #325 | Epoch Duration: 36.237189292907715
2018-05-16 07:25:49.113197 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #325 | Started Training: True
2018-05-16 07:26:25.910894 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #326 | Epoch Duration: 36.79755234718323
2018-05-16 07:26:25.912122 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #326 | Started Training: True
2018-05-16 07:27:02.090927 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #327 | Epoch Duration: 36.17853784561157
2018-05-16 07:27:02.093118 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #327 | Started Training: True
2018-05-16 07:27:38.315126 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #328 | Epoch Duration: 36.22183918952942
2018-05-16 07:27:38.318420 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #328 | Started Training: True
2018-05-16 07:29:14.778037 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #329 | Epoch Duration: 96.45942187309265
2018-05-16 07:29:14.778256 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #329 | Started Training: True
2018-05-16 07:32:50.757525 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #330 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          16.7005
VF Loss                          20.0962
Policy Loss                     -49.2784
Q Predictions Mean              569.981
Q Predictions Std               232.592
Q Predictions Max               887.404
Q Predictions Min                31.9664
V Predictions Mean              586.695
V Predictions Std               232.861
V Predictions Max               904.267
V Predictions Min                44.8546
Log Pis Mean                    -12.0023
Log Pis Std                       0.898016
Log Pis Max                      -8.732
Log Pis Min                     -14.419
Policy mu Mean                    0.0124461
Policy mu Std                     0.162601
Policy mu Max                     0.836925
Policy mu Min                    -0.58046
Policy log std Mean              -0.142281
Policy log std Std                0.0180778
Policy log std Max               -0.0906216
Policy log std Min               -0.273829
Test Rewards Mean                 0.00103595
Test Rewards Std                  0.00562777
Test Rewards Max                  0.0161931
Test Rewards Min                 -0.00592993
Test Returns Mean                 0.118927
Test Returns Std                  0.311692
Test Returns Max                  0.4433
Test Returns Min                 -0.207623
Test Actions Mean                -0.0777208
Test Actions Std                  0.335402
Test Actions Max                  0.877092
Test Actions Min                 -0.929398
Num Paths                         9
Exploration Rewards Mean         -0.00620796
Exploration Rewards Std           0.00754599
Exploration Rewards Max           0.00667884
Exploration Rewards Min          -0.0213393
Exploration Returns Mean         -0.795308
Exploration Returns Std           0.0113925
Exploration Returns Max          -0.782217
Exploration Returns Min          -0.822099
Exploration Actions Mean          0.0130731
Exploration Actions Std           0.590211
Exploration Actions Max           0.997329
Exploration Actions Min          -0.999662
AverageReturn                     0.118927
Number of train steps total  330844
Number of env steps total    331000
Number of rollouts total       2643
Train Time (s)                   98.252
(Previous) Eval Time (s)          2.368e-06
Sample Time (s)                 107.966
Epoch Time (s)                  206.218
Total Train Time (s)          40541.4
Epoch                           330
---------------------------  ---------------
2018-05-16 07:43:57.529935 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #330 | Epoch Duration: 882.7515625953674
2018-05-16 07:43:57.530086 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #330 | Started Training: True
2018-05-16 07:46:54.441756 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #331 | Epoch Duration: 176.91154217720032
2018-05-16 07:46:54.442003 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #331 | Started Training: True
2018-05-16 07:49:57.716771 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #332 | Epoch Duration: 183.27463150024414
2018-05-16 07:49:57.717021 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #332 | Started Training: True
2018-05-16 07:52:56.852304 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #333 | Epoch Duration: 179.13514828681946
2018-05-16 07:52:56.852544 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #333 | Started Training: True
2018-05-16 07:55:57.590732 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #334 | Epoch Duration: 180.73805570602417
2018-05-16 07:55:57.590974 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #334 | Started Training: True
2018-05-16 07:58:54.408340 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #335 | Epoch Duration: 176.81723022460938
2018-05-16 07:58:54.408591 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #335 | Started Training: True
2018-05-16 08:01:52.492948 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #336 | Epoch Duration: 178.084223985672
2018-05-16 08:01:52.493154 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #336 | Started Training: True
2018-05-16 08:04:52.896766 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #337 | Epoch Duration: 180.40348887443542
2018-05-16 08:04:52.897022 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #337 | Started Training: True
2018-05-16 08:07:51.861274 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #338 | Epoch Duration: 178.9641284942627
2018-05-16 08:07:51.861506 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #338 | Started Training: True
2018-05-16 08:09:17.318094 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #339 | Epoch Duration: 85.45646667480469
2018-05-16 08:09:17.318296 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #339 | Started Training: True
2018-05-16 08:10:04.305226 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #340 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          37.4447
VF Loss                          50.3663
Policy Loss                     -79.158
Q Predictions Mean              489.446
Q Predictions Std               261.931
Q Predictions Max               883.769
Q Predictions Min                -3.47728
V Predictions Mean              508.336
V Predictions Std               262.812
V Predictions Max               895.239
V Predictions Min                11.6056
Log Pis Mean                    -12.0055
Log Pis Std                       0.921011
Log Pis Max                      -8.40101
Log Pis Min                     -14.2249
Policy mu Mean                    0.0224666
Policy mu Std                     0.153445
Policy mu Max                     0.880332
Policy mu Min                    -0.633449
Policy log std Mean              -0.142461
Policy log std Std                0.0193358
Policy log std Max               -0.0673029
Policy log std Min               -0.307703
Test Rewards Mean                -0.00231751
Test Rewards Std                  0.00373631
Test Rewards Max                  0.0162988
Test Rewards Min                 -0.00637588
Test Returns Mean                -0.12295
Test Returns Std                  0.125916
Test Returns Max                  0.410552
Test Returns Min                 -0.169262
Test Actions Mean                -0.0461052
Test Actions Std                  0.274862
Test Actions Max                  0.806484
Test Actions Min                 -0.941124
Num Paths                         8
Exploration Rewards Mean         -0.00563654
Exploration Rewards Std           0.00743649
Exploration Rewards Max           0.00694153
Exploration Rewards Min          -0.021383
Exploration Returns Mean         -0.796866
Exploration Returns Std           0.00731656
Exploration Returns Max          -0.781005
Exploration Returns Min          -0.808682
Exploration Actions Mean          0.00902182
Exploration Actions Std           0.597436
Exploration Actions Max           0.997921
Exploration Actions Min          -0.997893
AverageReturn                    -0.12295
Number of train steps total  340844
Number of env steps total    341000
Number of rollouts total       2717
Train Time (s)                   20.8182
(Previous) Eval Time (s)          2.031e-06
Sample Time (s)                  16.612
Epoch Time (s)                   37.4302
Total Train Time (s)          42667.1
Epoch                           340
---------------------------  ---------------
2018-05-16 08:19:23.400555 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #340 | Epoch Duration: 606.082097530365
2018-05-16 08:19:23.400668 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #340 | Started Training: True
2018-05-16 08:22:22.175525 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #341 | Epoch Duration: 178.77475690841675
2018-05-16 08:22:22.175776 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #341 | Started Training: True
2018-05-16 08:23:00.687414 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #342 | Epoch Duration: 38.51149940490723
2018-05-16 08:23:00.687656 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #342 | Started Training: True
2018-05-16 08:23:36.523158 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #343 | Epoch Duration: 35.834922313690186
2018-05-16 08:23:36.523367 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #343 | Started Training: True
2018-05-16 08:24:13.742357 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #344 | Epoch Duration: 37.21883583068848
2018-05-16 08:24:13.746170 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #344 | Started Training: True
2018-05-16 08:24:50.074500 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #345 | Epoch Duration: 36.32814621925354
2018-05-16 08:24:50.075459 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #345 | Started Training: True
2018-05-16 08:25:27.038974 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #346 | Epoch Duration: 36.963358640670776
2018-05-16 08:25:27.039220 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #346 | Started Training: True
2018-05-16 08:26:03.478063 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #347 | Epoch Duration: 36.438716888427734
2018-05-16 08:26:03.478263 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #347 | Started Training: True
2018-05-16 08:27:22.228507 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #348 | Epoch Duration: 78.75012159347534
2018-05-16 08:27:22.228836 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #348 | Started Training: True
2018-05-16 08:30:23.098756 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #349 | Epoch Duration: 180.8697383403778
2018-05-16 08:30:23.098980 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #349 | Started Training: True
2018-05-16 08:33:34.158308 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #350 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           8.73796
VF Loss                           3.87726
Policy Loss                     -10.7768
Q Predictions Mean              526.929
Q Predictions Std               247.253
Q Predictions Max               877.683
Q Predictions Min                -1.97327
V Predictions Mean              540.327
V Predictions Std               247.114
V Predictions Max               889.821
V Predictions Min                11.2932
Log Pis Mean                    -11.9421
Log Pis Std                       0.97217
Log Pis Max                      -7.39463
Log Pis Min                     -14.2344
Policy mu Mean                    0.041841
Policy mu Std                     0.153403
Policy mu Max                     0.859256
Policy mu Min                    -0.663441
Policy log std Mean              -0.133351
Policy log std Std                0.0201583
Policy log std Max               -0.0401894
Policy log std Min               -0.258577
Test Rewards Mean                -0.00194652
Test Rewards Std                  0.00530043
Test Rewards Max                  0.0166635
Test Rewards Min                 -0.00863907
Test Returns Mean                -0.168374
Test Returns Std                  0.267763
Test Returns Max                  0.389192
Test Returns Min                 -0.604419
Test Actions Mean                -0.0580987
Test Actions Std                  0.254687
Test Actions Max                  0.541845
Test Actions Min                 -0.878514
Num Paths                         8
Exploration Rewards Mean         -0.00623511
Exploration Rewards Std           0.00758746
Exploration Rewards Max           0.00763654
Exploration Rewards Min          -0.0212582
Exploration Returns Mean         -0.796536
Exploration Returns Std           0.0036471
Exploration Returns Max          -0.790827
Exploration Returns Min          -0.802912
Exploration Actions Mean          0.016001
Exploration Actions Std           0.590414
Exploration Actions Max           0.997052
Exploration Actions Min          -0.999555
AverageReturn                    -0.168374
Number of train steps total  350844
Number of env steps total    351000
Number of rollouts total       2796
Train Time (s)                   88.1301
(Previous) Eval Time (s)          2.629e-06
Sample Time (s)                  93.0987
Epoch Time (s)                  181.229
Total Train Time (s)          44187.7
Epoch                           350
---------------------------  ---------------
2018-05-16 08:44:44.303084 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #350 | Epoch Duration: 861.2039897441864
2018-05-16 08:44:44.303200 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #350 | Started Training: True
2018-05-16 08:47:47.605649 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #351 | Epoch Duration: 183.3023476600647
2018-05-16 08:47:47.605905 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #351 | Started Training: True
2018-05-16 08:50:44.634278 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #352 | Epoch Duration: 177.02825045585632
2018-05-16 08:50:44.634500 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #352 | Started Training: True
2018-05-16 08:53:42.719420 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #353 | Epoch Duration: 178.0847463607788
2018-05-16 08:53:42.722546 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #353 | Started Training: True
2018-05-16 08:56:44.028182 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #354 | Epoch Duration: 181.30547547340393
2018-05-16 08:56:44.028382 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #354 | Started Training: True
2018-05-16 08:59:48.243960 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #355 | Epoch Duration: 184.21545386314392
2018-05-16 08:59:48.246405 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #355 | Started Training: True
2018-05-16 09:02:37.555166 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #356 | Epoch Duration: 169.30858945846558
2018-05-16 09:02:37.555445 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #356 | Started Training: True
2018-05-16 09:03:13.985397 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #357 | Epoch Duration: 36.42953968048096
2018-05-16 09:03:13.985607 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #357 | Started Training: True
2018-05-16 09:03:50.093976 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #358 | Epoch Duration: 36.10822081565857
2018-05-16 09:03:50.094181 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #358 | Started Training: True
2018-05-16 09:04:26.964938 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #359 | Epoch Duration: 36.87064456939697
2018-05-16 09:04:26.965149 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #359 | Started Training: True
2018-05-16 09:05:13.413844 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #360 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                          17.5319
VF Loss                          14.993
Policy Loss                     -25.8049
Q Predictions Mean              560.47
Q Predictions Std               237.296
Q Predictions Max               861.306
Q Predictions Min                 6.75385
V Predictions Mean              575.025
V Predictions Std               237.442
V Predictions Max               886.765
V Predictions Min                23.0507
Log Pis Mean                    -11.8805
Log Pis Std                       1.02592
Log Pis Max                      -6.5549
Log Pis Min                     -13.9516
Policy mu Mean                    0.0377492
Policy mu Std                     0.170953
Policy mu Max                     0.875091
Policy mu Min                    -0.627363
Policy log std Mean              -0.136882
Policy log std Std                0.0209675
Policy log std Max               -0.0732602
Policy log std Min               -0.266106
Test Rewards Mean                -0.00451178
Test Rewards Std                  0.00345059
Test Rewards Max                  0.000633953
Test Rewards Min                 -0.0126563
Test Returns Mean                -0.607962
Test Returns Std                  0.0110084
Test Returns Max                 -0.59187
Test Returns Min                 -0.621864
Test Actions Mean                -0.0686784
Test Actions Std                  0.264431
Test Actions Max                  0.709571
Test Actions Min                 -0.708435
Num Paths                         7
Exploration Rewards Mean         -0.00610026
Exploration Rewards Std           0.00757076
Exploration Rewards Max           0.00646735
Exploration Rewards Min          -0.0211878
Exploration Returns Mean         -0.800877
Exploration Returns Std           0.0138114
Exploration Returns Max          -0.783006
Exploration Returns Min          -0.829535
Exploration Actions Mean          0.0266919
Exploration Actions Std           0.593489
Exploration Actions Max           0.99776
Exploration Actions Min          -0.997355
AverageReturn                    -0.607962
Number of train steps total  360844
Number of env steps total    361000
Number of rollouts total       2870
Train Time (s)                   20.7976
(Previous) Eval Time (s)          2.047e-06
Sample Time (s)                  15.6211
Epoch Time (s)                   36.4186
Total Train Time (s)          46055.6
Epoch                           360
---------------------------  ----------------
2018-05-16 09:15:52.371835 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #360 | Epoch Duration: 685.4065427780151
2018-05-16 09:15:52.371948 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #360 | Started Training: True
2018-05-16 09:16:29.943668 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #361 | Epoch Duration: 37.57160687446594
2018-05-16 09:16:29.943881 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #361 | Started Training: True
2018-05-16 09:17:06.390217 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #362 | Epoch Duration: 36.44618582725525
2018-05-16 09:17:06.390455 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #362 | Started Training: True
2018-05-16 09:17:42.812110 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #363 | Epoch Duration: 36.42153286933899
2018-05-16 09:17:42.812324 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #363 | Started Training: True
2018-05-16 09:19:57.564171 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #364 | Epoch Duration: 134.75168991088867
2018-05-16 09:19:57.564412 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #364 | Started Training: True
2018-05-16 09:22:58.143991 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #365 | Epoch Duration: 180.57945728302002
2018-05-16 09:22:58.144237 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #365 | Started Training: True
2018-05-16 09:26:01.052308 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #366 | Epoch Duration: 182.90792608261108
2018-05-16 09:26:01.052556 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #366 | Started Training: True
2018-05-16 09:29:01.000932 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #367 | Epoch Duration: 179.94824123382568
2018-05-16 09:29:01.001207 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #367 | Started Training: True
2018-05-16 09:32:29.717791 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #368 | Epoch Duration: 208.71642351150513
2018-05-16 09:32:29.718043 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #368 | Started Training: True
2018-05-16 09:35:35.571355 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #369 | Epoch Duration: 185.85318803787231
2018-05-16 09:35:35.571604 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #369 | Started Training: True
2018-05-16 09:38:46.459293 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #370 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           7.10386
VF Loss                           6.56817
Policy Loss                      21.631
Q Predictions Mean              530.916
Q Predictions Std               253.264
Q Predictions Max               878.389
Q Predictions Min                 3.58883
V Predictions Mean              541.305
V Predictions Std               252.338
V Predictions Max               884.31
V Predictions Min                14.1191
Log Pis Mean                    -12.0417
Log Pis Std                       0.953947
Log Pis Max                      -8.12703
Log Pis Min                     -14.7579
Policy mu Mean                    0.0298515
Policy mu Std                     0.15802
Policy mu Max                     0.948816
Policy mu Min                    -0.614497
Policy log std Mean              -0.144096
Policy log std Std                0.0208685
Policy log std Max               -0.0739525
Policy log std Min               -0.292068
Test Rewards Mean                 0.00303127
Test Rewards Std                  0.0063741
Test Rewards Max                  0.0174419
Test Rewards Min                 -0.00721829
Test Returns Mean                 0.442999
Test Returns Std                  0.00937212
Test Returns Max                  0.461926
Test Returns Min                  0.431339
Test Actions Mean                -0.0589778
Test Actions Std                  0.145939
Test Actions Max                  0.436295
Test Actions Min                 -0.5185
Num Paths                         7
Exploration Rewards Mean         -0.00612892
Exploration Rewards Std           0.00756836
Exploration Rewards Max           0.00626067
Exploration Rewards Min          -0.0214679
Exploration Returns Mean         -0.798511
Exploration Returns Std           0.00959424
Exploration Returns Max          -0.778598
Exploration Returns Min          -0.809674
Exploration Actions Mean          0.020633
Exploration Actions Std           0.591222
Exploration Actions Max           0.999385
Exploration Actions Min          -0.998608
AverageReturn                     0.442999
Number of train steps total  370844
Number of env steps total    371000
Number of rollouts total       2947
Train Time (s)                   87.4042
(Previous) Eval Time (s)          2.62599e-06
Sample Time (s)                  92.8774
Epoch Time (s)                  180.282
Total Train Time (s)          47685.7
Epoch                           370
---------------------------  ----------------
2018-05-16 09:43:02.711375 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #370 | Epoch Duration: 447.13964796066284
2018-05-16 09:43:02.711482 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #370 | Started Training: True
2018-05-16 09:43:39.505199 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #371 | Epoch Duration: 36.79361867904663
2018-05-16 09:43:39.505417 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #371 | Started Training: True
2018-05-16 09:44:16.815746 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #372 | Epoch Duration: 37.310210943222046
2018-05-16 09:44:16.818436 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #372 | Started Training: True
2018-05-16 09:44:53.105992 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #373 | Epoch Duration: 36.287344217300415
2018-05-16 09:44:53.107508 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #373 | Started Training: True
2018-05-16 09:46:58.756873 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #374 | Epoch Duration: 125.64919829368591
2018-05-16 09:46:58.757131 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #374 | Started Training: True
2018-05-16 09:50:03.432792 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #375 | Epoch Duration: 184.6755268573761
2018-05-16 09:50:03.433023 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #375 | Started Training: True
2018-05-16 09:53:11.339358 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #376 | Epoch Duration: 187.9062123298645
2018-05-16 09:53:11.342510 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #376 | Started Training: True
2018-05-16 09:56:15.022269 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #377 | Epoch Duration: 183.6795735359192
2018-05-16 09:56:15.022538 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #377 | Started Training: True
2018-05-16 09:59:17.580579 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #378 | Epoch Duration: 182.5579059123993
2018-05-16 09:59:17.583789 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #378 | Started Training: True
2018-05-16 10:02:21.347020 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #379 | Epoch Duration: 183.76302909851074
2018-05-16 10:02:21.347254 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #379 | Started Training: True
2018-05-16 10:05:33.462355 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #380 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           6.84056
VF Loss                           4.85569
Policy Loss                      -4.5762
Q Predictions Mean              507.789
Q Predictions Std               252.397
Q Predictions Max               879.104
Q Predictions Min                13.7841
V Predictions Mean              520.737
V Predictions Std               251.271
V Predictions Max               883.752
V Predictions Min                30.3529
Log Pis Mean                    -12.3193
Log Pis Std                       0.87103
Log Pis Max                      -9.26398
Log Pis Min                     -15.7406
Policy mu Mean                    0.0245623
Policy mu Std                     0.14997
Policy mu Max                     0.763823
Policy mu Min                    -0.540998
Policy log std Mean              -0.141896
Policy log std Std                0.0188416
Policy log std Max               -0.0764487
Policy log std Min               -0.27906
Test Rewards Mean                 0.00295922
Test Rewards Std                  0.00625146
Test Rewards Max                  0.017646
Test Rewards Min                 -0.00658279
Test Returns Mean                 0.443884
Test Returns Std                  0.0108862
Test Returns Max                  0.458915
Test Returns Min                  0.425933
Test Actions Mean                -0.0621501
Test Actions Std                  0.125389
Test Actions Max                  0.362139
Test Actions Min                 -0.484746
Num Paths                         8
Exploration Rewards Mean         -0.00617713
Exploration Rewards Std           0.00758829
Exploration Rewards Max           0.00652156
Exploration Rewards Min          -0.0213127
Exploration Returns Mean         -0.794534
Exploration Returns Std           0.00489514
Exploration Returns Max          -0.787582
Exploration Returns Min          -0.80091
Exploration Actions Mean          0.0262577
Exploration Actions Std           0.592259
Exploration Actions Max           0.997356
Exploration Actions Min          -0.999388
AverageReturn                     0.443884
Number of train steps total  380844
Number of env steps total    381000
Number of rollouts total       3022
Train Time (s)                   87.85
(Previous) Eval Time (s)          2.357e-06
Sample Time (s)                  93.531
Epoch Time (s)                  181.381
Total Train Time (s)          49302
Epoch                           380
---------------------------  ---------------
2018-05-16 10:09:59.251066 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #380 | Epoch Duration: 457.903697013855
2018-05-16 10:09:59.251179 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #380 | Started Training: True
2018-05-16 10:10:36.301999 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #381 | Epoch Duration: 37.050713777542114
2018-05-16 10:10:36.302203 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #381 | Started Training: True
2018-05-16 10:11:55.216299 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #382 | Epoch Duration: 78.91398334503174
2018-05-16 10:11:55.216513 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #382 | Started Training: True
2018-05-16 10:14:58.536406 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #383 | Epoch Duration: 183.31976866722107
2018-05-16 10:14:58.536688 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #383 | Started Training: True
2018-05-16 10:17:59.880846 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #384 | Epoch Duration: 181.34397745132446
2018-05-16 10:17:59.881104 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #384 | Started Training: True
2018-05-16 10:20:57.305670 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #385 | Epoch Duration: 177.4244384765625
2018-05-16 10:20:57.305955 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #385 | Started Training: True
2018-05-16 10:23:51.581947 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #386 | Epoch Duration: 174.27581334114075
2018-05-16 10:23:51.582195 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #386 | Started Training: True
2018-05-16 10:26:51.599727 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #387 | Epoch Duration: 180.0174102783203
2018-05-16 10:26:51.601844 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #387 | Started Training: True
2018-05-16 10:29:51.552676 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #388 | Epoch Duration: 179.9506640434265
2018-05-16 10:29:51.552889 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #388 | Started Training: True
2018-05-16 10:32:49.376330 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #389 | Epoch Duration: 177.82332181930542
2018-05-16 10:32:49.376591 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #389 | Started Training: True
2018-05-16 10:36:03.506298 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #390 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           4.4348
VF Loss                           5.09626
Policy Loss                     -17.2101
Q Predictions Mean              534.309
Q Predictions Std               259.434
Q Predictions Max               875.493
Q Predictions Min                 5.82354
V Predictions Mean              547.97
V Predictions Std               259.264
V Predictions Max               887.195
V Predictions Min                18.0551
Log Pis Mean                    -11.9589
Log Pis Std                       0.906682
Log Pis Max                      -8.69435
Log Pis Min                     -14.425
Policy mu Mean                    0.0329592
Policy mu Std                     0.152212
Policy mu Max                     0.743425
Policy mu Min                    -0.477867
Policy log std Mean              -0.140224
Policy log std Std                0.0156382
Policy log std Max               -0.0895215
Policy log std Min               -0.251187
Test Rewards Mean                 0.00316847
Test Rewards Std                  0.00547023
Test Rewards Max                  0.0139427
Test Rewards Min                 -0.00401943
Test Returns Mean                 0.468481
Test Returns Std                  0.00433293
Test Returns Max                  0.473876
Test Returns Min                  0.459232
Test Actions Mean                -0.0349533
Test Actions Std                  0.0973864
Test Actions Max                  0.396798
Test Actions Min                 -0.300377
Num Paths                         8
Exploration Rewards Mean         -0.00610019
Exploration Rewards Std           0.00764373
Exploration Rewards Max           0.00738952
Exploration Rewards Min          -0.0214603
Exploration Returns Mean         -0.804462
Exploration Returns Std           0.00987988
Exploration Returns Max          -0.791219
Exploration Returns Min          -0.821349
Exploration Actions Mean          0.0230654
Exploration Actions Std           0.595156
Exploration Actions Max           0.998131
Exploration Actions Min          -0.998689
AverageReturn                     0.468481
Number of train steps total  390844
Number of env steps total    391000
Number of rollouts total       3098
Train Time (s)                   89.3594
(Previous) Eval Time (s)          2.7e-06
Sample Time (s)                  93.8538
Epoch Time (s)                  183.213
Total Train Time (s)          51065.7
Epoch                           390
---------------------------  ---------------
2018-05-16 10:39:23.276910 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #390 | Epoch Duration: 393.9002079963684
2018-05-16 10:39:23.277021 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #390 | Started Training: True
2018-05-16 10:40:01.019860 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #391 | Epoch Duration: 37.74274015426636
2018-05-16 10:40:01.022889 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #391 | Started Training: True
2018-05-16 10:40:36.555945 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #392 | Epoch Duration: 35.53289008140564
2018-05-16 10:40:36.556214 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #392 | Started Training: True
2018-05-16 10:41:13.254024 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #393 | Epoch Duration: 36.6976523399353
2018-05-16 10:41:13.254237 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #393 | Started Training: True
2018-05-16 10:42:01.249533 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #394 | Epoch Duration: 47.9951388835907
2018-05-16 10:42:01.249785 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #394 | Started Training: True
2018-05-16 10:45:01.140382 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #395 | Epoch Duration: 179.8904721736908
2018-05-16 10:45:01.140629 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #395 | Started Training: True
2018-05-16 10:48:01.888695 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #396 | Epoch Duration: 180.74793696403503
2018-05-16 10:48:01.888922 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #396 | Started Training: True
2018-05-16 10:51:07.570980 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #397 | Epoch Duration: 185.68193888664246
2018-05-16 10:51:07.572460 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #397 | Started Training: True
2018-05-16 10:54:05.756243 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #398 | Epoch Duration: 178.1836211681366
2018-05-16 10:54:05.756486 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #398 | Started Training: True
2018-05-16 10:57:04.263365 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #399 | Epoch Duration: 178.50675058364868
2018-05-16 10:57:04.263613 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #399 | Started Training: True
2018-05-16 11:00:09.205405 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #400 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           3.25177
VF Loss                           3.26382
Policy Loss                      -6.93137
Q Predictions Mean              506.654
Q Predictions Std               253.685
Q Predictions Max               879.553
Q Predictions Min                 3.93814
V Predictions Mean              519.615
V Predictions Std               252.923
V Predictions Max               888.676
V Predictions Min                17.2017
Log Pis Mean                    -12.1934
Log Pis Std                       0.85688
Log Pis Max                      -8.35239
Log Pis Min                     -14.4781
Policy mu Mean                    0.0438988
Policy mu Std                     0.140262
Policy mu Max                     0.713868
Policy mu Min                    -0.463048
Policy log std Mean              -0.137771
Policy log std Std                0.014306
Policy log std Max               -0.103054
Policy log std Min               -0.235562
Test Rewards Mean                 0.00443702
Test Rewards Std                  0.00183693
Test Rewards Max                  0.00713606
Test Rewards Min                  0.000557345
Test Returns Mean                 0.369638
Test Returns Std                  0.00552608
Test Returns Max                  0.381042
Test Returns Min                  0.361705
Test Actions Mean                -0.0291486
Test Actions Std                  0.152334
Test Actions Max                  0.616402
Test Actions Min                 -0.506086
Num Paths                         8
Exploration Rewards Mean         -0.0062062
Exploration Rewards Std           0.00768213
Exploration Rewards Max           0.00728316
Exploration Rewards Min          -0.0213603
Exploration Returns Mean         -0.798272
Exploration Returns Std           0.00606782
Exploration Returns Max          -0.790776
Exploration Returns Min          -0.809765
Exploration Actions Mean          0.0240346
Exploration Actions Std           0.592967
Exploration Actions Max           0.996586
Exploration Actions Min          -0.99862
AverageReturn                     0.369638
Number of train steps total  400844
Number of env steps total    401000
Number of rollouts total       3175
Train Time (s)                   86.388
(Previous) Eval Time (s)          3.008e-06
Sample Time (s)                  87.1049
Epoch Time (s)                  173.493
Total Train Time (s)          52641.6
Epoch                           400
---------------------------  ----------------
2018-05-16 11:05:39.391231 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #400 | Epoch Duration: 515.1274955272675
2018-05-16 11:05:39.391341 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #400 | Started Training: True
2018-05-16 11:06:58.691563 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #401 | Epoch Duration: 79.3001229763031
2018-05-16 11:06:58.691809 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #401 | Started Training: True
2018-05-16 11:09:57.589957 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #402 | Epoch Duration: 178.8980233669281
2018-05-16 11:09:57.590201 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #402 | Started Training: True
2018-05-16 11:12:57.325987 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #403 | Epoch Duration: 179.73564743995667
2018-05-16 11:12:57.326260 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #403 | Started Training: True
2018-05-16 11:15:56.694565 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #404 | Epoch Duration: 179.3681285381317
2018-05-16 11:15:56.694829 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #404 | Started Training: True
2018-05-16 11:18:56.820901 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #405 | Epoch Duration: 180.1259367465973
2018-05-16 11:18:56.821146 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #405 | Started Training: True
2018-05-16 11:21:55.034731 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #406 | Epoch Duration: 178.21345734596252
2018-05-16 11:21:55.034977 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #406 | Started Training: True
2018-05-16 11:24:50.951649 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #407 | Epoch Duration: 175.91654586791992
2018-05-16 11:24:50.951921 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #407 | Started Training: True
2018-05-16 11:27:47.530128 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #408 | Epoch Duration: 176.57803988456726
2018-05-16 11:27:47.533334 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #408 | Started Training: True
2018-05-16 11:30:44.112260 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #409 | Epoch Duration: 176.57876586914062
2018-05-16 11:30:44.114212 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #409 | Started Training: True
2018-05-16 11:32:26.656497 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #410 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           6.37992
VF Loss                           5.94803
Policy Loss                      -7.22453
Q Predictions Mean              481.623
Q Predictions Std               271.205
Q Predictions Max               878.273
Q Predictions Min                -6.85286
V Predictions Mean              494.439
V Predictions Std               272.417
V Predictions Max               901.192
V Predictions Min                 4.91618
Log Pis Mean                    -12.1063
Log Pis Std                       0.778449
Log Pis Max                     -10.4519
Log Pis Min                     -14.5374
Policy mu Mean                    0.0315509
Policy mu Std                     0.13416
Policy mu Max                     0.636522
Policy mu Min                    -0.443746
Policy log std Mean              -0.135482
Policy log std Std                0.0157072
Policy log std Max                0.00569789
Policy log std Min               -0.212802
Test Rewards Mean                 0.00532932
Test Rewards Std                  0.00310983
Test Rewards Max                  0.010848
Test Rewards Min                  0.000247693
Test Returns Mean                 0.499503
Test Returns Std                  0.0331281
Test Returns Max                  0.560838
Test Returns Min                  0.452289
Test Actions Mean                -0.0310026
Test Actions Std                  0.158889
Test Actions Max                  0.713579
Test Actions Min                 -0.531167
Num Paths                         5
Exploration Rewards Mean         -0.00621069
Exploration Rewards Std           0.00762491
Exploration Rewards Max           0.00793471
Exploration Rewards Min          -0.0210166
Exploration Returns Mean         -0.793727
Exploration Returns Std           0.0103447
Exploration Returns Max          -0.783255
Exploration Returns Min          -0.812757
Exploration Actions Mean          0.0325475
Exploration Actions Std           0.592639
Exploration Actions Max           0.998282
Exploration Actions Min          -0.995753
AverageReturn                     0.499503
Number of train steps total  410844
Number of env steps total    411000
Number of rollouts total       3248
Train Time (s)                   48.6758
(Previous) Eval Time (s)          2.774e-06
Sample Time (s)                  42.8191
Epoch Time (s)                   91.4949
Total Train Time (s)          54480.3
Epoch                           410
---------------------------  ----------------
2018-05-16 11:36:18.370383 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #410 | Epoch Duration: 334.25600385665894
2018-05-16 11:36:18.370501 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #410 | Started Training: True
2018-05-16 11:39:19.944711 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #411 | Epoch Duration: 181.5741105079651
2018-05-16 11:39:19.944968 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #411 | Started Training: True
2018-05-16 11:42:17.021785 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #412 | Epoch Duration: 177.07668113708496
2018-05-16 11:42:17.023769 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #412 | Started Training: True
2018-05-16 11:45:11.625931 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #413 | Epoch Duration: 174.60198259353638
2018-05-16 11:45:11.626192 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #413 | Started Training: True
2018-05-16 11:48:04.086678 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #414 | Epoch Duration: 172.460351228714
2018-05-16 11:48:04.086898 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #414 | Started Training: True
2018-05-16 11:51:00.044842 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #415 | Epoch Duration: 175.95659041404724
2018-05-16 11:51:00.045107 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #415 | Started Training: True
2018-05-16 11:53:58.539121 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #416 | Epoch Duration: 178.49387741088867
2018-05-16 11:53:58.541108 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #416 | Started Training: True
2018-05-16 11:56:55.641634 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #417 | Epoch Duration: 177.10037446022034
2018-05-16 11:56:55.641847 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #417 | Started Training: True
2018-05-16 11:59:37.565169 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #418 | Epoch Duration: 161.92316675186157
2018-05-16 11:59:37.565410 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #418 | Started Training: True
2018-05-16 12:00:13.908518 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #419 | Epoch Duration: 36.34299087524414
2018-05-16 12:00:13.908724 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #419 | Started Training: True
2018-05-16 12:01:02.031191 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #420 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                       12316.2
VF Loss                           8.82347
Policy Loss                      27.7246
Q Predictions Mean              576.434
Q Predictions Std               251.67
Q Predictions Max              1628.2
Q Predictions Min                10.6497
V Predictions Mean              606.556
V Predictions Std               390.608
V Predictions Max              4129.56
V Predictions Min                21.7564
Log Pis Mean                    -11.3634
Log Pis Std                       7.98288
Log Pis Max                      78.0062
Log Pis Min                     -15.66
Policy mu Mean                    0.0251763
Policy mu Std                     0.310436
Policy mu Max                     3.95029
Policy mu Min                    -3.38446
Policy log std Mean              -0.145564
Policy log std Std                0.0966289
Policy log std Max                0.0434095
Policy log std Min               -2.25415
Test Rewards Mean                 0.0049037
Test Rewards Std                  0.00177665
Test Rewards Max                  0.00803785
Test Rewards Min                  0.000551121
Test Returns Mean                 0.346201
Test Returns Std                  0.00239732
Test Returns Max                  0.349066
Test Returns Min                  0.342651
Test Actions Mean                -0.0243042
Test Actions Std                  0.170825
Test Actions Max                  0.598823
Test Actions Min                 -0.589226
Num Paths                         5
Exploration Rewards Mean         -0.00640021
Exploration Rewards Std           0.00769285
Exploration Rewards Max           0.00730043
Exploration Rewards Min          -0.0211861
Exploration Returns Mean         -0.802587
Exploration Returns Std           0.00654476
Exploration Returns Max          -0.791806
Exploration Returns Min          -0.811694
Exploration Actions Mean          0.0242638
Exploration Actions Std           0.586376
Exploration Actions Max           0.998875
Exploration Actions Min          -0.996412
AverageReturn                     0.346201
Number of train steps total  420844
Number of env steps total    421000
Number of rollouts total       3324
Train Time (s)                   21.1103
(Previous) Eval Time (s)          1.825e-06
Sample Time (s)                  15.7507
Epoch Time (s)                   36.861
Total Train Time (s)          56370.4
Epoch                           420
---------------------------  ----------------
2018-05-16 12:07:48.723340 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #420 | Epoch Duration: 454.8145101070404
2018-05-16 12:07:48.723460 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #420 | Started Training: True
2018-05-16 12:10:47.450567 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #421 | Epoch Duration: 178.7270028591156
2018-05-16 12:10:47.450785 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #421 | Started Training: True
2018-05-16 12:13:55.981568 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #422 | Epoch Duration: 188.53061485290527
2018-05-16 12:13:55.981775 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #422 | Started Training: True
2018-05-16 12:16:57.194590 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #423 | Epoch Duration: 181.21270155906677
2018-05-16 12:16:57.197814 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #423 | Started Training: True
2018-05-16 12:19:05.348488 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #424 | Epoch Duration: 128.15048909187317
2018-05-16 12:19:05.349570 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #424 | Started Training: True
2018-05-16 12:19:42.533885 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #425 | Epoch Duration: 37.18413591384888
2018-05-16 12:19:42.534136 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #425 | Started Training: True
2018-05-16 12:20:20.038134 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #426 | Epoch Duration: 37.50387907028198
2018-05-16 12:20:20.038344 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #426 | Started Training: True
2018-05-16 12:20:56.192241 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #427 | Epoch Duration: 36.1537082195282
2018-05-16 12:20:56.194623 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #427 | Started Training: True
2018-05-16 12:21:32.600330 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #428 | Epoch Duration: 36.4055438041687
2018-05-16 12:21:32.601176 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #428 | Started Training: True
2018-05-16 12:22:09.606836 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #429 | Epoch Duration: 37.00543737411499
2018-05-16 12:22:09.608268 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #429 | Started Training: True
2018-05-16 12:22:56.799043 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #430 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           3.4423
VF Loss                           3.65459
Policy Loss                     -14.165
Q Predictions Mean              545.482
Q Predictions Std               229.98
Q Predictions Max               877.055
Q Predictions Min                 1.19356
V Predictions Mean              559.008
V Predictions Std               230.115
V Predictions Max               887.831
V Predictions Min                15.9732
Log Pis Mean                    -12.065
Log Pis Std                       0.724274
Log Pis Max                      -9.73638
Log Pis Min                     -14.5491
Policy mu Mean                    0.0347508
Policy mu Std                     0.129088
Policy mu Max                     0.591165
Policy mu Min                    -0.410881
Policy log std Mean              -0.137763
Policy log std Std                0.0136811
Policy log std Max               -0.0580532
Policy log std Min               -0.240414
Test Rewards Mean                 0.00432017
Test Rewards Std                  0.00143585
Test Rewards Max                  0.00782589
Test Rewards Min                  0.000605554
Test Returns Mean                 0.32247
Test Returns Std                  0.00459741
Test Returns Max                  0.332353
Test Returns Min                  0.31488
Test Actions Mean                -0.0111425
Test Actions Std                  0.122356
Test Actions Max                  0.507555
Test Actions Min                 -0.349544
Num Paths                         9
Exploration Rewards Mean         -0.00634549
Exploration Rewards Std           0.00764898
Exploration Rewards Max           0.00847348
Exploration Rewards Min          -0.0211549
Exploration Returns Mean         -0.798122
Exploration Returns Std           0.00881456
Exploration Returns Max          -0.786617
Exploration Returns Min          -0.81916
Exploration Actions Mean          0.0224572
Exploration Actions Std           0.590846
Exploration Actions Max           0.998931
Exploration Actions Min          -0.998878
AverageReturn                     0.32247
Number of train steps total  430844
Number of env steps total    431000
Number of rollouts total       3405
Train Time (s)                   19.6381
(Previous) Eval Time (s)          2.963e-06
Sample Time (s)                  16.1173
Epoch Time (s)                   35.7554
Total Train Time (s)          57687.4
Epoch                           430
---------------------------  ----------------
2018-05-16 12:29:45.909435 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #430 | Epoch Duration: 456.30093264579773
2018-05-16 12:29:45.909546 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #430 | Started Training: True
2018-05-16 12:31:08.582555 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #431 | Epoch Duration: 82.67291688919067
2018-05-16 12:31:08.582772 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #431 | Started Training: True
2018-05-16 12:31:45.802574 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #432 | Epoch Duration: 37.21964383125305
2018-05-16 12:31:45.802821 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #432 | Started Training: True
2018-05-16 12:32:21.751240 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #433 | Epoch Duration: 35.94830083847046
2018-05-16 12:32:21.753398 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #433 | Started Training: True
2018-05-16 12:32:59.387089 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #434 | Epoch Duration: 37.63353180885315
2018-05-16 12:32:59.387306 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #434 | Started Training: True
2018-05-16 12:33:36.900012 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #435 | Epoch Duration: 37.51253151893616
2018-05-16 12:33:36.900314 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #435 | Started Training: True
2018-05-16 12:34:13.065213 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #436 | Epoch Duration: 36.1647264957428
2018-05-16 12:34:13.065418 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #436 | Started Training: True
2018-05-16 12:34:48.619230 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #437 | Epoch Duration: 35.55365610122681
2018-05-16 12:34:48.620470 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #437 | Started Training: True
2018-05-16 12:36:34.421337 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #438 | Epoch Duration: 105.80068969726562
2018-05-16 12:36:34.421589 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #438 | Started Training: True
2018-05-16 12:39:38.329676 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #439 | Epoch Duration: 183.90795588493347
2018-05-16 12:39:38.329903 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #439 | Started Training: True
2018-05-16 12:42:49.256248 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #440 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           3.05248
VF Loss                           5.29638
Policy Loss                      -7.7871
Q Predictions Mean              540.075
Q Predictions Std               254.63
Q Predictions Max               878.42
Q Predictions Min                 4.73913
V Predictions Mean              553.176
V Predictions Std               255.548
V Predictions Max               886.3
V Predictions Min                18.0462
Log Pis Mean                    -12.2367
Log Pis Std                       0.694394
Log Pis Max                     -10.6438
Log Pis Min                     -14.5347
Policy mu Mean                    0.0342117
Policy mu Std                     0.111967
Policy mu Max                     0.509874
Policy mu Min                    -0.348479
Policy log std Mean              -0.136499
Policy log std Std                0.0118071
Policy log std Max               -0.0851064
Policy log std Min               -0.198695
Test Rewards Mean                 0.00465705
Test Rewards Std                  0.001592
Test Rewards Max                  0.00769931
Test Rewards Min                  0.000570377
Test Returns Mean                 0.328167
Test Returns Std                  0.00197525
Test Returns Max                  0.331398
Test Returns Min                  0.324064
Test Actions Mean                -0.0488683
Test Actions Std                  0.179759
Test Actions Max                  0.590445
Test Actions Min                 -0.486009
Num Paths                         8
Exploration Rewards Mean         -0.00636326
Exploration Rewards Std           0.0076362
Exploration Rewards Max           0.00674897
Exploration Rewards Min          -0.0212523
Exploration Returns Mean         -0.801771
Exploration Returns Std           0.012334
Exploration Returns Max          -0.786467
Exploration Returns Min          -0.82821
Exploration Actions Mean          0.0240928
Exploration Actions Std           0.591705
Exploration Actions Max           0.998703
Exploration Actions Min          -0.997636
AverageReturn                     0.328167
Number of train steps total  440844
Number of env steps total    441000
Number of rollouts total       3486
Train Time (s)                   86.0958
(Previous) Eval Time (s)          2.371e-06
Sample Time (s)                  92.6192
Epoch Time (s)                  178.715
Total Train Time (s)          58865.9
Epoch                           440
---------------------------  ----------------
2018-05-16 12:49:24.646751 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #440 | Epoch Duration: 586.3167328834534
2018-05-16 12:49:24.646859 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #440 | Started Training: True
2018-05-16 12:50:02.178678 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #441 | Epoch Duration: 37.53172039985657
2018-05-16 12:50:02.178926 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #441 | Started Training: True
2018-05-16 12:50:39.086242 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #442 | Epoch Duration: 36.90719819068909
2018-05-16 12:50:39.086483 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #442 | Started Training: True
2018-05-16 12:51:16.346054 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #443 | Epoch Duration: 37.25939440727234
2018-05-16 12:51:16.346319 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #443 | Started Training: True
2018-05-16 12:52:20.997877 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #444 | Epoch Duration: 64.65137076377869
2018-05-16 12:52:20.998174 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #444 | Started Training: True
2018-05-16 12:55:23.420677 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #445 | Epoch Duration: 182.4223494529724
2018-05-16 12:55:23.420915 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #445 | Started Training: True
2018-05-16 12:58:19.871481 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #446 | Epoch Duration: 176.45043849945068
2018-05-16 12:58:19.871731 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #446 | Started Training: True
2018-05-16 13:01:16.046266 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #447 | Epoch Duration: 176.1744041442871
2018-05-16 13:01:16.046495 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #447 | Started Training: True
2018-05-16 13:04:19.116583 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #448 | Epoch Duration: 183.06996321678162
2018-05-16 13:04:19.116829 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #448 | Started Training: True
2018-05-16 13:07:18.751288 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #449 | Epoch Duration: 179.63432669639587
2018-05-16 13:07:18.751511 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #449 | Started Training: True
2018-05-16 13:10:32.819501 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #450 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           2.93709
VF Loss                           1.91563
Policy Loss                      -0.142223
Q Predictions Mean              511.895
Q Predictions Std               256.776
Q Predictions Max               869.683
Q Predictions Min                 0.680938
V Predictions Mean              524.353
V Predictions Std               256.851
V Predictions Max               883.178
V Predictions Min                13.9096
Log Pis Mean                    -12.2385
Log Pis Std                       0.733152
Log Pis Max                     -10.2854
Log Pis Min                     -14.1178
Policy mu Mean                    0.038159
Policy mu Std                     0.106959
Policy mu Max                     0.541163
Policy mu Min                    -0.339989
Policy log std Mean              -0.135993
Policy log std Std                0.0117387
Policy log std Max               -0.0905402
Policy log std Min               -0.204303
Test Rewards Mean                 0.00497477
Test Rewards Std                  0.00318413
Test Rewards Max                  0.0119539
Test Rewards Min                 -0.00123795
Test Returns Mean                 0.58647
Test Returns Std                  0.00370055
Test Returns Max                  0.591756
Test Returns Min                  0.579478
Test Actions Mean                 0.0188553
Test Actions Std                  0.171673
Test Actions Max                  0.525244
Test Actions Min                 -0.462418
Num Paths                         8
Exploration Rewards Mean         -0.00641234
Exploration Rewards Std           0.00766681
Exploration Rewards Max           0.00793695
Exploration Rewards Min          -0.021292
Exploration Returns Mean         -0.795932
Exploration Returns Std           0.00660794
Exploration Returns Max          -0.78656
Exploration Returns Min          -0.809778
Exploration Actions Mean          0.0204965
Exploration Actions Std           0.590802
Exploration Actions Max           0.998881
Exploration Actions Min          -0.998169
AverageReturn                     0.58647
Number of train steps total  450844
Number of env steps total    451000
Number of rollouts total       3566
Train Time (s)                   90.4165
(Previous) Eval Time (s)          2.296e-06
Sample Time (s)                  91.3944
Epoch Time (s)                  181.811
Total Train Time (s)          60310.6
Epoch                           450
---------------------------  ---------------
2018-05-16 13:13:29.601674 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #450 | Epoch Duration: 370.85005378723145
2018-05-16 13:13:29.601783 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #450 | Started Training: True
2018-05-16 13:14:07.202063 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #451 | Epoch Duration: 37.60018730163574
2018-05-16 13:14:07.202278 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #451 | Started Training: True
2018-05-16 13:14:44.481027 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #452 | Epoch Duration: 37.278579235076904
2018-05-16 13:14:44.481301 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #452 | Started Training: True
2018-05-16 13:15:20.847239 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #453 | Epoch Duration: 36.36578106880188
2018-05-16 13:15:20.847452 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #453 | Started Training: True
2018-05-16 13:15:57.908043 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #454 | Epoch Duration: 37.060441970825195
2018-05-16 13:15:57.908269 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #454 | Started Training: True
2018-05-16 13:16:51.778913 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #455 | Epoch Duration: 53.8704719543457
2018-05-16 13:16:51.779179 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #455 | Started Training: True
2018-05-16 13:19:53.662315 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #456 | Epoch Duration: 181.88301038742065
2018-05-16 13:19:53.662596 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #456 | Started Training: True
2018-05-16 13:22:52.516013 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #457 | Epoch Duration: 178.85329174995422
2018-05-16 13:22:52.518115 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #457 | Started Training: True
2018-05-16 13:25:49.949443 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #458 | Epoch Duration: 177.431147813797
2018-05-16 13:25:49.949689 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #458 | Started Training: True
2018-05-16 13:28:45.353951 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #459 | Epoch Duration: 175.4041292667389
2018-05-16 13:28:45.354201 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #459 | Started Training: True
2018-05-16 13:31:58.534198 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #460 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           3.3421
VF Loss                           3.06751
Policy Loss                      -4.98465
Q Predictions Mean              558.844
Q Predictions Std               234.795
Q Predictions Max               868.931
Q Predictions Min                34.8891
V Predictions Mean              571.604
V Predictions Std               234.441
V Predictions Max               885.142
V Predictions Min                49.2067
Log Pis Mean                    -12.2316
Log Pis Std                       0.762456
Log Pis Max                     -10.1709
Log Pis Min                     -16.8353
Policy mu Mean                    0.0318377
Policy mu Std                     0.106704
Policy mu Max                     0.478812
Policy mu Min                    -0.303838
Policy log std Mean              -0.136102
Policy log std Std                0.0110561
Policy log std Max               -0.0670124
Policy log std Min               -0.202612
Test Rewards Mean                 0.00493361
Test Rewards Std                  0.00306652
Test Rewards Max                  0.0118866
Test Rewards Min                 -1.71392e-05
Test Returns Mean                 0.584907
Test Returns Std                  0.00387305
Test Returns Max                  0.590201
Test Returns Min                  0.580377
Test Actions Mean                 0.0256467
Test Actions Std                  0.165309
Test Actions Max                  0.629253
Test Actions Min                 -0.388759
Num Paths                         7
Exploration Rewards Mean         -0.00644887
Exploration Rewards Std           0.00770273
Exploration Rewards Max           0.00875655
Exploration Rewards Min          -0.0212442
Exploration Returns Mean         -0.79966
Exploration Returns Std           0.00869923
Exploration Returns Max          -0.781292
Exploration Returns Min          -0.810333
Exploration Actions Mean          0.0195477
Exploration Actions Std           0.587969
Exploration Actions Max           0.999425
Exploration Actions Min          -0.997923
AverageReturn                     0.584907
Number of train steps total  460844
Number of env steps total    461000
Number of rollouts total       3645
Train Time (s)                   86.8614
(Previous) Eval Time (s)          2.72201e-06
Sample Time (s)                  93.8401
Epoch Time (s)                  180.702
Total Train Time (s)          61603.2
Epoch                           460
---------------------------  ----------------
2018-05-16 13:35:02.451491 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #460 | Epoch Duration: 377.0971474647522
2018-05-16 13:35:02.451598 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #460 | Started Training: True
2018-05-16 13:35:39.918243 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #461 | Epoch Duration: 37.46654796600342
2018-05-16 13:35:39.918480 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #461 | Started Training: True
2018-05-16 13:36:16.439485 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #462 | Epoch Duration: 36.5208683013916
2018-05-16 13:36:16.439691 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #462 | Started Training: True
2018-05-16 13:36:53.410807 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #463 | Epoch Duration: 36.97099423408508
2018-05-16 13:36:53.413006 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #463 | Started Training: True
2018-05-16 13:37:30.067389 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #464 | Epoch Duration: 36.65422177314758
2018-05-16 13:37:30.067660 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #464 | Started Training: True
2018-05-16 13:38:07.954309 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #465 | Epoch Duration: 37.8864860534668
2018-05-16 13:38:07.954581 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #465 | Started Training: True
2018-05-16 13:38:44.510789 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #466 | Epoch Duration: 36.55605983734131
2018-05-16 13:38:44.515456 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #466 | Started Training: True
2018-05-16 13:39:21.194776 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #467 | Epoch Duration: 36.67908191680908
2018-05-16 13:39:21.195059 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #467 | Started Training: True
2018-05-16 13:39:57.635152 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #468 | Epoch Duration: 36.439937114715576
2018-05-16 13:39:57.636368 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #468 | Started Training: True
2018-05-16 13:40:34.766296 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #469 | Epoch Duration: 37.12977910041809
2018-05-16 13:40:34.769825 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #469 | Started Training: True
2018-05-16 13:41:24.144388 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #470 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           9.27837
VF Loss                           9.79229
Policy Loss                      21.0817
Q Predictions Mean              515.026
Q Predictions Std               278.732
Q Predictions Max               872.505
Q Predictions Min                -0.233145
V Predictions Mean              525.708
V Predictions Std               277.351
V Predictions Max               883.818
V Predictions Min                15.4319
Log Pis Mean                    -12.1492
Log Pis Std                       0.760645
Log Pis Max                      -9.64812
Log Pis Min                     -14.6785
Policy mu Mean                    0.0430161
Policy mu Std                     0.108692
Policy mu Max                     0.51195
Policy mu Min                    -0.412605
Policy log std Mean              -0.138056
Policy log std Std                0.0107846
Policy log std Max               -0.0999439
Policy log std Min               -0.202113
Test Rewards Mean                 0.00492816
Test Rewards Std                  0.00310912
Test Rewards Max                  0.0120946
Test Rewards Min                  0.000463832
Test Returns Mean                 0.581522
Test Returns Std                  0.00402841
Test Returns Max                  0.588005
Test Returns Min                  0.577247
Test Actions Mean                 0.0152441
Test Actions Std                  0.12774
Test Actions Max                  0.513564
Test Actions Min                 -0.397195
Num Paths                         7
Exploration Rewards Mean         -0.00643112
Exploration Rewards Std           0.00759754
Exploration Rewards Max           0.00604743
Exploration Rewards Min          -0.0210802
Exploration Returns Mean         -0.790109
Exploration Returns Std           0.0118258
Exploration Returns Max          -0.76711
Exploration Returns Min          -0.802147
Exploration Actions Mean          0.0208912
Exploration Actions Std           0.586752
Exploration Actions Max           0.99952
Exploration Actions Min          -0.995524
AverageReturn                     0.581522
Number of train steps total  470844
Number of env steps total    471000
Number of rollouts total       3724
Train Time (s)                   20.9906
(Previous) Eval Time (s)          2.421e-06
Sample Time (s)                  16.0359
Epoch Time (s)                   37.0265
Total Train Time (s)          62143.9
Epoch                           470
---------------------------  ----------------
2018-05-16 13:44:03.383163 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #470 | Epoch Duration: 208.61316776275635
2018-05-16 13:44:03.383272 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #470 | Started Training: True
2018-05-16 13:44:40.593583 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #471 | Epoch Duration: 37.2102165222168
2018-05-16 13:44:40.593791 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #471 | Started Training: True
2018-05-16 13:45:17.623138 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #472 | Epoch Duration: 37.02919054031372
2018-05-16 13:45:17.623387 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #472 | Started Training: True
2018-05-16 13:45:53.074181 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #473 | Epoch Duration: 35.45067644119263
2018-05-16 13:45:53.074403 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #473 | Started Training: True
2018-05-16 13:46:38.074986 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #474 | Epoch Duration: 45.0004403591156
2018-05-16 13:46:38.075244 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #474 | Started Training: True
2018-05-16 13:49:40.047315 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #475 | Epoch Duration: 181.97193551063538
2018-05-16 13:49:40.047554 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #475 | Started Training: True
2018-05-16 13:52:41.203282 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #476 | Epoch Duration: 181.15560054779053
2018-05-16 13:52:41.203537 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #476 | Started Training: True
2018-05-16 13:55:39.136796 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #477 | Epoch Duration: 177.93313646316528
2018-05-16 13:55:39.137046 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #477 | Started Training: True
2018-05-16 13:59:07.800179 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #478 | Epoch Duration: 208.66300344467163
2018-05-16 13:59:07.800449 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #478 | Started Training: True
2018-05-16 14:02:33.677113 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #479 | Epoch Duration: 205.8765263557434
2018-05-16 14:02:33.678202 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #479 | Started Training: True
2018-05-16 14:05:41.688358 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #480 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           2.02793
VF Loss                           1.23086
Policy Loss                      -2.52824
Q Predictions Mean              519.352
Q Predictions Std               245.796
Q Predictions Max               870.752
Q Predictions Min                 4.18158
V Predictions Mean              531.881
V Predictions Std               245.451
V Predictions Max               882.193
V Predictions Min                18.5095
Log Pis Mean                    -12.225
Log Pis Std                       0.620887
Log Pis Max                     -10.8016
Log Pis Min                     -13.8466
Policy mu Mean                    0.0301918
Policy mu Std                     0.0836336
Policy mu Max                     0.437096
Policy mu Min                    -0.255376
Policy log std Mean              -0.131781
Policy log std Std                0.00897243
Policy log std Max               -0.0890412
Policy log std Min               -0.185539
Test Rewards Mean                 0.00413168
Test Rewards Std                  0.00687019
Test Rewards Max                  0.01429
Test Rewards Min                 -0.00438669
Test Returns Mean                 0.516977
Test Returns Std                  0.00275863
Test Returns Max                  0.52117
Test Returns Min                  0.512249
Test Actions Mean                -0.01893
Test Actions Std                  0.14252
Test Actions Max                  0.584061
Test Actions Min                 -0.531423
Num Paths                         8
Exploration Rewards Mean         -0.00641077
Exploration Rewards Std           0.00766201
Exploration Rewards Max           0.00813101
Exploration Rewards Min          -0.0214627
Exploration Returns Mean         -0.800545
Exploration Returns Std           0.00864517
Exploration Returns Max          -0.78736
Exploration Returns Min          -0.812031
Exploration Actions Mean          0.0129182
Exploration Actions Std           0.58997
Exploration Actions Max           0.998684
Exploration Actions Min          -0.997369
AverageReturn                     0.516977
Number of train steps total  480844
Number of env steps total    481000
Number of rollouts total       3804
Train Time (s)                   88.7843
(Previous) Eval Time (s)          2.54399e-06
Sample Time (s)                  86.1812
Epoch Time (s)                  174.965
Total Train Time (s)          63664.9
Epoch                           480
---------------------------  ----------------
2018-05-16 14:09:24.538707 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #480 | Epoch Duration: 410.8603494167328
2018-05-16 14:09:24.538823 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #480 | Started Training: True
2018-05-16 14:10:03.098481 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #481 | Epoch Duration: 38.55954718589783
2018-05-16 14:10:03.098691 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #481 | Started Training: True
2018-05-16 14:10:40.310155 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #482 | Epoch Duration: 37.21132183074951
2018-05-16 14:10:40.310368 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #482 | Started Training: True
2018-05-16 14:11:17.966580 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #483 | Epoch Duration: 37.65603685379028
2018-05-16 14:11:17.966927 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #483 | Started Training: True
2018-05-16 14:11:55.148221 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #484 | Epoch Duration: 37.180500745773315
2018-05-16 14:11:55.148427 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #484 | Started Training: True
2018-05-16 14:14:14.115938 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #485 | Epoch Duration: 138.96735095977783
2018-05-16 14:14:14.116186 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #485 | Started Training: True
2018-05-16 14:17:12.577962 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #486 | Epoch Duration: 178.46163821220398
2018-05-16 14:17:12.578218 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #486 | Started Training: True
2018-05-16 14:20:32.187613 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #487 | Epoch Duration: 199.60925841331482
2018-05-16 14:20:32.187857 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #487 | Started Training: True
2018-05-16 14:23:55.873145 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #488 | Epoch Duration: 203.6851680278778
2018-05-16 14:23:55.876332 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #488 | Started Training: True
2018-05-16 14:27:15.446919 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #489 | Epoch Duration: 199.57039403915405
2018-05-16 14:27:15.447163 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #489 | Started Training: True
2018-05-16 14:30:28.510582 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #490 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           2.55145
VF Loss                           2.21223
Policy Loss                       9.0523
Q Predictions Mean              533.857
Q Predictions Std               218.598
Q Predictions Max               864.063
Q Predictions Min                24.4127
V Predictions Mean              545.421
V Predictions Std               218.269
V Predictions Max               878.992
V Predictions Min                38.3551
Log Pis Mean                    -12.1726
Log Pis Std                       0.647641
Log Pis Max                     -10.4227
Log Pis Min                     -14.0931
Policy mu Mean                    0.0213122
Policy mu Std                     0.0899142
Policy mu Max                     0.474265
Policy mu Min                    -0.332583
Policy log std Mean              -0.137971
Policy log std Std                0.0101296
Policy log std Max               -0.085172
Policy log std Min               -0.212781
Test Rewards Mean                 0.00243873
Test Rewards Std                  0.00584962
Test Rewards Max                  0.0180757
Test Rewards Min                 -0.00648916
Test Returns Mean                 0.423933
Test Returns Std                  0.00656026
Test Returns Max                  0.428953
Test Returns Min                  0.409724
Test Actions Mean                -0.0956758
Test Actions Std                  0.194339
Test Actions Max                  0.62921
Test Actions Min                 -0.711442
Num Paths                         9
Exploration Rewards Mean         -0.00642376
Exploration Rewards Std           0.00767698
Exploration Rewards Max           0.00730328
Exploration Rewards Min          -0.021217
Exploration Returns Mean         -0.806539
Exploration Returns Std           0.00886801
Exploration Returns Max          -0.790996
Exploration Returns Min          -0.818012
Exploration Actions Mean          0.0207224
Exploration Actions Std           0.589325
Exploration Actions Max           0.998161
Exploration Actions Min          -0.998235
AverageReturn                     0.423933
Number of train steps total  490844
Number of env steps total    491000
Number of rollouts total       3883
Train Time (s)                   87.8388
(Previous) Eval Time (s)          2.49699e-06
Sample Time (s)                  91.902
Epoch Time (s)                  179.741
Total Train Time (s)          65643.2
Epoch                           490
---------------------------  ----------------
2018-05-16 14:42:23.154084 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #490 | Epoch Duration: 907.7068061828613
2018-05-16 14:42:23.154194 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #490 | Started Training: True
2018-05-16 14:42:59.998683 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #491 | Epoch Duration: 36.844393730163574
2018-05-16 14:42:59.998888 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #491 | Started Training: True
2018-05-16 14:43:36.760212 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #492 | Epoch Duration: 36.76116919517517
2018-05-16 14:43:36.760459 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #492 | Started Training: True
2018-05-16 14:44:13.013975 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #493 | Epoch Duration: 36.2533962726593
2018-05-16 14:44:13.014198 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #493 | Started Training: True
2018-05-16 14:44:49.558743 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #494 | Epoch Duration: 36.5444233417511
2018-05-16 14:44:49.561356 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #494 | Started Training: True
2018-05-16 14:45:25.859354 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #495 | Epoch Duration: 36.2978355884552
2018-05-16 14:45:25.859626 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #495 | Started Training: True
2018-05-16 14:46:03.260327 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #496 | Epoch Duration: 37.40053415298462
2018-05-16 14:46:03.262541 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #496 | Started Training: True
2018-05-16 14:46:39.604071 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #497 | Epoch Duration: 36.341310262680054
2018-05-16 14:46:39.604276 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #497 | Started Training: True
2018-05-16 14:47:16.586585 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #498 | Epoch Duration: 36.98215866088867
2018-05-16 14:47:16.586793 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #498 | Started Training: True
2018-05-16 14:47:53.414072 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #499 | Epoch Duration: 36.82711696624756
2018-05-16 14:47:53.414281 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #499 | Started Training: True
2018-05-16 14:48:42.768628 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #500 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           3.54004
VF Loss                           5.66718
Policy Loss                      17.8018
Q Predictions Mean              572.9
Q Predictions Std               236.198
Q Predictions Max               871.889
Q Predictions Min                -5.62094
V Predictions Mean              583.776
V Predictions Std               236.163
V Predictions Max               880.032
V Predictions Min                 2.31887
Log Pis Mean                    -12.1967
Log Pis Std                       0.781748
Log Pis Max                      -9.26452
Log Pis Min                     -14.1955
Policy mu Mean                    0.0196809
Policy mu Std                     0.101076
Policy mu Max                     0.453032
Policy mu Min                    -0.419102
Policy log std Mean              -0.133757
Policy log std Std                0.0153552
Policy log std Max               -0.040391
Policy log std Min               -0.184959
Test Rewards Mean                 0.0046004
Test Rewards Std                  0.00309294
Test Rewards Max                  0.011774
Test Rewards Min                  0.00043533
Test Returns Mean                 0.593451
Test Returns Std                  0.00303455
Test Returns Max                  0.599219
Test Returns Min                  0.589431
Test Actions Mean                 0.0103268
Test Actions Std                  0.163346
Test Actions Max                  0.466131
Test Actions Min                 -0.676157
Num Paths                         8
Exploration Rewards Mean         -0.0064859
Exploration Rewards Std           0.0076198
Exploration Rewards Max           0.0069763
Exploration Rewards Min          -0.0213275
Exploration Returns Mean         -0.799388
Exploration Returns Std           0.0129959
Exploration Returns Max          -0.776667
Exploration Returns Min          -0.818745
Exploration Actions Mean          0.0108272
Exploration Actions Std           0.588893
Exploration Actions Max           0.999042
Exploration Actions Min          -0.997218
AverageReturn                     0.593451
Number of train steps total  500844
Number of env steps total    501000
Number of rollouts total       3961
Train Time (s)                   20.5216
(Previous) Eval Time (s)          2.035e-06
Sample Time (s)                  15.9139
Epoch Time (s)                   36.4355
Total Train Time (s)          66180.4
Epoch                           500
---------------------------  ---------------
2018-05-16 14:51:20.565413 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #500 | Epoch Duration: 207.1509644985199
2018-05-16 14:51:20.565521 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #500 | Started Training: True
2018-05-16 14:51:57.776092 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #501 | Epoch Duration: 37.21047496795654
2018-05-16 14:51:57.776318 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #501 | Started Training: True
2018-05-16 14:52:34.937565 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #502 | Epoch Duration: 37.16112565994263
2018-05-16 14:52:34.937783 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #502 | Started Training: True
2018-05-16 14:53:11.889446 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #503 | Epoch Duration: 36.95149087905884
2018-05-16 14:53:11.889712 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #503 | Started Training: True
2018-05-16 14:53:48.183923 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #504 | Epoch Duration: 36.29403734207153
2018-05-16 14:53:48.184195 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #504 | Started Training: True
2018-05-16 14:54:25.114748 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #505 | Epoch Duration: 36.930384159088135
2018-05-16 14:54:25.117120 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #505 | Started Training: True
2018-05-16 14:55:01.267051 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #506 | Epoch Duration: 36.1497700214386
2018-05-16 14:55:01.267273 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #506 | Started Training: True
2018-05-16 14:55:38.071727 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #507 | Epoch Duration: 36.804336071014404
2018-05-16 14:55:38.071956 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #507 | Started Training: True
2018-05-16 14:56:15.630746 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #508 | Epoch Duration: 37.55861854553223
2018-05-16 14:56:15.630953 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #508 | Started Training: True
2018-05-16 14:59:18.924311 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #509 | Epoch Duration: 183.293199300766
2018-05-16 14:59:18.924565 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #509 | Started Training: True
2018-05-16 15:03:14.266269 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #510 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           3.48029
VF Loss                           3.58236
Policy Loss                     -11.0936
Q Predictions Mean              505.65
Q Predictions Std               242.439
Q Predictions Max               867.357
Q Predictions Min                 1.51549
V Predictions Mean              518.856
V Predictions Std               242.908
V Predictions Max               877.674
V Predictions Min                12.528
Log Pis Mean                    -12.0891
Log Pis Std                       0.782405
Log Pis Max                      -9.76231
Log Pis Min                     -16.0908
Policy mu Mean                    0.0304627
Policy mu Std                     0.0945217
Policy mu Max                     0.43318
Policy mu Min                    -0.386986
Policy log std Mean              -0.135019
Policy log std Std                0.0105748
Policy log std Max               -0.0994165
Policy log std Min               -0.182546
Test Rewards Mean                 0.00495541
Test Rewards Std                  0.00316071
Test Rewards Max                  0.0124586
Test Rewards Min                  0.000247633
Test Returns Mean                 0.587492
Test Returns Std                  0.00454761
Test Returns Max                  0.592884
Test Returns Min                  0.582121
Test Actions Mean                -0.00610796
Test Actions Std                  0.160528
Test Actions Max                  0.557937
Test Actions Min                 -0.573667
Num Paths                         8
Exploration Rewards Mean         -0.00632329
Exploration Rewards Std           0.00759807
Exploration Rewards Max           0.00733887
Exploration Rewards Min          -0.0212936
Exploration Returns Mean         -0.791992
Exploration Returns Std           0.00867509
Exploration Returns Max          -0.78211
Exploration Returns Min          -0.812453
Exploration Actions Mean          0.0188099
Exploration Actions Std           0.588688
Exploration Actions Max           0.997422
Exploration Actions Min          -0.997823
AverageReturn                     0.587492
Number of train steps total  510844
Number of env steps total    511000
Number of rollouts total       4042
Train Time (s)                  101.215
(Previous) Eval Time (s)          3.041e-06
Sample Time (s)                 120.468
Epoch Time (s)                  221.682
Total Train Time (s)          67076.4
Epoch                           510
---------------------------  ----------------
2018-05-16 15:06:16.702609 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #510 | Epoch Duration: 417.77791810035706
2018-05-16 15:06:16.702723 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #510 | Started Training: True
2018-05-16 15:09:19.638904 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #511 | Epoch Duration: 182.9360852241516
2018-05-16 15:09:19.639166 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #511 | Started Training: True
2018-05-16 15:12:15.154219 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #512 | Epoch Duration: 175.51492428779602
2018-05-16 15:12:15.154491 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #512 | Started Training: True
2018-05-16 15:15:17.516759 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #513 | Epoch Duration: 182.3621325492859
2018-05-16 15:15:17.516967 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #513 | Started Training: True
2018-05-16 15:17:22.887422 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #514 | Epoch Duration: 125.37033653259277
2018-05-16 15:17:22.889996 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #514 | Started Training: True
2018-05-16 15:17:59.738606 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #515 | Epoch Duration: 36.848413705825806
2018-05-16 15:17:59.738815 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #515 | Started Training: True
2018-05-16 15:18:37.276113 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #516 | Epoch Duration: 37.537131786346436
2018-05-16 15:18:37.276383 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #516 | Started Training: True
2018-05-16 15:19:14.103514 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #517 | Epoch Duration: 36.82696485519409
2018-05-16 15:19:14.103803 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #517 | Started Training: True
2018-05-16 15:19:50.362736 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #518 | Epoch Duration: 36.25877070426941
2018-05-16 15:19:50.362979 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #518 | Started Training: True
2018-05-16 15:20:27.170760 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #519 | Epoch Duration: 36.80764436721802
2018-05-16 15:20:27.171206 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #519 | Started Training: True
2018-05-16 15:21:16.959825 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #520 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           2.19591
VF Loss                           1.62139
Policy Loss                       0.424408
Q Predictions Mean              570.491
Q Predictions Std               240.185
Q Predictions Max               866.835
Q Predictions Min                28.1234
V Predictions Mean              582.822
V Predictions Std               240.466
V Predictions Max               877.785
V Predictions Min                39.5391
Log Pis Mean                    -12.1614
Log Pis Std                       0.687184
Log Pis Max                     -10.063
Log Pis Min                     -14.0553
Policy mu Mean                    0.0232826
Policy mu Std                     0.0891536
Policy mu Max                     0.497276
Policy mu Min                    -0.301998
Policy log std Mean              -0.136591
Policy log std Std                0.01155
Policy log std Max               -0.0700663
Policy log std Min               -0.193051
Test Rewards Mean                 0.00501983
Test Rewards Std                  0.00308468
Test Rewards Max                  0.012393
Test Rewards Min                  0.000496958
Test Returns Mean                 0.624133
Test Returns Std                  0.00157591
Test Returns Max                  0.626648
Test Returns Min                  0.621186
Test Actions Mean                 0.0409649
Test Actions Std                  0.232126
Test Actions Max                  0.740252
Test Actions Min                 -0.902991
Num Paths                         7
Exploration Rewards Mean         -0.00633152
Exploration Rewards Std           0.00762172
Exploration Rewards Max           0.00712045
Exploration Rewards Min          -0.0213356
Exploration Returns Mean         -0.795962
Exploration Returns Std           0.00800694
Exploration Returns Max          -0.778948
Exploration Returns Min          -0.805844
Exploration Actions Mean          0.0220217
Exploration Actions Std           0.592246
Exploration Actions Max           0.997956
Exploration Actions Min          -0.998945
AverageReturn                     0.624133
Number of train steps total  520844
Number of env steps total    521000
Number of rollouts total       4120
Train Time (s)                   20.1799
(Previous) Eval Time (s)          3.002e-06
Sample Time (s)                  15.8864
Epoch Time (s)                   36.0663
Total Train Time (s)          68166.2
Epoch                           520
---------------------------  ----------------
2018-05-16 15:24:26.713194 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #520 | Epoch Duration: 239.5415859222412
2018-05-16 15:24:26.713346 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #520 | Started Training: True
2018-05-16 15:27:29.237645 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #521 | Epoch Duration: 182.52416968345642
2018-05-16 15:27:29.237873 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #521 | Started Training: True
2018-05-16 15:30:28.702723 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #522 | Epoch Duration: 179.46472930908203
2018-05-16 15:30:28.702939 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #522 | Started Training: True
2018-05-16 15:33:28.444353 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #523 | Epoch Duration: 179.74129176139832
2018-05-16 15:33:28.444599 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #523 | Started Training: True
2018-05-16 15:36:28.941436 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #524 | Epoch Duration: 180.49672079086304
2018-05-16 15:36:28.941656 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #524 | Started Training: True
2018-05-16 15:39:26.239621 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #525 | Epoch Duration: 177.2977957725525
2018-05-16 15:39:26.239874 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #525 | Started Training: True
2018-05-16 15:40:09.036795 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #526 | Epoch Duration: 42.796788930892944
2018-05-16 15:40:09.036999 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #526 | Started Training: True
2018-05-16 15:40:45.294454 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #527 | Epoch Duration: 36.25730633735657
2018-05-16 15:40:45.294664 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #527 | Started Training: True
2018-05-16 15:41:21.785531 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #528 | Epoch Duration: 36.49070119857788
2018-05-16 15:41:21.785736 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #528 | Started Training: True
2018-05-16 15:41:58.158734 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #529 | Epoch Duration: 36.3728404045105
2018-05-16 15:41:58.163091 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #529 | Started Training: True
2018-05-16 15:42:48.383930 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #530 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           3.56715
VF Loss                           4.37251
Policy Loss                      22.4279
Q Predictions Mean              532.216
Q Predictions Std               242.083
Q Predictions Max               868.052
Q Predictions Min                 0.0186541
V Predictions Mean              542.515
V Predictions Std               241.744
V Predictions Max               877.951
V Predictions Min                11.9063
Log Pis Mean                    -12.1497
Log Pis Std                       0.608137
Log Pis Max                     -10.3494
Log Pis Min                     -14.1211
Policy mu Mean                    0.0203645
Policy mu Std                     0.0840804
Policy mu Max                     0.454098
Policy mu Min                    -0.264518
Policy log std Mean              -0.135642
Policy log std Std                0.0106055
Policy log std Max               -0.0979529
Policy log std Min               -0.20283
Test Rewards Mean                 0.00493922
Test Rewards Std                  0.00310211
Test Rewards Max                  0.0122143
Test Rewards Min                  0.000341021
Test Returns Mean                 0.615207
Test Returns Std                  0.00286575
Test Returns Max                  0.618707
Test Returns Min                  0.608822
Test Actions Mean                 0.0209992
Test Actions Std                  0.162356
Test Actions Max                  0.52161
Test Actions Min                 -0.759891
Num Paths                         8
Exploration Rewards Mean         -0.00636261
Exploration Rewards Std           0.00765121
Exploration Rewards Max           0.00725547
Exploration Rewards Min          -0.0211527
Exploration Returns Mean         -0.796917
Exploration Returns Std           0.00832621
Exploration Returns Max          -0.785771
Exploration Returns Min          -0.80636
Exploration Actions Mean          0.0102673
Exploration Actions Std           0.587721
Exploration Actions Max           0.995921
Exploration Actions Min          -0.997256
AverageReturn                     0.615207
Number of train steps total  530844
Number of env steps total    531000
Number of rollouts total       4200
Train Time (s)                   20.6957
(Previous) Eval Time (s)          2.93e-06
Sample Time (s)                  15.932
Epoch Time (s)                   36.6277
Total Train Time (s)          69442.6
Epoch                           530
---------------------------  ----------------
2018-05-16 15:45:43.369017 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #530 | Epoch Duration: 225.20570397377014
2018-05-16 15:45:43.369131 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #530 | Started Training: True
2018-05-16 15:48:38.804021 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #531 | Epoch Duration: 175.43479228019714
2018-05-16 15:48:38.804243 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #531 | Started Training: True
2018-05-16 15:51:34.348406 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #532 | Epoch Duration: 175.54403114318848
2018-05-16 15:51:34.348683 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #532 | Started Training: True
2018-05-16 15:54:26.404743 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #533 | Epoch Duration: 172.05592894554138
2018-05-16 15:54:26.404996 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #533 | Started Training: True
2018-05-16 15:57:23.276102 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #534 | Epoch Duration: 176.87097096443176
2018-05-16 15:57:23.279551 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #534 | Started Training: True
2018-05-16 16:00:21.592960 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #535 | Epoch Duration: 178.3132119178772
2018-05-16 16:00:21.593195 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #535 | Started Training: True
2018-05-16 16:03:17.755309 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #536 | Epoch Duration: 176.16198706626892
2018-05-16 16:03:17.755518 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #536 | Started Training: True
2018-05-16 16:06:18.019998 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #537 | Epoch Duration: 180.26436352729797
2018-05-16 16:06:18.020232 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #537 | Started Training: True
2018-05-16 16:08:22.820231 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #538 | Epoch Duration: 124.79987049102783
2018-05-16 16:08:22.820634 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #538 | Started Training: True
2018-05-16 16:09:00.059085 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #539 | Epoch Duration: 37.23822546005249
2018-05-16 16:09:00.059350 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #539 | Started Training: True
2018-05-16 16:09:51.085584 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #540 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           1.51275
VF Loss                           0.998786
Policy Loss                       1.8456
Q Predictions Mean              533.633
Q Predictions Std               245.036
Q Predictions Max               864.99
Q Predictions Min                23.2736
V Predictions Mean              545.901
V Predictions Std               244.791
V Predictions Max               877.23
V Predictions Min                34.9657
Log Pis Mean                    -12.2685
Log Pis Std                       0.667346
Log Pis Max                     -10.549
Log Pis Min                     -14.0652
Policy mu Mean                    0.0210844
Policy mu Std                     0.0817559
Policy mu Max                     0.403562
Policy mu Min                    -0.279438
Policy log std Mean              -0.135792
Policy log std Std                0.00984784
Policy log std Max               -0.0997491
Policy log std Min               -0.193264
Test Rewards Mean                 0.00501463
Test Rewards Std                  0.00300191
Test Rewards Max                  0.0123781
Test Rewards Min                  0.00054453
Test Returns Mean                 0.602313
Test Returns Std                  0.00276615
Test Returns Max                  0.607012
Test Returns Min                  0.599104
Test Actions Mean                 0.017575
Test Actions Std                  0.153375
Test Actions Max                  0.456592
Test Actions Min                 -0.67923
Num Paths                         8
Exploration Rewards Mean         -0.00635322
Exploration Rewards Std           0.00760836
Exploration Rewards Max           0.00714977
Exploration Rewards Min          -0.0212671
Exploration Returns Mean         -0.796535
Exploration Returns Std           0.00806189
Exploration Returns Max          -0.783948
Exploration Returns Min          -0.808113
Exploration Actions Mean          0.014937
Exploration Actions Std           0.588383
Exploration Actions Max           0.998958
Exploration Actions Min          -0.995746
AverageReturn                     0.602313
Number of train steps total  540844
Number of env steps total    541000
Number of rollouts total       4279
Train Time (s)                   20.7733
(Previous) Eval Time (s)          2.684e-06
Sample Time (s)                  16.4706
Epoch Time (s)                   37.2439
Total Train Time (s)          71059.9
Epoch                           540
---------------------------  ---------------
2018-05-16 16:12:40.973718 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #540 | Epoch Duration: 220.91420912742615
2018-05-16 16:12:40.973838 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #540 | Started Training: True
2018-05-16 16:15:34.076344 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #541 | Epoch Duration: 173.10239791870117
2018-05-16 16:15:34.076596 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #541 | Started Training: True
2018-05-16 16:18:36.256695 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #542 | Epoch Duration: 182.17997026443481
2018-05-16 16:18:36.256978 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #542 | Started Training: True
2018-05-16 16:21:31.746696 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #543 | Epoch Duration: 175.48955512046814
2018-05-16 16:21:31.746944 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #543 | Started Training: True
2018-05-16 16:24:28.730029 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #544 | Epoch Duration: 176.9829556941986
2018-05-16 16:24:28.732072 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #544 | Started Training: True
2018-05-16 16:27:28.930310 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #545 | Epoch Duration: 180.1980803012848
2018-05-16 16:27:28.930545 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #545 | Started Training: True
2018-05-16 16:30:30.382555 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #546 | Epoch Duration: 181.45187640190125
2018-05-16 16:30:30.382804 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #546 | Started Training: True
2018-05-16 16:33:29.693327 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #547 | Epoch Duration: 179.31038856506348
2018-05-16 16:33:29.693558 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #547 | Started Training: True
2018-05-16 16:36:16.559153 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #548 | Epoch Duration: 166.8654339313507
2018-05-16 16:36:16.559364 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #548 | Started Training: True
2018-05-16 16:36:54.110359 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #549 | Epoch Duration: 37.550840854644775
2018-05-16 16:36:54.110630 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #549 | Started Training: True
2018-05-16 16:37:45.015703 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #550 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           2.00655
VF Loss                           1.35654
Policy Loss                       1.55078
Q Predictions Mean              511.826
Q Predictions Std               271.055
Q Predictions Max               868.136
Q Predictions Min                 3.72629
V Predictions Mean              523.749
V Predictions Std               271.597
V Predictions Max               880
V Predictions Min                15.0083
Log Pis Mean                    -12.1439
Log Pis Std                       0.65885
Log Pis Max                      -9.81369
Log Pis Min                     -14.4171
Policy mu Mean                    0.0216492
Policy mu Std                     0.0807073
Policy mu Max                     0.446099
Policy mu Min                    -0.262746
Policy log std Mean              -0.13585
Policy log std Std                0.0098066
Policy log std Max               -0.0960078
Policy log std Min               -0.18399
Test Rewards Mean                 0.00490436
Test Rewards Std                  0.00303725
Test Rewards Max                  0.0116143
Test Rewards Min                  0.000512487
Test Returns Mean                 0.583619
Test Returns Std                  0.00137437
Test Returns Max                  0.586567
Test Returns Min                  0.581991
Test Actions Mean                -0.0150521
Test Actions Std                  0.143383
Test Actions Max                  0.460468
Test Actions Min                 -0.391407
Num Paths                         8
Exploration Rewards Mean         -0.00626353
Exploration Rewards Std           0.00762533
Exploration Rewards Max           0.00740197
Exploration Rewards Min          -0.021242
Exploration Returns Mean         -0.786074
Exploration Returns Std           0.00790969
Exploration Returns Max          -0.775856
Exploration Returns Min          -0.799969
Exploration Actions Mean          0.017897
Exploration Actions Std           0.586901
Exploration Actions Max           0.997563
Exploration Actions Min          -0.997486
AverageReturn                     0.583619
Number of train steps total  550844
Number of env steps total    551000
Number of rollouts total       4358
Train Time (s)                   20.5286
(Previous) Eval Time (s)          2.57e-06
Sample Time (s)                  16.4124
Epoch Time (s)                   36.941
Total Train Time (s)          72724.7
Epoch                           550
---------------------------  ----------------
2018-05-16 16:40:25.973423 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #550 | Epoch Duration: 211.8626790046692
2018-05-16 16:40:25.973535 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #550 | Started Training: True
2018-05-16 16:43:28.664483 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #551 | Epoch Duration: 182.69085001945496
2018-05-16 16:43:28.664739 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #551 | Started Training: True
2018-05-16 16:46:33.928407 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #552 | Epoch Duration: 185.26352643966675
2018-05-16 16:46:33.928660 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #552 | Started Training: True
2018-05-16 16:49:35.828534 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #553 | Epoch Duration: 181.89974188804626
2018-05-16 16:49:35.828771 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #553 | Started Training: True
2018-05-16 16:52:35.540569 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #554 | Epoch Duration: 179.71167087554932
2018-05-16 16:52:35.540822 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #554 | Started Training: True
2018-05-16 16:55:40.201913 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #555 | Epoch Duration: 184.66096591949463
2018-05-16 16:55:40.202159 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #555 | Started Training: True
2018-05-16 16:59:11.659661 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #556 | Epoch Duration: 211.4573838710785
2018-05-16 16:59:11.659897 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #556 | Started Training: True
2018-05-16 17:02:21.285147 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #557 | Epoch Duration: 189.6251299381256
2018-05-16 17:02:21.285359 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #557 | Started Training: True
2018-05-16 17:05:48.742151 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #558 | Epoch Duration: 207.4566731452942
2018-05-16 17:05:48.742420 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #558 | Started Training: True
2018-05-16 17:06:55.798815 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #559 | Epoch Duration: 67.05625629425049
2018-05-16 17:06:55.799064 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #559 | Started Training: True
2018-05-16 17:07:48.153249 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #560 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           1.18534
VF Loss                           1.41947
Policy Loss                       3.77386
Q Predictions Mean              532.435
Q Predictions Std               254.753
Q Predictions Max               866.71
Q Predictions Min                 0.721756
V Predictions Mean              544.297
V Predictions Std               254.222
V Predictions Max               878.203
V Predictions Min                13.4154
Log Pis Mean                    -12.1866
Log Pis Std                       0.663107
Log Pis Max                     -10.4853
Log Pis Min                     -14.4517
Policy mu Mean                    0.0180457
Policy mu Std                     0.0893257
Policy mu Max                     0.451782
Policy mu Min                    -0.315395
Policy log std Mean              -0.134377
Policy log std Std                0.0119015
Policy log std Max               -0.0967742
Policy log std Min               -0.208585
Test Rewards Mean                 0.00487443
Test Rewards Std                  0.00341906
Test Rewards Max                  0.0133411
Test Rewards Min                 -0.000488541
Test Returns Mean                 0.594681
Test Returns Std                  0.00216742
Test Returns Max                  0.59781
Test Returns Min                  0.592051
Test Actions Mean                -0.0230739
Test Actions Std                  0.147673
Test Actions Max                  0.427271
Test Actions Min                 -0.634401
Num Paths                         9
Exploration Rewards Mean         -0.00643764
Exploration Rewards Std           0.0076473
Exploration Rewards Max           0.00684168
Exploration Rewards Min          -0.0213076
Exploration Returns Mean         -0.798267
Exploration Returns Std           0.00997844
Exploration Returns Max          -0.78241
Exploration Returns Min          -0.815422
Exploration Actions Mean          0.0169664
Exploration Actions Std           0.590268
Exploration Actions Max           0.997364
Exploration Actions Min          -0.999238
AverageReturn                     0.594681
Number of train steps total  560844
Number of env steps total    561000
Number of rollouts total       4437
Train Time (s)                   20.4512
(Previous) Eval Time (s)          2.582e-06
Sample Time (s)                  17.7115
Epoch Time (s)                   38.1626
Total Train Time (s)          74535.8
Epoch                           560
---------------------------  ----------------
2018-05-16 17:10:37.414124 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #560 | Epoch Duration: 221.61494493484497
2018-05-16 17:10:37.414278 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #560 | Started Training: True
2018-05-16 17:14:00.291672 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #561 | Epoch Duration: 202.8772487640381
2018-05-16 17:14:00.291927 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #561 | Started Training: True
2018-05-16 17:17:23.106921 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #562 | Epoch Duration: 202.81485652923584
2018-05-16 17:17:23.107170 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #562 | Started Training: True
2018-05-16 17:20:44.156824 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #563 | Epoch Duration: 201.04952025413513
2018-05-16 17:20:44.157062 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #563 | Started Training: True
2018-05-16 17:24:28.195072 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #564 | Epoch Duration: 224.03788542747498
2018-05-16 17:24:28.198710 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #564 | Started Training: True
2018-05-16 17:27:51.492825 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #565 | Epoch Duration: 203.29392623901367
2018-05-16 17:27:51.493045 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #565 | Started Training: True
2018-05-16 17:30:55.064600 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #566 | Epoch Duration: 183.5713894367218
2018-05-16 17:30:55.064837 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #566 | Started Training: True
2018-05-16 17:33:51.679026 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #567 | Epoch Duration: 176.6140651702881
2018-05-16 17:33:51.679275 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #567 | Started Training: True
2018-05-16 17:36:51.276383 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #568 | Epoch Duration: 179.59697699546814
2018-05-16 17:36:51.276600 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #568 | Started Training: True
2018-05-16 17:37:31.402460 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #569 | Epoch Duration: 40.12574076652527
2018-05-16 17:37:31.402709 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #569 | Started Training: True
2018-05-16 17:38:22.695323 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #570 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           2.32998
VF Loss                           2.29873
Policy Loss                     -13.7208
Q Predictions Mean              549.859
Q Predictions Std               241.194
Q Predictions Max               865.992
Q Predictions Min                10.9752
V Predictions Mean              563.259
V Predictions Std               240.797
V Predictions Max               878.262
V Predictions Min                26.8341
Log Pis Mean                    -12.0947
Log Pis Std                       0.618482
Log Pis Max                     -10.3187
Log Pis Min                     -14.5688
Policy mu Mean                    0.0166645
Policy mu Std                     0.0874336
Policy mu Max                     0.463958
Policy mu Min                    -0.302522
Policy log std Mean              -0.134289
Policy log std Std                0.00898703
Policy log std Max               -0.100795
Policy log std Min               -0.190531
Test Rewards Mean                 0.0048033
Test Rewards Std                  0.00308003
Test Rewards Max                  0.0123881
Test Rewards Min                  0.000263783
Test Returns Mean                 0.619025
Test Returns Std                  0.00138865
Test Returns Max                  0.620916
Test Returns Min                  0.615944
Test Actions Mean                -0.00693829
Test Actions Std                  0.144314
Test Actions Max                  0.403205
Test Actions Min                 -0.761701
Num Paths                         8
Exploration Rewards Mean         -0.00646623
Exploration Rewards Std           0.00768914
Exploration Rewards Max           0.00756932
Exploration Rewards Min          -0.0213152
Exploration Returns Mean         -0.79858
Exploration Returns Std           0.010753
Exploration Returns Max          -0.78007
Exploration Returns Min          -0.815061
Exploration Actions Mean          0.0111558
Exploration Actions Std           0.589863
Exploration Actions Max           0.998893
Exploration Actions Min          -0.999067
AverageReturn                     0.619025
Number of train steps total  570844
Number of env steps total    571000
Number of rollouts total       4516
Train Time (s)                   20.7646
(Previous) Eval Time (s)          2.588e-06
Sample Time (s)                  16.0866
Epoch Time (s)                   36.8511
Total Train Time (s)          76356.6
Epoch                           570
---------------------------  ----------------
2018-05-16 17:40:58.403292 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #570 | Epoch Duration: 207.00047159194946
2018-05-16 17:40:58.403401 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #570 | Started Training: True
2018-05-16 17:41:35.434380 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #571 | Epoch Duration: 37.03088116645813
2018-05-16 17:41:35.436767 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #571 | Started Training: True
2018-05-16 17:42:11.029032 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #572 | Epoch Duration: 35.59209132194519
2018-05-16 17:42:11.030269 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #572 | Started Training: True
2018-05-16 17:42:48.118948 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #573 | Epoch Duration: 37.088480949401855
2018-05-16 17:42:48.119199 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #573 | Started Training: True
2018-05-16 17:43:23.804862 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #574 | Epoch Duration: 35.6855149269104
2018-05-16 17:43:23.805146 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #574 | Started Training: True
2018-05-16 17:44:01.930367 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #575 | Epoch Duration: 38.12506055831909
2018-05-16 17:44:01.930593 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #575 | Started Training: True
2018-05-16 17:44:39.254613 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #576 | Epoch Duration: 37.32390642166138
2018-05-16 17:44:39.254823 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #576 | Started Training: True
2018-05-16 17:45:15.893818 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #577 | Epoch Duration: 36.63881993293762
2018-05-16 17:45:15.894030 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #577 | Started Training: True
2018-05-16 17:45:51.886840 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #578 | Epoch Duration: 35.99241757392883
2018-05-16 17:45:51.887104 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #578 | Started Training: True
2018-05-16 17:46:28.768615 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #579 | Epoch Duration: 36.881346702575684
2018-05-16 17:46:28.768862 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #579 | Started Training: True
2018-05-16 17:47:19.812096 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #580 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           2.8955
VF Loss                           6.40887
Policy Loss                      -6.56625
Q Predictions Mean              506.329
Q Predictions Std               263.613
Q Predictions Max               865.231
Q Predictions Min                 6.15398
V Predictions Mean              519.2
V Predictions Std               264.594
V Predictions Max               878.087
V Predictions Min                20.475
Log Pis Mean                    -12.214
Log Pis Std                       0.62336
Log Pis Max                     -10.2839
Log Pis Min                     -14.4394
Policy mu Mean                    0.01171
Policy mu Std                     0.0841835
Policy mu Max                     0.469718
Policy mu Min                    -0.271241
Policy log std Mean              -0.13575
Policy log std Std                0.0116445
Policy log std Max               -0.0865126
Policy log std Min               -0.202469
Test Rewards Mean                 0.00464491
Test Rewards Std                  0.00309543
Test Rewards Max                  0.0132386
Test Rewards Min                 -0.000182603
Test Returns Mean                 0.636933
Test Returns Std                  0.0197959
Test Returns Max                  0.660419
Test Returns Min                  0.600178
Test Actions Mean                 0.0042381
Test Actions Std                  0.183182
Test Actions Max                  0.49569
Test Actions Min                 -0.864025
Num Paths                         8
Exploration Rewards Mean         -0.00647516
Exploration Rewards Std           0.00763282
Exploration Rewards Max           0.00613051
Exploration Rewards Min          -0.0211873
Exploration Returns Mean         -0.801301
Exploration Returns Std           0.0098736
Exploration Returns Max          -0.78138
Exploration Returns Min          -0.810169
Exploration Actions Mean          0.0242023
Exploration Actions Std           0.591446
Exploration Actions Max           0.996927
Exploration Actions Min          -0.995514
AverageReturn                     0.636933
Number of train steps total  580844
Number of env steps total    581000
Number of rollouts total       4595
Train Time (s)                   20.3692
(Previous) Eval Time (s)          2.431e-06
Sample Time (s)                  15.9861
Epoch Time (s)                   36.3552
Total Train Time (s)          76919.4
Epoch                           580
---------------------------  ----------------
2018-05-16 17:50:21.440717 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #580 | Epoch Duration: 232.6717345714569
2018-05-16 17:50:21.440825 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #580 | Started Training: True
2018-05-16 17:50:58.534121 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #581 | Epoch Duration: 37.093196868896484
2018-05-16 17:50:58.535167 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #581 | Started Training: True
2018-05-16 17:51:34.566115 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #582 | Epoch Duration: 36.030781269073486
2018-05-16 17:51:34.566324 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #582 | Started Training: True
2018-05-16 17:52:11.692215 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #583 | Epoch Duration: 37.12570810317993
2018-05-16 17:52:11.692458 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #583 | Started Training: True
2018-05-16 17:52:47.582770 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #584 | Epoch Duration: 35.890180826187134
2018-05-16 17:52:47.583985 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #584 | Started Training: True
2018-05-16 17:53:24.143061 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #585 | Epoch Duration: 36.55885863304138
2018-05-16 17:53:24.143274 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #585 | Started Training: True
2018-05-16 17:54:01.814667 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #586 | Epoch Duration: 37.67122745513916
2018-05-16 17:54:01.814892 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #586 | Started Training: True
2018-05-16 17:54:38.645953 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #587 | Epoch Duration: 36.83094263076782
2018-05-16 17:54:38.646154 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #587 | Started Training: True
2018-05-16 17:55:15.422511 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #588 | Epoch Duration: 36.776246309280396
2018-05-16 17:55:15.422731 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #588 | Started Training: True
2018-05-16 17:55:53.080882 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #589 | Epoch Duration: 37.657999753952026
2018-05-16 17:55:53.081152 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #589 | Started Training: True
2018-05-16 17:56:44.448858 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #590 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           1.23909
VF Loss                           1.48797
Policy Loss                       7.78297
Q Predictions Mean              556.446
Q Predictions Std               242.855
Q Predictions Max               864.219
Q Predictions Min                 3.18271
V Predictions Mean              567.969
V Predictions Std               242.571
V Predictions Max               878.425
V Predictions Min                15.3489
Log Pis Mean                    -12.2126
Log Pis Std                       0.633361
Log Pis Max                     -10.5831
Log Pis Min                     -13.8355
Policy mu Mean                    0.00957661
Policy mu Std                     0.0856286
Policy mu Max                     0.428129
Policy mu Min                    -0.321001
Policy log std Mean              -0.13321
Policy log std Std                0.00929431
Policy log std Max               -0.10326
Policy log std Min               -0.194294
Test Rewards Mean                 0.00502819
Test Rewards Std                  0.00282965
Test Rewards Max                  0.0115313
Test Rewards Min                  0.000201446
Test Returns Mean                 0.660579
Test Returns Std                  0.00265683
Test Returns Max                  0.664585
Test Returns Min                  0.656779
Test Actions Mean                 0.00748319
Test Actions Std                  0.13864
Test Actions Max                  0.400037
Test Actions Min                 -0.722026
Num Paths                         8
Exploration Rewards Mean         -0.00644351
Exploration Rewards Std           0.00764205
Exploration Rewards Max           0.00623294
Exploration Rewards Min          -0.021312
Exploration Returns Mean         -0.79819
Exploration Returns Std           0.00435373
Exploration Returns Max          -0.79046
Exploration Returns Min          -0.805411
Exploration Actions Mean          0.0158249
Exploration Actions Std           0.588047
Exploration Actions Max           0.997487
Exploration Actions Min          -0.996398
AverageReturn                     0.660579
Number of train steps total  590844
Number of env steps total    591000
Number of rollouts total       4677
Train Time (s)                   20.6984
(Previous) Eval Time (s)          2.731e-06
Sample Time (s)                  15.8349
Epoch Time (s)                   36.5332
Total Train Time (s)          77464.9
Epoch                           590
---------------------------  ----------------
2018-05-16 17:59:27.088449 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #590 | Epoch Duration: 214.00714492797852
2018-05-16 17:59:27.088557 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #590 | Started Training: True
2018-05-16 18:00:03.739300 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #591 | Epoch Duration: 36.65064358711243
2018-05-16 18:00:03.739579 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #591 | Started Training: True
2018-05-16 18:00:41.063870 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #592 | Epoch Duration: 37.32369375228882
2018-05-16 18:00:41.064952 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #592 | Started Training: True
2018-05-16 18:01:17.015573 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #593 | Epoch Duration: 35.95046591758728
2018-05-16 18:01:17.015844 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #593 | Started Training: True
2018-05-16 18:03:42.357938 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #594 | Epoch Duration: 145.34193348884583
2018-05-16 18:03:42.358172 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #594 | Started Training: True
2018-05-16 18:06:37.938520 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #595 | Epoch Duration: 175.58022356033325
2018-05-16 18:06:37.938770 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #595 | Started Training: True
2018-05-16 18:09:31.529361 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #596 | Epoch Duration: 173.59045934677124
2018-05-16 18:09:31.529609 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #596 | Started Training: True
2018-05-16 18:12:28.435302 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #597 | Epoch Duration: 176.90554976463318
2018-05-16 18:12:28.435538 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #597 | Started Training: True
2018-05-16 18:15:23.072272 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #598 | Epoch Duration: 174.6366057395935
2018-05-16 18:15:23.076256 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #598 | Started Training: True
2018-05-16 18:18:21.873045 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #599 | Epoch Duration: 178.79655599594116
2018-05-16 18:18:21.873299 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #599 | Started Training: True
2018-05-16 18:21:55.035079 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #600 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           1.39368
VF Loss                           3.65093
Policy Loss                     -13.0934
Q Predictions Mean              504.184
Q Predictions Std               241.682
Q Predictions Max               860.326
Q Predictions Min                 6.07328
V Predictions Mean              517.477
V Predictions Std               242.747
V Predictions Max               875.315
V Predictions Min                19.5151
Log Pis Mean                    -12.2248
Log Pis Std                       0.59394
Log Pis Max                     -10.3442
Log Pis Min                     -13.6741
Policy mu Mean                    0.0127536
Policy mu Std                     0.0792449
Policy mu Max                     0.443158
Policy mu Min                    -0.296452
Policy log std Mean              -0.133081
Policy log std Std                0.00852585
Policy log std Max               -0.100089
Policy log std Min               -0.159781
Test Rewards Mean                 0.00467352
Test Rewards Std                  0.00321778
Test Rewards Max                  0.0115557
Test Rewards Min                 -0.000510805
Test Returns Mean                 0.594121
Test Returns Std                  0.00368154
Test Returns Max                  0.600056
Test Returns Min                  0.588973
Test Actions Mean                 0.00494264
Test Actions Std                  0.126444
Test Actions Max                  0.349952
Test Actions Min                 -0.66703
Num Paths                         8
Exploration Rewards Mean         -0.00650926
Exploration Rewards Std           0.00767801
Exploration Rewards Max           0.0077497
Exploration Rewards Min          -0.0211776
Exploration Returns Mean         -0.798198
Exploration Returns Std           0.0105377
Exploration Returns Max          -0.780807
Exploration Returns Min          -0.816583
Exploration Actions Mean          0.0141464
Exploration Actions Std           0.587992
Exploration Actions Max           0.997646
Exploration Actions Min          -0.998444
AverageReturn                     0.594121
Number of train steps total  600844
Number of env steps total    601000
Number of rollouts total       4759
Train Time (s)                   95.7684
(Previous) Eval Time (s)          2.703e-06
Sample Time (s)                 101.56
Epoch Time (s)                  197.329
Total Train Time (s)          78975.4
Epoch                           600
---------------------------  ----------------
2018-05-16 18:24:37.898072 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #600 | Epoch Duration: 376.0246624946594
2018-05-16 18:24:37.898182 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #600 | Started Training: True
2018-05-16 18:25:15.678455 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #601 | Epoch Duration: 37.78017997741699
2018-05-16 18:25:15.678672 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #601 | Started Training: True
2018-05-16 18:25:52.793627 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #602 | Epoch Duration: 37.114771127700806
2018-05-16 18:25:52.793851 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #602 | Started Training: True
2018-05-16 18:26:30.031143 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #603 | Epoch Duration: 37.237120151519775
2018-05-16 18:26:30.031416 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #603 | Started Training: True
2018-05-16 18:27:07.090145 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #604 | Epoch Duration: 37.05856800079346
2018-05-16 18:27:07.092509 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #604 | Started Training: True
2018-05-16 18:28:49.010515 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #605 | Epoch Duration: 101.91784596443176
2018-05-16 18:28:49.010723 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #605 | Started Training: True
2018-05-16 18:31:43.559940 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #606 | Epoch Duration: 174.5490620136261
2018-05-16 18:31:43.560157 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #606 | Started Training: True
2018-05-16 18:34:38.070237 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #607 | Epoch Duration: 174.50991773605347
2018-05-16 18:34:38.072380 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #607 | Started Training: True
2018-05-16 18:37:34.192902 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #608 | Epoch Duration: 176.12034821510315
2018-05-16 18:37:34.193164 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #608 | Started Training: True
2018-05-16 18:40:31.046214 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #609 | Epoch Duration: 176.8529188632965
2018-05-16 18:40:31.046482 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #609 | Started Training: True
2018-05-16 18:43:44.073828 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #610 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           1.40617
VF Loss                           0.94482
Policy Loss                       2.5161
Q Predictions Mean              535.49
Q Predictions Std               249.647
Q Predictions Max               858.616
Q Predictions Min                -3.17858
V Predictions Mean              547.434
V Predictions Std               249.656
V Predictions Max               870.078
V Predictions Min                 5.21235
Log Pis Mean                    -12.2226
Log Pis Std                       0.518073
Log Pis Max                     -10.7884
Log Pis Min                     -13.3392
Policy mu Mean                    0.0138524
Policy mu Std                     0.0750811
Policy mu Max                     0.392844
Policy mu Min                    -0.287016
Policy log std Mean              -0.134894
Policy log std Std                0.00680647
Policy log std Max               -0.0999309
Policy log std Min               -0.170172
Test Rewards Mean                 0.00373625
Test Rewards Std                  0.00646591
Test Rewards Max                  0.0184423
Test Rewards Min                 -0.00671592
Test Returns Mean                 0.591395
Test Returns Std                  0.00625482
Test Returns Max                  0.599299
Test Returns Min                  0.580899
Test Actions Mean                 0.0201271
Test Actions Std                  0.192653
Test Actions Max                  0.441225
Test Actions Min                 -0.827654
Num Paths                         6
Exploration Rewards Mean         -0.00637813
Exploration Rewards Std           0.00766349
Exploration Rewards Max           0.00783667
Exploration Rewards Min          -0.0215058
Exploration Returns Mean         -0.801519
Exploration Returns Std           0.00557637
Exploration Returns Max          -0.794204
Exploration Returns Min          -0.811398
Exploration Actions Mean          0.00674973
Exploration Actions Std           0.589415
Exploration Actions Max           0.996117
Exploration Actions Min          -0.99753
AverageReturn                     0.591395
Number of train steps total  610844
Number of env steps total    611000
Number of rollouts total       4835
Train Time (s)                   84.11
(Previous) Eval Time (s)          2.644e-06
Sample Time (s)                  93.028
Epoch Time (s)                  177.138
Total Train Time (s)          80372.4
Epoch                           610
---------------------------  ---------------
2018-05-16 18:47:55.131651 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #610 | Epoch Duration: 444.0850510597229
2018-05-16 18:47:55.131762 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #610 | Started Training: True
2018-05-16 18:48:33.725706 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #611 | Epoch Duration: 38.59384822845459
2018-05-16 18:48:33.725912 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #611 | Started Training: True
2018-05-16 18:49:11.150604 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #612 | Epoch Duration: 37.424540758132935
2018-05-16 18:49:11.150861 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #612 | Started Training: True
2018-05-16 18:49:48.078554 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #613 | Epoch Duration: 36.92757320404053
2018-05-16 18:49:48.078774 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #613 | Started Training: True
2018-05-16 18:50:27.436433 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #614 | Epoch Duration: 39.35749053955078
2018-05-16 18:50:27.439861 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #614 | Started Training: True
2018-05-16 18:53:24.644009 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #615 | Epoch Duration: 177.20395970344543
2018-05-16 18:53:24.645069 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #615 | Started Training: True
2018-05-16 18:56:24.421050 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #616 | Epoch Duration: 179.7758309841156
2018-05-16 18:56:24.421267 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #616 | Started Training: True
2018-05-16 18:59:23.436612 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #617 | Epoch Duration: 179.01518440246582
2018-05-16 18:59:23.436860 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #617 | Started Training: True
2018-05-16 19:02:27.864302 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #618 | Epoch Duration: 184.42731261253357
2018-05-16 19:02:27.864533 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #618 | Started Training: True
2018-05-16 19:05:27.261445 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #619 | Epoch Duration: 179.39678955078125
2018-05-16 19:05:27.261679 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #619 | Started Training: True
2018-05-16 19:08:42.536628 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #620 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           1.89278
VF Loss                           1.10082
Policy Loss                      -0.829365
Q Predictions Mean              529.225
Q Predictions Std               242.226
Q Predictions Max               862.379
Q Predictions Min                69.82
V Predictions Mean              541.51
V Predictions Std               241.804
V Predictions Max               873.961
V Predictions Min                84.5721
Log Pis Mean                    -12.2147
Log Pis Std                       0.674933
Log Pis Max                     -10.2836
Log Pis Min                     -13.8098
Policy mu Mean                    0.0257709
Policy mu Std                     0.0913034
Policy mu Max                     0.461674
Policy mu Min                    -0.455004
Policy log std Mean              -0.134806
Policy log std Std                0.0108585
Policy log std Max               -0.0872772
Policy log std Min               -0.187647
Test Rewards Mean                -0.00168417
Test Rewards Std                  0.0042252
Test Rewards Max                  0.0171482
Test Rewards Min                 -0.0116319
Test Returns Mean                -0.348624
Test Returns Std                  0.457684
Test Returns Max                  0.564356
Test Returns Min                 -0.640121
Test Actions Mean                -0.0509298
Test Actions Std                  0.26177
Test Actions Max                  0.707163
Test Actions Min                 -0.958238
Num Paths                         8
Exploration Rewards Mean         -0.00649533
Exploration Rewards Std           0.00764164
Exploration Rewards Max           0.0065753
Exploration Rewards Min          -0.0212985
Exploration Returns Mean         -0.795678
Exploration Returns Std           0.00789189
Exploration Returns Max          -0.782198
Exploration Returns Min          -0.806641
Exploration Actions Mean          0.00844305
Exploration Actions Std           0.586496
Exploration Actions Max           0.995552
Exploration Actions Min          -0.997989
AverageReturn                    -0.348624
Number of train steps total  620844
Number of env steps total    621000
Number of rollouts total       4915
Train Time (s)                   88.0052
(Previous) Eval Time (s)          2.188e-06
Sample Time (s)                  91.2976
Epoch Time (s)                  179.303
Total Train Time (s)          82072.4
Epoch                           620
---------------------------  ---------------
2018-05-16 19:16:15.403227 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #620 | Epoch Duration: 648.1414320468903
2018-05-16 19:16:15.403369 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #620 | Started Training: True
2018-05-16 19:19:14.250973 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #621 | Epoch Duration: 178.84749031066895
2018-05-16 19:19:14.252210 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #621 | Started Training: True
2018-05-16 19:22:20.746350 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #622 | Epoch Duration: 186.49399042129517
2018-05-16 19:22:20.749580 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #622 | Started Training: True
2018-05-16 19:25:20.647722 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #623 | Epoch Duration: 179.89794754981995
2018-05-16 19:25:20.647972 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #623 | Started Training: True
2018-05-16 19:28:24.272492 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #624 | Epoch Duration: 183.62438440322876
2018-05-16 19:28:24.272749 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #624 | Started Training: True
2018-05-16 19:31:46.064671 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #625 | Epoch Duration: 201.7917983531952
2018-05-16 19:31:46.067891 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #625 | Started Training: True
2018-05-16 19:34:47.425103 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #626 | Epoch Duration: 181.35701870918274
2018-05-16 19:34:47.425362 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #626 | Started Training: True
2018-05-16 19:35:39.100323 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #627 | Epoch Duration: 51.67483353614807
2018-05-16 19:35:39.100563 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #627 | Started Training: True
2018-05-16 19:36:15.479461 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #628 | Epoch Duration: 36.37876915931702
2018-05-16 19:36:15.480565 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #628 | Started Training: True
2018-05-16 19:36:53.408090 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #629 | Epoch Duration: 37.92731976509094
2018-05-16 19:36:53.408312 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #629 | Started Training: True
2018-05-16 19:37:45.807068 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #630 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           1.72521
VF Loss                           2.54086
Policy Loss                      -7.21022
Q Predictions Mean              530.964
Q Predictions Std               238.028
Q Predictions Max               863.03
Q Predictions Min                 6.86418
V Predictions Mean              543.96
V Predictions Std               237.399
V Predictions Max               872.981
V Predictions Min                21.198
Log Pis Mean                    -12.2378
Log Pis Std                       0.663543
Log Pis Max                     -10.5674
Log Pis Min                     -14.5084
Policy mu Mean                    0.0195381
Policy mu Std                     0.0929777
Policy mu Max                     0.604531
Policy mu Min                    -0.730101
Policy log std Mean              -0.133203
Policy log std Std                0.0158606
Policy log std Max               -0.0882833
Policy log std Min               -0.256217
Test Rewards Mean                 0.00415209
Test Rewards Std                  0.0062151
Test Rewards Max                  0.0202535
Test Rewards Min                 -0.00458888
Test Returns Mean                 0.644167
Test Returns Std                  0.00318572
Test Returns Max                  0.649243
Test Returns Min                  0.638073
Test Actions Mean                 0.029683
Test Actions Std                  0.131909
Test Actions Max                  0.391255
Test Actions Min                 -0.518054
Num Paths                         8
Exploration Rewards Mean         -0.00643164
Exploration Rewards Std           0.00765032
Exploration Rewards Max           0.00786443
Exploration Rewards Min          -0.0210538
Exploration Returns Mean         -0.794308
Exploration Returns Std           0.00634229
Exploration Returns Max          -0.784336
Exploration Returns Min          -0.804942
Exploration Actions Mean          0.0117042
Exploration Actions Std           0.588844
Exploration Actions Max           0.998236
Exploration Actions Min          -0.996299
AverageReturn                     0.644167
Number of train steps total  630844
Number of env steps total    631000
Number of rollouts total       4994
Train Time (s)                   21.0403
(Previous) Eval Time (s)          2.23801e-06
Sample Time (s)                  15.8544
Epoch Time (s)                   36.8947
Total Train Time (s)          83594.4
Epoch                           630
---------------------------  ----------------
2018-05-16 19:41:37.564283 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #630 | Epoch Duration: 284.1558654308319
2018-05-16 19:41:37.564393 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #630 | Started Training: True
2018-05-16 19:42:14.610313 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #631 | Epoch Duration: 37.045825242996216
2018-05-16 19:42:14.610542 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #631 | Started Training: True
2018-05-16 19:44:43.342717 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #632 | Epoch Duration: 148.73204708099365
2018-05-16 19:44:43.342993 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #632 | Started Training: True
2018-05-16 19:47:45.477652 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #633 | Epoch Duration: 182.13449668884277
2018-05-16 19:47:45.477860 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #633 | Started Training: True
2018-05-16 19:50:42.132877 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #634 | Epoch Duration: 176.6548900604248
2018-05-16 19:50:42.133131 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #634 | Started Training: True
2018-05-16 19:53:39.914844 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #635 | Epoch Duration: 177.7815797328949
2018-05-16 19:53:39.918169 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #635 | Started Training: True
2018-05-16 19:56:37.484319 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #636 | Epoch Duration: 177.5659749507904
2018-05-16 19:56:37.484556 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #636 | Started Training: True
2018-05-16 19:59:33.932038 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #637 | Epoch Duration: 176.4473569393158
2018-05-16 19:59:33.932303 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #637 | Started Training: True
2018-05-16 20:02:33.538113 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #638 | Epoch Duration: 179.60567045211792
2018-05-16 20:02:33.538378 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #638 | Started Training: True
2018-05-16 20:05:38.702847 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #639 | Epoch Duration: 185.16433548927307
2018-05-16 20:05:38.703092 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #639 | Started Training: True
2018-05-16 20:08:37.277929 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #640 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           2.57353
VF Loss                           0.884861
Policy Loss                      -1.5812
Q Predictions Mean              500.97
Q Predictions Std               255.181
Q Predictions Max               859.776
Q Predictions Min                -3.68225
V Predictions Mean              513.418
V Predictions Std               255.171
V Predictions Max               873.216
V Predictions Min                 4.064
Log Pis Mean                    -12.2088
Log Pis Std                       0.57582
Log Pis Max                     -10.8894
Log Pis Min                     -13.8819
Policy mu Mean                    0.0122551
Policy mu Std                     0.0700203
Policy mu Max                     0.460365
Policy mu Min                    -0.333221
Policy log std Mean              -0.134797
Policy log std Std                0.00682662
Policy log std Max               -0.116322
Policy log std Min               -0.181516
Test Rewards Mean                 0.00419467
Test Rewards Std                  0.00616985
Test Rewards Max                  0.0164778
Test Rewards Min                 -0.00296632
Test Returns Mean                 0.580962
Test Returns Std                  0.0163957
Test Returns Max                  0.610609
Test Returns Min                  0.560611
Test Actions Mean                 0.0134544
Test Actions Std                  0.13274
Test Actions Max                  0.460337
Test Actions Min                 -0.667715
Num Paths                         7
Exploration Rewards Mean         -0.00640174
Exploration Rewards Std           0.00757803
Exploration Rewards Max           0.0063008
Exploration Rewards Min          -0.0210967
Exploration Returns Mean         -0.797473
Exploration Returns Std           0.00739574
Exploration Returns Max          -0.787539
Exploration Returns Min          -0.810474
Exploration Actions Mean          0.00143468
Exploration Actions Std           0.588448
Exploration Actions Max           0.99874
Exploration Actions Min          -0.998246
AverageReturn                     0.580962
Number of train steps total  640844
Number of env steps total    641000
Number of rollouts total       5073
Train Time (s)                   78.9522
(Previous) Eval Time (s)          2.35401e-06
Sample Time (s)                  83.4627
Epoch Time (s)                  162.415
Total Train Time (s)          85442.2
Epoch                           640
---------------------------  ----------------
2018-05-16 20:12:25.682439 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #640 | Epoch Duration: 406.9792363643646
2018-05-16 20:12:25.682568 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #640 | Started Training: True
2018-05-16 20:15:18.162839 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #641 | Epoch Duration: 172.48016047477722
2018-05-16 20:15:18.163074 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #641 | Started Training: True
2018-05-16 20:18:15.633277 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #642 | Epoch Duration: 177.47003602981567
2018-05-16 20:18:15.633539 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #642 | Started Training: True
2018-05-16 20:21:13.750630 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #643 | Epoch Duration: 178.11696600914001
2018-05-16 20:21:13.750860 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #643 | Started Training: True
2018-05-16 20:24:19.764680 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #644 | Epoch Duration: 186.0136947631836
2018-05-16 20:24:19.764913 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #644 | Started Training: True
2018-05-16 20:27:22.578643 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #645 | Epoch Duration: 182.81360745429993
2018-05-16 20:27:22.578851 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #645 | Started Training: True
2018-05-16 20:30:21.685430 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #646 | Epoch Duration: 179.1064531803131
2018-05-16 20:30:21.685657 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #646 | Started Training: True
2018-05-16 20:33:18.932458 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #647 | Epoch Duration: 177.2466766834259
2018-05-16 20:33:18.932684 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #647 | Started Training: True
2018-05-16 20:35:59.279619 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #648 | Epoch Duration: 160.34681153297424
2018-05-16 20:35:59.279830 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #648 | Started Training: True
2018-05-16 20:36:37.385982 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #649 | Epoch Duration: 38.106032609939575
2018-05-16 20:36:37.386253 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #649 | Started Training: True
2018-05-16 20:37:31.354750 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #650 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           3.11694
VF Loss                           2.52172
Policy Loss                      14.9251
Q Predictions Mean              507.022
Q Predictions Std               238.057
Q Predictions Max               864.754
Q Predictions Min                 8.4657
V Predictions Mean              518.049
V Predictions Std               238.135
V Predictions Max               876.85
V Predictions Min                18.9266
Log Pis Mean                    -12.257
Log Pis Std                       0.62658
Log Pis Max                      -9.83873
Log Pis Min                     -14.0089
Policy mu Mean                    0.0106812
Policy mu Std                     0.0867824
Policy mu Max                     0.51718
Policy mu Min                    -0.342037
Policy log std Mean              -0.134017
Policy log std Std                0.00923812
Policy log std Max               -0.0991468
Policy log std Min               -0.186469
Test Rewards Mean                 0.00396303
Test Rewards Std                  0.00719755
Test Rewards Max                  0.0208998
Test Rewards Min                 -0.00798499
Test Returns Mean                 0.678339
Test Returns Std                  0.00532286
Test Returns Max                  0.687476
Test Returns Min                  0.669933
Test Actions Mean                -0.00679138
Test Actions Std                  0.185352
Test Actions Max                  0.6663
Test Actions Min                 -0.574116
Num Paths                         8
Exploration Rewards Mean         -0.006392
Exploration Rewards Std           0.00760164
Exploration Rewards Max           0.00698919
Exploration Rewards Min          -0.0214942
Exploration Returns Mean         -0.795005
Exploration Returns Std           0.00860247
Exploration Returns Max          -0.776424
Exploration Returns Min          -0.805909
Exploration Actions Mean          0.009524
Exploration Actions Std           0.586115
Exploration Actions Max           0.998189
Exploration Actions Min          -0.997539
AverageReturn                     0.678339
Number of train steps total  650844
Number of env steps total    651000
Number of rollouts total       5152
Train Time (s)                   21.2457
(Previous) Eval Time (s)          3.073e-06
Sample Time (s)                  16.4965
Epoch Time (s)                   37.7422
Total Train Time (s)          87193.7
Epoch                           650
---------------------------  ---------------
2018-05-16 20:41:37.391978 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #650 | Epoch Duration: 300.0055499076843
2018-05-16 20:41:37.392187 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #650 | Started Training: True
2018-05-16 20:44:38.604560 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #651 | Epoch Duration: 181.21219992637634
2018-05-16 20:44:38.604816 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #651 | Started Training: True
2018-05-16 20:47:32.832132 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #652 | Epoch Duration: 174.22718501091003
2018-05-16 20:47:32.832357 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #652 | Started Training: True
2018-05-16 20:50:26.899139 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #653 | Epoch Duration: 174.06664896011353
2018-05-16 20:50:26.899434 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #653 | Started Training: True
2018-05-16 20:53:25.990248 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #654 | Epoch Duration: 179.0906503200531
2018-05-16 20:53:25.990493 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #654 | Started Training: True
2018-05-16 20:56:28.948727 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #655 | Epoch Duration: 182.95808625221252
2018-05-16 20:56:28.948970 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #655 | Started Training: True
2018-05-16 20:59:29.620316 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #656 | Epoch Duration: 180.67122435569763
2018-05-16 20:59:29.620550 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #656 | Started Training: True
2018-05-16 21:01:05.352771 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #657 | Epoch Duration: 95.73208832740784
2018-05-16 21:01:05.353044 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #657 | Started Training: True
2018-05-16 21:01:42.216760 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #658 | Epoch Duration: 36.86353302001953
2018-05-16 21:01:42.218528 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #658 | Started Training: True
2018-05-16 21:02:19.387692 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #659 | Epoch Duration: 37.16897773742676
2018-05-16 21:02:19.388618 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #659 | Started Training: True
2018-05-16 21:03:12.265500 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #660 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           1.01591
VF Loss                           0.740894
Policy Loss                       0.539989
Q Predictions Mean              499.795
Q Predictions Std               244.373
Q Predictions Max               860.596
Q Predictions Min                 6.41911
V Predictions Mean              512.101
V Predictions Std               244.331
V Predictions Max               874.202
V Predictions Min                19.3422
Log Pis Mean                    -12.2492
Log Pis Std                       0.724641
Log Pis Max                     -10.4205
Log Pis Min                     -15.1119
Policy mu Mean                    0.0244489
Policy mu Std                     0.0849239
Policy mu Max                     0.479619
Policy mu Min                    -0.320711
Policy log std Mean              -0.137667
Policy log std Std                0.00925109
Policy log std Max               -0.0980003
Policy log std Min               -0.21084
Test Rewards Mean                 0.00384595
Test Rewards Std                  0.00685954
Test Rewards Max                  0.0212349
Test Rewards Min                 -0.00706365
Test Returns Mean                 0.658298
Test Returns Std                  0.0200111
Test Returns Max                  0.681875
Test Returns Min                  0.62622
Test Actions Mean                -0.0152192
Test Actions Std                  0.187109
Test Actions Max                  0.574789
Test Actions Min                 -0.599516
Num Paths                         8
Exploration Rewards Mean         -0.00643319
Exploration Rewards Std           0.00766208
Exploration Rewards Max           0.007
Exploration Rewards Min          -0.0210991
Exploration Returns Mean         -0.800932
Exploration Returns Std           0.00759451
Exploration Returns Max          -0.788851
Exploration Returns Min          -0.815403
Exploration Actions Mean          0.00391808
Exploration Actions Std           0.590676
Exploration Actions Max           0.999271
Exploration Actions Min          -0.998121
AverageReturn                     0.658298
Number of train steps total  660844
Number of env steps total    661000
Number of rollouts total       5230
Train Time (s)                   20.2812
(Previous) Eval Time (s)          2.342e-06
Sample Time (s)                  16.123
Epoch Time (s)                   36.4042
Total Train Time (s)          88722.4
Epoch                           660
---------------------------  ---------------
2018-05-16 21:07:06.318643 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #660 | Epoch Duration: 286.9298732280731
2018-05-16 21:07:06.318760 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #660 | Started Training: True
2018-05-16 21:10:02.546341 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #661 | Epoch Duration: 176.2274820804596
2018-05-16 21:10:02.546649 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #661 | Started Training: True
2018-05-16 21:12:59.039070 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #662 | Epoch Duration: 176.49228763580322
2018-05-16 21:12:59.039324 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #662 | Started Training: True
2018-05-16 21:16:00.005943 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #663 | Epoch Duration: 180.96648406982422
2018-05-16 21:16:00.006194 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #663 | Started Training: True
2018-05-16 21:18:53.965223 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #664 | Epoch Duration: 173.95887851715088
2018-05-16 21:18:53.967264 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #664 | Started Training: True
2018-05-16 21:21:49.587598 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #665 | Epoch Duration: 175.62016201019287
2018-05-16 21:21:49.587817 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #665 | Started Training: True
2018-05-16 21:24:50.860862 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #666 | Epoch Duration: 181.27289199829102
2018-05-16 21:24:50.864076 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #666 | Started Training: True
2018-05-16 21:26:52.651013 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #667 | Epoch Duration: 121.78675127029419
2018-05-16 21:26:52.651218 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #667 | Started Training: True
2018-05-16 21:27:30.367520 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #668 | Epoch Duration: 37.716169118881226
2018-05-16 21:27:30.367790 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #668 | Started Training: True
2018-05-16 21:28:07.065882 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #669 | Epoch Duration: 36.69792580604553
2018-05-16 21:28:07.066101 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #669 | Started Training: True
2018-05-16 21:28:59.923706 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #670 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           1.5671
VF Loss                           1.68085
Policy Loss                       6.72509
Q Predictions Mean              522.836
Q Predictions Std               254.195
Q Predictions Max               862.159
Q Predictions Min                 8.05492
V Predictions Mean              534.458
V Predictions Std               253.356
V Predictions Max               871.781
V Predictions Min                22.4865
Log Pis Mean                    -12.2429
Log Pis Std                       0.69555
Log Pis Max                      -9.98291
Log Pis Min                     -14.2277
Policy mu Mean                    0.00528862
Policy mu Std                     0.0860904
Policy mu Max                     0.457478
Policy mu Min                    -0.479022
Policy log std Mean              -0.135092
Policy log std Std                0.00983649
Policy log std Max               -0.0864907
Policy log std Min               -0.204616
Test Rewards Mean                 0.00394322
Test Rewards Std                  0.00655879
Test Rewards Max                  0.0165423
Test Rewards Min                 -0.0047626
Test Returns Mean                 0.53677
Test Returns Std                  0.00796659
Test Returns Max                  0.544183
Test Returns Min                  0.519297
Test Actions Mean                -0.0143468
Test Actions Std                  0.0940119
Test Actions Max                  0.385982
Test Actions Min                 -0.279696
Num Paths                         8
Exploration Rewards Mean         -0.00624361
Exploration Rewards Std           0.00761324
Exploration Rewards Max           0.00763721
Exploration Rewards Min          -0.0210518
Exploration Returns Mean         -0.799182
Exploration Returns Std           0.0112215
Exploration Returns Max          -0.782224
Exploration Returns Min          -0.817123
Exploration Actions Mean          0.00329501
Exploration Actions Std           0.589463
Exploration Actions Max           0.999141
Exploration Actions Min          -0.997868
AverageReturn                     0.53677
Number of train steps total  670844
Number of env steps total    671000
Number of rollouts total       5308
Train Time (s)                   20.2958
(Previous) Eval Time (s)          1.972e-06
Sample Time (s)                  15.9944
Epoch Time (s)                   36.2902
Total Train Time (s)          90244.1
Epoch                           670
---------------------------  ---------------
2018-05-16 21:32:28.255157 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #670 | Epoch Duration: 261.18892884254456
2018-05-16 21:32:28.255266 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #670 | Started Training: True
2018-05-16 21:35:26.279519 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #671 | Epoch Duration: 178.02415657043457
2018-05-16 21:35:26.279810 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #671 | Started Training: True
2018-05-16 21:38:31.164267 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #672 | Epoch Duration: 184.88427901268005
2018-05-16 21:38:31.164531 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #672 | Started Training: True
2018-05-16 21:41:32.009670 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #673 | Epoch Duration: 180.8450062274933
2018-05-16 21:41:32.009876 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #673 | Started Training: True
2018-05-16 21:44:32.730142 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #674 | Epoch Duration: 180.72014689445496
2018-05-16 21:44:32.730414 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #674 | Started Training: True
2018-05-16 21:47:31.196475 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #675 | Epoch Duration: 178.46592593193054
2018-05-16 21:47:31.196720 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #675 | Started Training: True
2018-05-16 21:50:32.306861 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #676 | Epoch Duration: 181.1100058555603
2018-05-16 21:50:32.307100 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #676 | Started Training: True
2018-05-16 21:52:21.497871 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #677 | Epoch Duration: 109.19063901901245
2018-05-16 21:52:21.498079 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #677 | Started Training: True
2018-05-16 21:52:57.918319 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #678 | Epoch Duration: 36.42008018493652
2018-05-16 21:52:57.918555 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #678 | Started Training: True
2018-05-16 21:53:35.735562 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #679 | Epoch Duration: 37.81684637069702
2018-05-16 21:53:35.735838 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #679 | Started Training: True
2018-05-16 21:54:28.755667 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #680 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           1.17817
VF Loss                           2.34417
Policy Loss                      13.2689
Q Predictions Mean              535.538
Q Predictions Std               244.989
Q Predictions Max               863.733
Q Predictions Min                -3.41338
V Predictions Mean              546.616
V Predictions Std               244.812
V Predictions Max               873.303
V Predictions Min                 1.57785
Log Pis Mean                    -12.1481
Log Pis Std                       0.693805
Log Pis Max                     -10.6312
Log Pis Min                     -14.576
Policy mu Mean                    0.00364773
Policy mu Std                     0.0845281
Policy mu Max                     0.452824
Policy mu Min                    -0.287013
Policy log std Mean              -0.137241
Policy log std Std                0.00866141
Policy log std Max               -0.0984797
Policy log std Min               -0.18402
Test Rewards Mean                 0.00284877
Test Rewards Std                  0.00603077
Test Rewards Max                  0.0166021
Test Rewards Min                 -0.00739531
Test Returns Mean                 0.500909
Test Returns Std                  0.00866991
Test Returns Max                  0.511648
Test Returns Min                  0.487781
Test Actions Mean                -0.0449065
Test Actions Std                  0.141032
Test Actions Max                  0.475692
Test Actions Min                 -0.522566
Num Paths                         9
Exploration Rewards Mean         -0.00639264
Exploration Rewards Std           0.0075605
Exploration Rewards Max           0.00537791
Exploration Rewards Min          -0.0211325
Exploration Returns Mean         -0.801211
Exploration Returns Std           0.00694582
Exploration Returns Max          -0.788024
Exploration Returns Min          -0.811264
Exploration Actions Mean          0.000232773
Exploration Actions Std           0.589282
Exploration Actions Max           0.9962
Exploration Actions Min          -0.998255
AverageReturn                     0.500909
Number of train steps total  680844
Number of env steps total    681000
Number of rollouts total       5387
Train Time (s)                   20.1001
(Previous) Eval Time (s)          2.866e-06
Sample Time (s)                  16.1804
Epoch Time (s)                   36.2805
Total Train Time (s)          91912.3
Epoch                           680
---------------------------  ----------------
2018-05-16 22:00:16.774543 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #680 | Epoch Duration: 401.0385479927063
2018-05-16 22:00:16.774660 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #680 | Started Training: True
2018-05-16 22:03:18.446269 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #681 | Epoch Duration: 181.67151069641113
2018-05-16 22:03:18.446540 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #681 | Started Training: True
2018-05-16 22:06:13.262677 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #682 | Epoch Duration: 174.81599521636963
2018-05-16 22:06:13.262933 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #682 | Started Training: True
2018-05-16 22:09:08.289455 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #683 | Epoch Duration: 175.02638220787048
2018-05-16 22:09:08.291757 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #683 | Started Training: True
2018-05-16 22:11:19.743018 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #684 | Epoch Duration: 131.45108199119568
2018-05-16 22:11:19.743287 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #684 | Started Training: True
2018-05-16 22:11:55.685093 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #685 | Epoch Duration: 35.9416401386261
2018-05-16 22:11:55.685365 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #685 | Started Training: True
2018-05-16 22:12:32.350377 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #686 | Epoch Duration: 36.664846420288086
2018-05-16 22:12:32.352772 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #686 | Started Training: True
2018-05-16 22:13:09.422722 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #687 | Epoch Duration: 37.06978416442871
2018-05-16 22:13:09.422934 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #687 | Started Training: True
2018-05-16 22:13:45.875357 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #688 | Epoch Duration: 36.452277183532715
2018-05-16 22:13:45.875558 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #688 | Started Training: True
2018-05-16 22:14:22.501701 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #689 | Epoch Duration: 36.626028299331665
2018-05-16 22:14:22.501930 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #689 | Started Training: True
2018-05-16 22:15:16.451263 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #690 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           1.81373
VF Loss                           1.21414
Policy Loss                      -7.16032
Q Predictions Mean              519.38
Q Predictions Std               258.106
Q Predictions Max               861.37
Q Predictions Min                 9.45151
V Predictions Mean              532.293
V Predictions Std               257.773
V Predictions Max               871.84
V Predictions Min                23.3988
Log Pis Mean                    -12.3099
Log Pis Std                       0.633571
Log Pis Max                      -9.53585
Log Pis Min                     -14.271
Policy mu Mean                    0.00344424
Policy mu Std                     0.0949299
Policy mu Max                     0.537825
Policy mu Min                    -0.377085
Policy log std Mean              -0.136977
Policy log std Std                0.0125458
Policy log std Max               -0.0996352
Policy log std Min               -0.201452
Test Rewards Mean                 0.00420311
Test Rewards Std                  0.00504104
Test Rewards Max                  0.0166211
Test Rewards Min                 -0.002819
Test Returns Mean                 0.632868
Test Returns Std                  0.025721
Test Returns Max                  0.675893
Test Returns Min                  0.587234
Test Actions Mean                -0.0373809
Test Actions Std                  0.136444
Test Actions Max                  0.368933
Test Actions Min                 -0.421041
Num Paths                         7
Exploration Rewards Mean         -0.00648043
Exploration Rewards Std           0.00767033
Exploration Rewards Max           0.00705764
Exploration Rewards Min          -0.02127
Exploration Returns Mean         -0.798944
Exploration Returns Std           0.00529567
Exploration Returns Max          -0.790305
Exploration Returns Min          -0.808274
Exploration Actions Mean          0.0166623
Exploration Actions Std           0.589479
Exploration Actions Max           0.997459
Exploration Actions Min          -0.998863
AverageReturn                     0.632868
Number of train steps total  690844
Number of env steps total    691000
Number of rollouts total       5468
Train Time (s)                   21.1381
(Previous) Eval Time (s)          2.042e-06
Sample Time (s)                  15.8855
Epoch Time (s)                   37.0236
Total Train Time (s)          93131.7
Epoch                           690
---------------------------  ---------------
2018-05-16 22:20:36.392034 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #690 | Epoch Duration: 373.8899869918823
2018-05-16 22:20:36.392187 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #690 | Started Training: True
2018-05-16 22:23:33.267946 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #691 | Epoch Duration: 176.87562370300293
2018-05-16 22:23:33.268205 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #691 | Started Training: True
2018-05-16 22:26:23.645695 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #692 | Epoch Duration: 170.37736058235168
2018-05-16 22:26:23.649321 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #692 | Started Training: True
2018-05-16 22:28:53.746570 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #693 | Epoch Duration: 150.09704518318176
2018-05-16 22:28:53.750036 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #693 | Started Training: True
2018-05-16 22:29:29.165014 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #694 | Epoch Duration: 35.41479849815369
2018-05-16 22:29:29.165223 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #694 | Started Training: True
2018-05-16 22:30:05.545831 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #695 | Epoch Duration: 36.380441665649414
2018-05-16 22:30:05.547853 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #695 | Started Training: True
2018-05-16 22:30:42.911352 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #696 | Epoch Duration: 37.363322734832764
2018-05-16 22:30:42.911620 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #696 | Started Training: True
2018-05-16 22:31:19.229837 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #697 | Epoch Duration: 36.31804537773132
2018-05-16 22:31:19.230464 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #697 | Started Training: True
2018-05-16 22:31:55.550905 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #698 | Epoch Duration: 36.320252895355225
2018-05-16 22:31:55.554414 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #698 | Started Training: True
2018-05-16 22:32:32.687770 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #699 | Epoch Duration: 37.13316202163696
2018-05-16 22:32:32.688068 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #699 | Started Training: True
2018-05-16 22:35:28.425245 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #700 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                          14.7006
VF Loss                           1.60747
Policy Loss                      -7.39996
Q Predictions Mean              521.443
Q Predictions Std               259.302
Q Predictions Max               865.574
Q Predictions Min                -2.91984
V Predictions Mean              534.327
V Predictions Std               259.33
V Predictions Max               877.847
V Predictions Min                 6.79823
Log Pis Mean                    -12.2486
Log Pis Std                       0.7113
Log Pis Max                      -9.65121
Log Pis Min                     -15.0965
Policy mu Mean                    0.00849905
Policy mu Std                     0.0880378
Policy mu Max                     0.512362
Policy mu Min                    -0.34974
Policy log std Mean              -0.136554
Policy log std Std                0.00972882
Policy log std Max               -0.0949659
Policy log std Min               -0.197211
Test Rewards Mean                 0.00237202
Test Rewards Std                  0.00613694
Test Rewards Max                  0.017184
Test Rewards Min                 -0.00656557
Test Returns Mean                 0.433289
Test Returns Std                  0.00378932
Test Returns Max                  0.439277
Test Returns Min                  0.428889
Test Actions Mean                -0.0527388
Test Actions Std                  0.142405
Test Actions Max                  0.422136
Test Actions Min                 -0.544485
Num Paths                        10
Exploration Rewards Mean         -0.00632262
Exploration Rewards Std           0.00762574
Exploration Rewards Max           0.00669135
Exploration Rewards Min          -0.0213649
Exploration Returns Mean         -0.800444
Exploration Returns Std           0.00733885
Exploration Returns Max          -0.792878
Exploration Returns Min          -0.815907
Exploration Actions Mean          0.00755087
Exploration Actions Std           0.588506
Exploration Actions Max           0.997895
Exploration Actions Min          -0.998509
AverageReturn                     0.433289
Number of train steps total  700844
Number of env steps total    701000
Number of rollouts total       5549
Train Time (s)                   77.6901
(Previous) Eval Time (s)          2.566e-06
Sample Time (s)                  80.224
Epoch Time (s)                  157.914
Total Train Time (s)          94713.8
Epoch                           700
---------------------------  ---------------
2018-05-16 22:46:58.733342 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #700 | Epoch Duration: 866.0450930595398
2018-05-16 22:46:58.733458 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #700 | Started Training: True
2018-05-16 22:49:56.917607 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #701 | Epoch Duration: 178.1840353012085
2018-05-16 22:49:56.917849 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #701 | Started Training: True
2018-05-16 22:52:54.236207 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #702 | Epoch Duration: 177.31823658943176
2018-05-16 22:52:54.236455 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #702 | Started Training: True
2018-05-16 22:55:50.696873 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #703 | Epoch Duration: 176.46028757095337
2018-05-16 22:55:50.697145 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #703 | Started Training: True
2018-05-16 22:58:42.169418 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #704 | Epoch Duration: 171.47211527824402
2018-05-16 22:58:42.169651 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #704 | Started Training: True
2018-05-16 23:01:36.541139 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #705 | Epoch Duration: 174.37134861946106
2018-05-16 23:01:36.541377 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #705 | Started Training: True
2018-05-16 23:04:35.384874 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #706 | Epoch Duration: 178.84336972236633
2018-05-16 23:04:35.385113 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #706 | Started Training: True
2018-05-16 23:06:54.901310 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #707 | Epoch Duration: 139.51606678962708
2018-05-16 23:06:54.901572 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #707 | Started Training: True
2018-05-16 23:07:31.007816 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #708 | Epoch Duration: 36.10607409477234
2018-05-16 23:07:31.008683 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #708 | Started Training: True
2018-05-16 23:08:07.642777 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #709 | Epoch Duration: 36.63393998146057
2018-05-16 23:08:07.643038 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #709 | Started Training: True
2018-05-16 23:09:02.324687 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #710 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           1.76878
VF Loss                           2.00737
Policy Loss                       3.68036
Q Predictions Mean              558.247
Q Predictions Std               250.616
Q Predictions Max               862.404
Q Predictions Min                -1.82161
V Predictions Mean              570.135
V Predictions Std               249.848
V Predictions Max               872.789
V Predictions Min                 3.76024
Log Pis Mean                    -12.1566
Log Pis Std                       0.671568
Log Pis Max                      -9.93485
Log Pis Min                     -14.2273
Policy mu Mean                    0.0085892
Policy mu Std                     0.0935177
Policy mu Max                     0.555884
Policy mu Min                    -0.389345
Policy log std Mean              -0.134565
Policy log std Std                0.0105989
Policy log std Max               -0.105754
Policy log std Min               -0.184365
Test Rewards Mean                 0.00185256
Test Rewards Std                  0.00533336
Test Rewards Max                  0.0183206
Test Rewards Min                 -0.00676858
Test Returns Mean                 0.442762
Test Returns Std                  0.0314604
Test Returns Max                  0.484065
Test Returns Min                  0.408751
Test Actions Mean                -0.0835757
Test Actions Std                  0.210054
Test Actions Max                  0.566483
Test Actions Min                 -0.715333
Num Paths                         7
Exploration Rewards Mean         -0.00629896
Exploration Rewards Std           0.00765844
Exploration Rewards Max           0.00722194
Exploration Rewards Min          -0.0211591
Exploration Returns Mean         -0.799069
Exploration Returns Std           0.00904364
Exploration Returns Max          -0.78223
Exploration Returns Min          -0.814392
Exploration Actions Mean          0.010303
Exploration Actions Std           0.58844
Exploration Actions Max           0.998769
Exploration Actions Min          -0.99573
AverageReturn                     0.442762
Number of train steps total  710844
Number of env steps total    711000
Number of rollouts total       5625
Train Time (s)                   20.5889
(Previous) Eval Time (s)          2.991e-06
Sample Time (s)                  16.6959
Epoch Time (s)                   37.2849
Total Train Time (s)          96684.6
Epoch                           710
---------------------------  ---------------
2018-05-16 23:19:49.719167 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #710 | Epoch Duration: 702.0759799480438
2018-05-16 23:19:49.719289 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #710 | Started Training: True
2018-05-16 23:20:26.030278 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #711 | Epoch Duration: 36.31089234352112
2018-05-16 23:20:26.030517 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #711 | Started Training: True
2018-05-16 23:21:01.899889 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #712 | Epoch Duration: 35.86920404434204
2018-05-16 23:21:01.900102 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #712 | Started Training: True
2018-05-16 23:21:38.107279 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #713 | Epoch Duration: 36.207019567489624
2018-05-16 23:21:38.109555 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #713 | Started Training: True
2018-05-16 23:22:15.209972 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #714 | Epoch Duration: 37.1002562046051
2018-05-16 23:22:15.211120 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #714 | Started Training: True
2018-05-16 23:24:41.170813 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #715 | Epoch Duration: 145.9595148563385
2018-05-16 23:24:41.171037 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #715 | Started Training: True
2018-05-16 23:27:38.494862 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #716 | Epoch Duration: 177.3236563205719
2018-05-16 23:27:38.495122 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #716 | Started Training: True
2018-05-16 23:30:34.962985 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #717 | Epoch Duration: 176.46773719787598
2018-05-16 23:30:34.963771 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #717 | Started Training: True
2018-05-16 23:33:33.371124 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #718 | Epoch Duration: 178.40714073181152
2018-05-16 23:33:33.371365 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #718 | Started Training: True
2018-05-16 23:36:34.984861 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #719 | Epoch Duration: 181.61336970329285
2018-05-16 23:36:34.985076 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #719 | Started Training: True
2018-05-16 23:39:56.188957 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #720 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                         239.539
VF Loss                         207.391
Policy Loss                     173.967
Q Predictions Mean              580.197
Q Predictions Std               249.436
Q Predictions Max               874.391
Q Predictions Min                 5.82213
V Predictions Mean              578.349
V Predictions Std               248.695
V Predictions Max               874.814
V Predictions Min                 2.55685
Log Pis Mean                    -12.1988
Log Pis Std                       0.633788
Log Pis Max                     -10.3391
Log Pis Min                     -14.5474
Policy mu Mean                    0.00433174
Policy mu Std                     0.0963271
Policy mu Max                     0.402879
Policy mu Min                    -0.417493
Policy log std Mean              -0.136642
Policy log std Std                0.0106216
Policy log std Max               -0.0863306
Policy log std Min               -0.199738
Test Rewards Mean                 0.0045734
Test Rewards Std                  0.00310355
Test Rewards Max                  0.0111931
Test Rewards Min                 -0.000116635
Test Returns Mean                 0.595113
Test Returns Std                  0.00251207
Test Returns Max                  0.601385
Test Returns Min                  0.592855
Test Actions Mean                -0.0126857
Test Actions Std                  0.108868
Test Actions Max                  0.394614
Test Actions Min                 -0.304106
Num Paths                        10
Exploration Rewards Mean         -0.00639003
Exploration Rewards Std           0.00760057
Exploration Rewards Max           0.00622905
Exploration Rewards Min          -0.0214162
Exploration Returns Mean         -0.803866
Exploration Returns Std           0.00710663
Exploration Returns Max          -0.797328
Exploration Returns Min          -0.820587
Exploration Actions Mean          0.0079573
Exploration Actions Std           0.58742
Exploration Actions Max           0.998841
Exploration Actions Min          -0.997988
AverageReturn                     0.595113
Number of train steps total  720844
Number of env steps total    721000
Number of rollouts total       5707
Train Time (s)                   86.1246
(Previous) Eval Time (s)          2.47899e-06
Sample Time (s)                  96.9602
Epoch Time (s)                  183.085
Total Train Time (s)          98062.3
Epoch                           720
---------------------------  ----------------
2018-05-16 23:42:47.640180 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #720 | Epoch Duration: 372.6549446582794
2018-05-16 23:42:47.640288 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #720 | Started Training: True
2018-05-16 23:43:26.063078 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #721 | Epoch Duration: 38.422690629959106
2018-05-16 23:43:26.063351 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #721 | Started Training: True
2018-05-16 23:44:02.970242 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #722 | Epoch Duration: 36.90672707557678
2018-05-16 23:44:02.970477 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #722 | Started Training: True
2018-05-16 23:44:39.971625 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #723 | Epoch Duration: 37.00097393989563
2018-05-16 23:44:39.973059 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #723 | Started Training: True
2018-05-16 23:45:16.802669 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #724 | Epoch Duration: 36.82938838005066
2018-05-16 23:45:16.803830 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #724 | Started Training: True
2018-05-16 23:45:52.822424 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #725 | Epoch Duration: 36.018415689468384
2018-05-16 23:45:52.822660 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #725 | Started Training: True
2018-05-16 23:46:29.719113 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #726 | Epoch Duration: 36.89632701873779
2018-05-16 23:46:29.719389 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #726 | Started Training: True
2018-05-16 23:49:21.538480 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #727 | Epoch Duration: 171.81893348693848
2018-05-16 23:49:21.541953 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #727 | Started Training: True
2018-05-16 23:52:22.096398 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #728 | Epoch Duration: 180.55425214767456
2018-05-16 23:52:22.096655 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #728 | Started Training: True
2018-05-16 23:55:19.901468 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #729 | Epoch Duration: 177.8046851158142
2018-05-16 23:55:19.901710 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #729 | Started Training: True
2018-05-16 23:58:38.782587 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #730 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                       52846.1
VF Loss                           4.66059
Policy Loss                     -21.6259
Q Predictions Mean              537.057
Q Predictions Std               277.191
Q Predictions Max              1775.52
Q Predictions Min                 1.22786
V Predictions Mean              571.666
V Predictions Std               431.786
V Predictions Max              4506.59
V Predictions Min                10.6018
Log Pis Mean                    -11.4408
Log Pis Std                       8.63713
Log Pis Max                      85.6562
Log Pis Min                     -14.8419
Policy mu Mean                   -0.00121864
Policy mu Std                     0.312085
Policy mu Max                     3.7044
Policy mu Min                    -3.94694
Policy log std Mean              -0.138848
Policy log std Std                0.0764262
Policy log std Max               -0.0848412
Policy log std Min               -1.83516
Test Rewards Mean                 0.00474725
Test Rewards Std                  0.00398978
Test Rewards Max                  0.0158968
Test Rewards Min                 -0.000874971
Test Returns Mean                 0.603494
Test Returns Std                  0.00595646
Test Returns Max                  0.607933
Test Returns Min                  0.588158
Test Actions Mean                -0.0389836
Test Actions Std                  0.13119
Test Actions Max                  0.417194
Test Actions Min                 -0.442192
Num Paths                         8
Exploration Rewards Mean         -0.00638576
Exploration Rewards Std           0.00763597
Exploration Rewards Max           0.00690506
Exploration Rewards Min          -0.0208958
Exploration Returns Mean         -0.803009
Exploration Returns Std           0.00735724
Exploration Returns Max          -0.786141
Exploration Returns Min          -0.813785
Exploration Actions Mean          0.0127234
Exploration Actions Std           0.590742
Exploration Actions Max           0.998954
Exploration Actions Min          -0.999039
AverageReturn                     0.603494
Number of train steps total  730844
Number of env steps total    731000
Number of rollouts total       5783
Train Time (s)                   86.595
(Previous) Eval Time (s)          2.50401e-06
Sample Time (s)                  93.5689
Epoch Time (s)                  180.164
Total Train Time (s)          99180.9
Epoch                           730
---------------------------  ----------------
2018-05-17 00:01:26.483379 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #730 | Epoch Duration: 366.5815589427948
2018-05-17 00:01:26.483501 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #730 | Started Training: True
2018-05-17 00:03:59.230398 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #731 | Epoch Duration: 152.7467999458313
2018-05-17 00:03:59.230641 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #731 | Started Training: True
2018-05-17 00:04:36.684592 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #732 | Epoch Duration: 37.45379137992859
2018-05-17 00:04:36.684796 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #732 | Started Training: True
2018-05-17 00:05:13.317860 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #733 | Epoch Duration: 36.6329505443573
2018-05-17 00:05:13.318076 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #733 | Started Training: True
2018-05-17 00:05:49.969675 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #734 | Epoch Duration: 36.65143442153931
2018-05-17 00:05:49.969876 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #734 | Started Training: True
2018-05-17 00:06:27.112703 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #735 | Epoch Duration: 37.142674922943115
2018-05-17 00:06:27.114952 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #735 | Started Training: True
2018-05-17 00:07:03.874871 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #736 | Epoch Duration: 36.75971245765686
2018-05-17 00:07:03.876060 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #736 | Started Training: True
2018-05-17 00:07:40.071972 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #737 | Epoch Duration: 36.195730447769165
2018-05-17 00:07:40.072231 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #737 | Started Training: True
2018-05-17 00:08:16.824979 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #738 | Epoch Duration: 36.7526216506958
2018-05-17 00:08:16.827171 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #738 | Started Training: True
2018-05-17 00:09:01.365457 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #739 | Epoch Duration: 44.53812336921692
2018-05-17 00:09:01.365695 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #739 | Started Training: True
2018-05-17 00:12:19.120870 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #740 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           5.81526
VF Loss                          23.4621
Policy Loss                     -56.474
Q Predictions Mean              522.321
Q Predictions Std               254.323
Q Predictions Max               863.315
Q Predictions Min                -8.61824
V Predictions Mean              539.212
V Predictions Std               253.944
V Predictions Max               877.72
V Predictions Min                 2.80079
Log Pis Mean                    -12.1656
Log Pis Std                       0.718252
Log Pis Max                     -10.3002
Log Pis Min                     -14.2792
Policy mu Mean                   -0.000946517
Policy mu Std                     0.0912062
Policy mu Max                     0.55919
Policy mu Min                    -0.41508
Policy log std Mean              -0.138479
Policy log std Std                0.0106289
Policy log std Max               -0.0767599
Policy log std Min               -0.206123
Test Rewards Mean                 0.00348101
Test Rewards Std                  0.0058543
Test Rewards Max                  0.0169936
Test Rewards Min                 -0.00291389
Test Returns Mean                 0.493868
Test Returns Std                  0.00582746
Test Returns Max                  0.500241
Test Returns Min                  0.484668
Test Actions Mean                -0.0421713
Test Actions Std                  0.137489
Test Actions Max                  0.323098
Test Actions Min                 -0.429761
Num Paths                         7
Exploration Rewards Mean         -0.00629204
Exploration Rewards Std           0.00762834
Exploration Rewards Max           0.0074878
Exploration Rewards Min          -0.0211409
Exploration Returns Mean         -0.800887
Exploration Returns Std           0.00587406
Exploration Returns Max          -0.791473
Exploration Returns Min          -0.8106
Exploration Actions Mean          0.00568935
Exploration Actions Std           0.591987
Exploration Actions Max           0.998599
Exploration Actions Min          -0.996625
AverageReturn                     0.493868
Number of train steps total  740844
Number of env steps total    741000
Number of rollouts total       5864
Train Time (s)                   86.2138
(Previous) Eval Time (s)          2.28801e-06
Sample Time (s)                  92.8485
Epoch Time (s)                  179.062
Total Train Time (s)         100075
Epoch                           740
---------------------------  ----------------
2018-05-17 00:16:20.677836 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #740 | Epoch Duration: 439.3120243549347
2018-05-17 00:16:20.677987 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #740 | Started Training: True
2018-05-17 00:19:20.320240 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #741 | Epoch Duration: 179.64212560653687
2018-05-17 00:19:20.322201 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #741 | Started Training: True
2018-05-17 00:22:23.863054 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #742 | Epoch Duration: 183.54065704345703
2018-05-17 00:22:23.863295 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #742 | Started Training: True
2018-05-17 00:23:41.787813 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #743 | Epoch Duration: 77.92437767982483
2018-05-17 00:23:41.788089 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #743 | Started Training: True
2018-05-17 00:24:17.684524 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #744 | Epoch Duration: 35.89627552032471
2018-05-17 00:24:17.686165 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #744 | Started Training: True
2018-05-17 00:24:54.895435 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #745 | Epoch Duration: 37.20908451080322
2018-05-17 00:24:54.895647 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #745 | Started Training: True
2018-05-17 00:25:31.339328 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #746 | Epoch Duration: 36.44350838661194
2018-05-17 00:25:31.339594 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #746 | Started Training: True
2018-05-17 00:26:08.711940 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #747 | Epoch Duration: 37.37217831611633
2018-05-17 00:26:08.713145 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #747 | Started Training: True
2018-05-17 00:26:44.097878 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #748 | Epoch Duration: 35.384533166885376
2018-05-17 00:26:44.098112 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #748 | Started Training: True
2018-05-17 00:27:21.395329 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #749 | Epoch Duration: 37.29708933830261
2018-05-17 00:27:21.395623 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #749 | Started Training: True
2018-05-17 00:28:17.290751 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #750 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           2.49793
VF Loss                           1.11846
Policy Loss                       4.25321
Q Predictions Mean              537.981
Q Predictions Std               260.689
Q Predictions Max               866.067
Q Predictions Min                -3.50199
V Predictions Mean              550.008
V Predictions Std               260.637
V Predictions Max               876.849
V Predictions Min                 6.85565
Log Pis Mean                    -12.336
Log Pis Std                       0.632924
Log Pis Max                     -10.5161
Log Pis Min                     -15.7379
Policy mu Mean                    0.00477216
Policy mu Std                     0.10119
Policy mu Max                     0.462298
Policy mu Min                    -0.410096
Policy log std Mean              -0.134445
Policy log std Std                0.0100742
Policy log std Max               -0.0964548
Policy log std Min               -0.183576
Test Rewards Mean                 0.00284188
Test Rewards Std                  0.00551077
Test Rewards Max                  0.0162385
Test Rewards Min                 -0.00327911
Test Returns Mean                 0.489751
Test Returns Std                  0.00139011
Test Returns Max                  0.490899
Test Returns Min                  0.486933
Test Actions Mean                -0.0348535
Test Actions Std                  0.134982
Test Actions Max                  0.301122
Test Actions Min                 -0.473681
Num Paths                         8
Exploration Rewards Mean         -0.00651188
Exploration Rewards Std           0.00765059
Exploration Rewards Max           0.00615915
Exploration Rewards Min          -0.0211615
Exploration Returns Mean         -0.800961
Exploration Returns Std           0.00620811
Exploration Returns Max          -0.79108
Exploration Returns Min          -0.810581
Exploration Actions Mean          0.0150092
Exploration Actions Std           0.59113
Exploration Actions Max           0.996942
Exploration Actions Min          -0.997654
AverageReturn                     0.489751
Number of train steps total  750844
Number of env steps total    751000
Number of rollouts total       5943
Train Time (s)                   21.408
(Previous) Eval Time (s)          2.186e-06
Sample Time (s)                  16.1808
Epoch Time (s)                   37.5888
Total Train Time (s)         101014
Epoch                           750
---------------------------  ---------------
2018-05-17 00:31:59.945810 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #750 | Epoch Duration: 278.54998803138733
2018-05-17 00:31:59.945920 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #750 | Started Training: True
2018-05-17 00:35:04.307205 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #751 | Epoch Duration: 184.36119198799133
2018-05-17 00:35:04.307419 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #751 | Started Training: True
2018-05-17 00:38:04.797711 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #752 | Epoch Duration: 180.49016857147217
2018-05-17 00:38:04.797926 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #752 | Started Training: True
2018-05-17 00:41:04.534258 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #753 | Epoch Duration: 179.73620200157166
2018-05-17 00:41:04.536391 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #753 | Started Training: True
2018-05-17 00:44:05.770328 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #754 | Epoch Duration: 181.23376417160034
2018-05-17 00:44:05.770597 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #754 | Started Training: True
2018-05-17 00:46:46.674668 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #755 | Epoch Duration: 160.9039397239685
2018-05-17 00:46:46.676843 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #755 | Started Training: True
2018-05-17 00:47:23.127595 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #756 | Epoch Duration: 36.45054340362549
2018-05-17 00:47:23.127830 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #756 | Started Training: True
2018-05-17 00:47:59.955418 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #757 | Epoch Duration: 36.827420473098755
2018-05-17 00:47:59.955691 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #757 | Started Training: True
2018-05-17 00:48:35.723519 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #758 | Epoch Duration: 35.76766538619995
2018-05-17 00:48:35.725808 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #758 | Started Training: True
2018-05-17 00:49:13.753327 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #759 | Epoch Duration: 38.02730941772461
2018-05-17 00:49:13.753539 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #759 | Started Training: True
2018-05-17 00:50:09.880508 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #760 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                         223.288
VF Loss                         226.849
Policy Loss                     174.346
Q Predictions Mean              534.94
Q Predictions Std               259.587
Q Predictions Max               877.548
Q Predictions Min                14.7516
V Predictions Mean              532.829
V Predictions Std               255.452
V Predictions Max               874.447
V Predictions Min                19.7062
Log Pis Mean                    -12.1527
Log Pis Std                       0.753035
Log Pis Max                      -9.47508
Log Pis Min                     -14.5366
Policy mu Mean                    0.0107098
Policy mu Std                     0.0981594
Policy mu Max                     0.577171
Policy mu Min                    -0.399018
Policy log std Mean              -0.136172
Policy log std Std                0.00918701
Policy log std Max               -0.112712
Policy log std Min               -0.219314
Test Rewards Mean                 0.0029549
Test Rewards Std                  0.00594974
Test Rewards Max                  0.0158854
Test Rewards Min                 -0.00665552
Test Returns Mean                 0.480382
Test Returns Std                  0.00727492
Test Returns Max                  0.490261
Test Returns Min                  0.471654
Test Actions Mean                -0.03959
Test Actions Std                  0.12769
Test Actions Max                  0.337352
Test Actions Min                 -0.55749
Num Paths                         7
Exploration Rewards Mean         -0.00645545
Exploration Rewards Std           0.00761899
Exploration Rewards Max           0.00582232
Exploration Rewards Min          -0.0211282
Exploration Returns Mean         -0.798631
Exploration Returns Std           0.00979732
Exploration Returns Max          -0.784062
Exploration Returns Min          -0.818532
Exploration Actions Mean          0.000437368
Exploration Actions Std           0.59203
Exploration Actions Max           0.998215
Exploration Actions Min          -0.997734
AverageReturn                     0.480382
Number of train steps total  760844
Number of env steps total    761000
Number of rollouts total       6024
Train Time (s)                   20.8031
(Previous) Eval Time (s)          2.15101e-06
Sample Time (s)                  16.6365
Epoch Time (s)                   37.4396
Total Train Time (s)         102353
Epoch                           760
---------------------------  ----------------
2018-05-17 00:54:19.494258 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #760 | Epoch Duration: 305.7405767440796
2018-05-17 00:54:19.494395 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #760 | Started Training: True
2018-05-17 00:57:11.957692 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #761 | Epoch Duration: 172.46318006515503
2018-05-17 00:57:11.957939 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #761 | Started Training: True
2018-05-17 01:00:09.560810 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #762 | Epoch Duration: 177.60274076461792
2018-05-17 01:00:09.561055 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #762 | Started Training: True
2018-05-17 01:03:04.439911 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #763 | Epoch Duration: 174.87872791290283
2018-05-17 01:03:04.440161 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #763 | Started Training: True
2018-05-17 01:06:00.399153 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #764 | Epoch Duration: 175.95885968208313
2018-05-17 01:06:00.399399 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #764 | Started Training: True
2018-05-17 01:08:58.120426 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #765 | Epoch Duration: 177.72090005874634
2018-05-17 01:08:58.120675 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #765 | Started Training: True
2018-05-17 01:09:55.623025 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #766 | Epoch Duration: 57.5022087097168
2018-05-17 01:09:55.623287 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #766 | Started Training: True
2018-05-17 01:10:32.670648 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #767 | Epoch Duration: 37.04719567298889
2018-05-17 01:10:32.672492 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #767 | Started Training: True
2018-05-17 01:11:09.860850 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #768 | Epoch Duration: 37.18814539909363
2018-05-17 01:11:09.861120 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #768 | Started Training: True
2018-05-17 01:11:45.755063 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #769 | Epoch Duration: 35.89378237724304
2018-05-17 01:11:45.755295 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #769 | Started Training: True
2018-05-17 01:12:42.429387 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #770 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           2.18316
VF Loss                           1.45125
Policy Loss                       6.52229
Q Predictions Mean              499.283
Q Predictions Std               249.289
Q Predictions Max               862.084
Q Predictions Min                 4.40038
V Predictions Mean              511.027
V Predictions Std               249.147
V Predictions Max               872.782
V Predictions Min                15.3437
Log Pis Mean                    -12.2607
Log Pis Std                       0.648341
Log Pis Max                     -10.6776
Log Pis Min                     -15.2746
Policy mu Mean                    0.00565322
Policy mu Std                     0.0940671
Policy mu Max                     0.448128
Policy mu Min                    -0.382377
Policy log std Mean              -0.136868
Policy log std Std                0.00922012
Policy log std Max               -0.112842
Policy log std Min               -0.196567
Test Rewards Mean                 0.00265532
Test Rewards Std                  0.00555236
Test Rewards Max                  0.0163096
Test Rewards Min                 -0.00619857
Test Returns Mean                 0.486808
Test Returns Std                  0.00490712
Test Returns Max                  0.495078
Test Returns Min                  0.479065
Test Actions Mean                -0.0512048
Test Actions Std                  0.167422
Test Actions Max                  0.449481
Test Actions Min                 -0.584721
Num Paths                         8
Exploration Rewards Mean         -0.00635566
Exploration Rewards Std           0.00761861
Exploration Rewards Max           0.00565012
Exploration Rewards Min          -0.0211401
Exploration Returns Mean         -0.800813
Exploration Returns Std           0.010367
Exploration Returns Max          -0.786815
Exploration Returns Min          -0.815062
Exploration Actions Mean          0.0113796
Exploration Actions Std           0.586711
Exploration Actions Max           0.997871
Exploration Actions Min          -0.997945
AverageReturn                     0.486808
Number of train steps total  770844
Number of env steps total    771000
Number of rollouts total       6103
Train Time (s)                   21.5412
(Previous) Eval Time (s)          2.459e-06
Sample Time (s)                  16.2762
Epoch Time (s)                   37.8175
Total Train Time (s)         103684
Epoch                           770
---------------------------  ---------------
2018-05-17 01:16:30.794330 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #770 | Epoch Duration: 285.0389075279236
2018-05-17 01:16:30.794503 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #770 | Started Training: True
2018-05-17 01:19:27.754228 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #771 | Epoch Duration: 176.95958876609802
2018-05-17 01:19:27.754501 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #771 | Started Training: True
2018-05-17 01:22:27.162105 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #772 | Epoch Duration: 179.40745902061462
2018-05-17 01:22:27.162345 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #772 | Started Training: True
2018-05-17 01:25:24.699138 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #773 | Epoch Duration: 177.53664708137512
2018-05-17 01:25:24.699376 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #773 | Started Training: True
2018-05-17 01:28:21.291037 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #774 | Epoch Duration: 176.59153366088867
2018-05-17 01:28:21.291274 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #774 | Started Training: True
2018-05-17 01:30:56.236007 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #775 | Epoch Duration: 154.94460678100586
2018-05-17 01:30:56.237150 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #775 | Started Training: True
2018-05-17 01:31:33.806074 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #776 | Epoch Duration: 37.568739891052246
2018-05-17 01:31:33.806303 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #776 | Started Training: True
2018-05-17 01:32:10.647949 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #777 | Epoch Duration: 36.841516971588135
2018-05-17 01:32:10.648207 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #777 | Started Training: True
2018-05-17 01:32:47.125825 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #778 | Epoch Duration: 36.47746229171753
2018-05-17 01:32:47.126031 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #778 | Started Training: True
2018-05-17 01:33:23.575022 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #779 | Epoch Duration: 36.44887971878052
2018-05-17 01:33:23.575238 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #779 | Started Training: True
2018-05-17 01:34:19.992366 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #780 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                        7059.71
VF Loss                          14.6655
Policy Loss                     -22.6379
Q Predictions Mean              559.069
Q Predictions Std               248.335
Q Predictions Max              1754.9
Q Predictions Min                 6.29626
V Predictions Mean              592.561
V Predictions Std               412.681
V Predictions Max              4499.7
V Predictions Min                21.2892
Log Pis Mean                    -11.5609
Log Pis Std                       8.41596
Log Pis Max                      83.0081
Log Pis Min                     -14.8847
Policy mu Mean                   -0.00227057
Policy mu Std                     0.298863
Policy mu Max                     4.01828
Policy mu Min                    -3.92047
Policy log std Mean              -0.141341
Policy log std Std                0.0627261
Policy log std Max               -0.109978
Policy log std Min               -1.33619
Test Rewards Mean                 0.00168476
Test Rewards Std                  0.00509827
Test Rewards Max                  0.0168435
Test Rewards Min                 -0.00619526
Test Returns Mean                 0.422032
Test Returns Std                  0.00433943
Test Returns Max                  0.429046
Test Returns Min                  0.417875
Test Actions Mean                -0.0776439
Test Actions Std                  0.219071
Test Actions Max                  0.492999
Test Actions Min                 -0.668247
Num Paths                         9
Exploration Rewards Mean         -0.00622967
Exploration Rewards Std           0.00760884
Exploration Rewards Max           0.0072875
Exploration Rewards Min          -0.0212169
Exploration Returns Mean         -0.801551
Exploration Returns Std           0.00737497
Exploration Returns Max          -0.784276
Exploration Returns Min          -0.809922
Exploration Actions Mean          0.0115295
Exploration Actions Std           0.590933
Exploration Actions Max           0.998543
Exploration Actions Min          -0.997863
AverageReturn                     0.422032
Number of train steps total  780844
Number of env steps total    781000
Number of rollouts total       6183
Train Time (s)                   21.1811
(Previous) Eval Time (s)          2.149e-06
Sample Time (s)                  16.0985
Epoch Time (s)                   37.2796
Total Train Time (s)         105511
Epoch                           780
---------------------------  ---------------
2018-05-17 01:46:57.659611 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #780 | Epoch Duration: 814.0842096805573
2018-05-17 01:46:57.659759 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #780 | Started Training: True
2018-05-17 01:50:01.187684 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #781 | Epoch Duration: 183.52780032157898
2018-05-17 01:50:01.187942 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #781 | Started Training: True
2018-05-17 01:53:00.696437 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #782 | Epoch Duration: 179.5083680152893
2018-05-17 01:53:00.696679 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #782 | Started Training: True
2018-05-17 01:56:00.094848 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #783 | Epoch Duration: 179.39802980422974
2018-05-17 01:56:00.095130 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #783 | Started Training: True
2018-05-17 01:58:59.080462 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #784 | Epoch Duration: 178.98515462875366
2018-05-17 01:58:59.080718 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #784 | Started Training: True
2018-05-17 02:01:55.647039 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #785 | Epoch Duration: 176.56619000434875
2018-05-17 02:01:55.647270 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #785 | Started Training: True
2018-05-17 02:04:55.393237 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #786 | Epoch Duration: 179.74584126472473
2018-05-17 02:04:55.393440 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #786 | Started Training: True
2018-05-17 02:07:55.315342 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #787 | Epoch Duration: 179.921772480011
2018-05-17 02:07:55.315607 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #787 | Started Training: True
2018-05-17 02:10:53.530054 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #788 | Epoch Duration: 178.21428322792053
2018-05-17 02:10:53.530283 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #788 | Started Training: True
2018-05-17 02:12:05.519626 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #789 | Epoch Duration: 71.9892041683197
2018-05-17 02:12:05.520560 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #789 | Started Training: True
2018-05-17 02:13:02.757374 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #790 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           1.95055
VF Loss                           1.92616
Policy Loss                      11.33
Q Predictions Mean              552.645
Q Predictions Std               230.872
Q Predictions Max               860.321
Q Predictions Min                31.1612
V Predictions Mean              564.028
V Predictions Std               230.651
V Predictions Max               874.645
V Predictions Min                42.9031
Log Pis Mean                    -12.1881
Log Pis Std                       0.61796
Log Pis Max                      -9.97829
Log Pis Min                     -13.87
Policy mu Mean                    0.0061246
Policy mu Std                     0.0872328
Policy mu Max                     0.501851
Policy mu Min                    -0.369185
Policy log std Mean              -0.136216
Policy log std Std                0.00952182
Policy log std Max               -0.11214
Policy log std Min               -0.203055
Test Rewards Mean                 0.00406094
Test Rewards Std                  0.00306166
Test Rewards Max                  0.0118453
Test Rewards Min                 -0.000570625
Test Returns Mean                 0.579191
Test Returns Std                  0.0266217
Test Returns Max                  0.629422
Test Returns Min                  0.556913
Test Actions Mean                -0.0398488
Test Actions Std                  0.255893
Test Actions Max                  0.687806
Test Actions Min                 -0.631146
Num Paths                         8
Exploration Rewards Mean         -0.00636228
Exploration Rewards Std           0.00759405
Exploration Rewards Max           0.00552503
Exploration Rewards Min          -0.0211942
Exploration Returns Mean         -0.798466
Exploration Returns Std           0.00952986
Exploration Returns Max          -0.780122
Exploration Returns Min          -0.812154
Exploration Actions Mean          0.00110418
Exploration Actions Std           0.592016
Exploration Actions Max           0.998459
Exploration Actions Min          -0.998163
AverageReturn                     0.579191
Number of train steps total  790844
Number of env steps total    791000
Number of rollouts total       6260
Train Time (s)                   21.1602
(Previous) Eval Time (s)          2.441e-06
Sample Time (s)                  16.2364
Epoch Time (s)                   37.3966
Total Train Time (s)         107259
Epoch                           790
---------------------------  ----------------
2018-05-17 02:16:05.925552 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #790 | Epoch Duration: 240.4048399925232
2018-05-17 02:16:05.925663 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #790 | Started Training: True
2018-05-17 02:17:02.638430 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #791 | Epoch Duration: 56.71265649795532
2018-05-17 02:17:02.638653 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #791 | Started Training: True
2018-05-17 02:20:01.173640 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #792 | Epoch Duration: 178.53485941886902
2018-05-17 02:20:01.173886 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #792 | Started Training: True
2018-05-17 02:23:01.984412 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #793 | Epoch Duration: 180.8104054927826
2018-05-17 02:23:01.984665 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #793 | Started Training: True
2018-05-17 02:25:59.300894 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #794 | Epoch Duration: 177.3160924911499
2018-05-17 02:25:59.301100 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #794 | Started Training: True
2018-05-17 02:29:01.391728 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #795 | Epoch Duration: 182.09045577049255
2018-05-17 02:29:01.391965 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #795 | Started Training: True
2018-05-17 02:31:57.647141 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #796 | Epoch Duration: 176.25504350662231
2018-05-17 02:31:57.647364 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #796 | Started Training: True
2018-05-17 02:34:57.405610 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #797 | Epoch Duration: 179.75812029838562
2018-05-17 02:34:57.405853 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #797 | Started Training: True
2018-05-17 02:38:01.616505 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #798 | Epoch Duration: 184.21051692962646
2018-05-17 02:38:01.616750 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #798 | Started Training: True
2018-05-17 02:41:03.159858 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #799 | Epoch Duration: 181.54297471046448
2018-05-17 02:41:03.160080 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #799 | Started Training: True
2018-05-17 02:43:02.619335 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #800 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           4.44995
VF Loss                           1.15509
Policy Loss                       3.3122
Q Predictions Mean              545.406
Q Predictions Std               235.08
Q Predictions Max               866.339
Q Predictions Min                -0.45945
V Predictions Mean              557.476
V Predictions Std               234.952
V Predictions Max               877.193
V Predictions Min                10.3686
Log Pis Mean                    -12.21
Log Pis Std                       0.726206
Log Pis Max                     -10.473
Log Pis Min                     -15.0282
Policy mu Mean                    0.00986851
Policy mu Std                     0.0999568
Policy mu Max                     0.456535
Policy mu Min                    -0.667042
Policy log std Mean              -0.129037
Policy log std Std                0.0140766
Policy log std Max               -0.0442718
Policy log std Min               -0.212146
Test Rewards Mean                 0.00255898
Test Rewards Std                  0.00512878
Test Rewards Max                  0.0183902
Test Rewards Min                 -0.00444426
Test Returns Mean                 0.419672
Test Returns Std                  0.0453969
Test Returns Max                  0.474225
Test Returns Min                  0.374929
Test Actions Mean                -0.0288411
Test Actions Std                  0.155454
Test Actions Max                  0.445665
Test Actions Min                 -0.549782
Num Paths                         6
Exploration Rewards Mean         -0.00633244
Exploration Rewards Std           0.00757231
Exploration Rewards Max           0.00605379
Exploration Rewards Min          -0.021195
Exploration Returns Mean         -0.79261
Exploration Returns Std           0.0128527
Exploration Returns Max          -0.779276
Exploration Returns Min          -0.81241
Exploration Actions Mean          0.00283919
Exploration Actions Std           0.591445
Exploration Actions Max           0.997096
Exploration Actions Min          -0.997906
AverageReturn                     0.419672
Number of train steps total  800844
Number of env steps total    801000
Number of rollouts total       6339
Train Time (s)                   50.0523
(Previous) Eval Time (s)          2.50801e-06
Sample Time (s)                  48.8993
Epoch Time (s)                   98.9516
Total Train Time (s)         109174
Epoch                           800
---------------------------  ----------------
2018-05-17 02:48:01.522689 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #800 | Epoch Duration: 418.36248874664307
2018-05-17 02:48:01.522874 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #800 | Started Training: True
2018-05-17 02:51:03.549526 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #801 | Epoch Duration: 182.02649855613708
2018-05-17 02:51:03.549781 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #801 | Started Training: True
2018-05-17 02:54:00.664425 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #802 | Epoch Duration: 177.114511013031
2018-05-17 02:54:00.664659 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #802 | Started Training: True
2018-05-17 02:56:59.444763 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #803 | Epoch Duration: 178.7799687385559
2018-05-17 02:56:59.444988 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #803 | Started Training: True
2018-05-17 02:59:56.201771 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #804 | Epoch Duration: 176.75665807724
2018-05-17 02:59:56.202018 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #804 | Started Training: True
2018-05-17 03:02:48.166696 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #805 | Epoch Duration: 171.96454286575317
2018-05-17 03:02:48.166939 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #805 | Started Training: True
2018-05-17 03:05:51.215732 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #806 | Epoch Duration: 183.04866480827332
2018-05-17 03:05:51.215967 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #806 | Started Training: True
2018-05-17 03:08:51.120346 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #807 | Epoch Duration: 179.90425181388855
2018-05-17 03:08:51.120605 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #807 | Started Training: True
2018-05-17 03:10:18.532173 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #808 | Epoch Duration: 87.41142916679382
2018-05-17 03:10:18.532445 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #808 | Started Training: True
2018-05-17 03:10:55.562309 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #809 | Epoch Duration: 37.029699087142944
2018-05-17 03:10:55.562564 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #809 | Started Training: True
2018-05-17 03:11:53.631388 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #810 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           2.85927
VF Loss                           4.08585
Policy Loss                     -19.2891
Q Predictions Mean              494.004
Q Predictions Std               224.918
Q Predictions Max               856.974
Q Predictions Min                 7.93618
V Predictions Mean              507.908
V Predictions Std               225.208
V Predictions Max               872.43
V Predictions Min                22.6006
Log Pis Mean                    -12.2981
Log Pis Std                       0.637622
Log Pis Max                     -10.2598
Log Pis Min                     -14.5649
Policy mu Mean                    0.0082793
Policy mu Std                     0.0825596
Policy mu Max                     0.503374
Policy mu Min                    -0.396316
Policy log std Mean              -0.136957
Policy log std Std                0.00747493
Policy log std Max               -0.10288
Policy log std Min               -0.188886
Test Rewards Mean                 0.00163169
Test Rewards Std                  0.00481189
Test Rewards Max                  0.0162306
Test Rewards Min                 -0.00492244
Test Returns Mean                 0.444636
Test Returns Std                  0.00488999
Test Returns Max                  0.452469
Test Returns Min                  0.440506
Test Actions Mean                -0.0604175
Test Actions Std                  0.203511
Test Actions Max                  0.538183
Test Actions Min                 -0.661514
Num Paths                         8
Exploration Rewards Mean         -0.00639048
Exploration Rewards Std           0.00759335
Exploration Rewards Max           0.00555644
Exploration Rewards Min          -0.021026
Exploration Returns Mean         -0.802005
Exploration Returns Std           0.0101393
Exploration Returns Max          -0.780202
Exploration Returns Min          -0.815619
Exploration Actions Mean          0.00261532
Exploration Actions Std           0.591692
Exploration Actions Max           0.999475
Exploration Actions Min          -0.997728
AverageReturn                     0.444636
Number of train steps total  810844
Number of env steps total    811000
Number of rollouts total       6417
Train Time (s)                   21.1734
(Previous) Eval Time (s)          2.15201e-06
Sample Time (s)                  16.1277
Epoch Time (s)                   37.3011
Total Train Time (s)         111326
Epoch                           810
---------------------------  ----------------
2018-05-17 03:23:53.514241 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #810 | Epoch Duration: 777.9515523910522
2018-05-17 03:23:53.514367 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #810 | Started Training: True
2018-05-17 03:24:30.419511 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #811 | Epoch Duration: 36.9050407409668
2018-05-17 03:24:30.421470 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #811 | Started Training: True
2018-05-17 03:25:06.885591 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #812 | Epoch Duration: 36.46391940116882
2018-05-17 03:25:06.886461 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #812 | Started Training: True
2018-05-17 03:25:43.751516 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #813 | Epoch Duration: 36.864856004714966
2018-05-17 03:25:43.754263 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #813 | Started Training: True
2018-05-17 03:28:01.841115 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #814 | Epoch Duration: 138.08662962913513
2018-05-17 03:28:01.841382 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #814 | Started Training: True
2018-05-17 03:31:02.614162 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #815 | Epoch Duration: 180.77265429496765
2018-05-17 03:31:02.614413 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #815 | Started Training: True
2018-05-17 03:34:05.699393 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #816 | Epoch Duration: 183.08484601974487
2018-05-17 03:34:05.702429 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #816 | Started Training: True
2018-05-17 03:37:04.685581 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #817 | Epoch Duration: 178.9829559326172
2018-05-17 03:37:04.685831 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #817 | Started Training: True
2018-05-17 03:40:02.600072 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #818 | Epoch Duration: 177.91412043571472
2018-05-17 03:40:02.600298 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #818 | Started Training: True
2018-05-17 03:42:59.517726 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #819 | Epoch Duration: 176.91730332374573
2018-05-17 03:42:59.517973 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #819 | Started Training: True
2018-05-17 03:46:17.806724 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #820 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           3.23195
VF Loss                           1.96119
Policy Loss                      -4.99546
Q Predictions Mean              510.101
Q Predictions Std               246.998
Q Predictions Max               862.723
Q Predictions Min                 5.39989
V Predictions Mean              522.675
V Predictions Std               246.736
V Predictions Max               874.475
V Predictions Min                18.6381
Log Pis Mean                    -12.114
Log Pis Std                       0.709058
Log Pis Max                      -9.87478
Log Pis Min                     -14.9151
Policy mu Mean                    0.00222178
Policy mu Std                     0.0968663
Policy mu Max                     0.515948
Policy mu Min                    -0.47166
Policy log std Mean              -0.134362
Policy log std Std                0.0104462
Policy log std Max               -0.10503
Policy log std Min               -0.200926
Test Rewards Mean                 0.00186223
Test Rewards Std                  0.00504711
Test Rewards Max                  0.0161529
Test Rewards Min                 -0.00343564
Test Returns Mean                 0.276541
Test Returns Std                  0.266302
Test Returns Max                  0.48866
Test Returns Min                 -0.0770611
Test Actions Mean                -0.0188772
Test Actions Std                  0.168664
Test Actions Max                  0.50632
Test Actions Min                 -0.645176
Num Paths                         8
Exploration Rewards Mean         -0.00630422
Exploration Rewards Std           0.00756437
Exploration Rewards Max           0.00709788
Exploration Rewards Min          -0.0210754
Exploration Returns Mean         -0.799848
Exploration Returns Std           0.0178719
Exploration Returns Max          -0.76053
Exploration Returns Min          -0.820617
Exploration Actions Mean          0.0106659
Exploration Actions Std           0.588363
Exploration Actions Max           0.995569
Exploration Actions Min          -0.998418
AverageReturn                     0.276541
Number of train steps total  820844
Number of env steps total    821000
Number of rollouts total       6496
Train Time (s)                   83.6768
(Previous) Eval Time (s)          2.5e-06
Sample Time (s)                  93.0147
Epoch Time (s)                  176.691
Total Train Time (s)         113263
Epoch                           820
---------------------------  ---------------
2018-05-17 03:56:10.407182 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #820 | Epoch Duration: 790.8890879154205
2018-05-17 03:56:10.407292 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #820 | Started Training: True
2018-05-17 03:56:48.403588 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #821 | Epoch Duration: 37.996204137802124
2018-05-17 03:56:48.403798 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #821 | Started Training: True
2018-05-17 03:57:26.315400 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #822 | Epoch Duration: 37.91144013404846
2018-05-17 03:57:26.315609 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #822 | Started Training: True
2018-05-17 03:58:03.602852 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #823 | Epoch Duration: 37.28708505630493
2018-05-17 03:58:03.603109 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #823 | Started Training: True
2018-05-17 03:58:39.729824 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #824 | Epoch Duration: 36.126559257507324
2018-05-17 03:58:39.730028 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #824 | Started Training: True
2018-05-17 03:59:16.723098 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #825 | Epoch Duration: 36.99294948577881
2018-05-17 03:59:16.723371 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #825 | Started Training: True
2018-05-17 03:59:53.511159 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #826 | Epoch Duration: 36.787625312805176
2018-05-17 03:59:53.511429 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #826 | Started Training: True
2018-05-17 04:00:31.098804 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #827 | Epoch Duration: 37.58721375465393
2018-05-17 04:00:31.099045 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #827 | Started Training: True
2018-05-17 04:01:07.608596 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #828 | Epoch Duration: 36.50942420959473
2018-05-17 04:01:07.608809 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #828 | Started Training: True
2018-05-17 04:01:43.428210 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #829 | Epoch Duration: 35.819241762161255
2018-05-17 04:01:43.428421 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #829 | Started Training: True
2018-05-17 04:02:39.479965 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #830 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           6.68611
VF Loss                          18.1997
Policy Loss                      46.621
Q Predictions Mean              512.099
Q Predictions Std               238.991
Q Predictions Max               863.049
Q Predictions Min                25.0663
V Predictions Mean              520.326
V Predictions Std               239.303
V Predictions Max               876.732
V Predictions Min                33.9413
Log Pis Mean                    -12.2048
Log Pis Std                       0.702957
Log Pis Max                     -10.1696
Log Pis Min                     -14.3513
Policy mu Mean                    0.0455469
Policy mu Std                     0.103865
Policy mu Max                     0.578701
Policy mu Min                    -0.414906
Policy log std Mean              -0.137346
Policy log std Std                0.0150506
Policy log std Max               -0.089561
Policy log std Min               -0.19387
Test Rewards Mean                -0.000700364
Test Rewards Std                  0.00404335
Test Rewards Max                  0.0155558
Test Rewards Min                 -0.00824585
Test Returns Mean                -0.174951
Test Returns Std                  0.496405
Test Returns Max                  0.460272
Test Returns Min                 -0.585446
Test Actions Mean                -0.0841714
Test Actions Std                  0.30183
Test Actions Max                  0.663621
Test Actions Min                 -0.885496
Num Paths                         7
Exploration Rewards Mean         -0.00631458
Exploration Rewards Std           0.00762575
Exploration Rewards Max           0.00624783
Exploration Rewards Min          -0.0209461
Exploration Returns Mean         -0.798344
Exploration Returns Std           0.00891586
Exploration Returns Max          -0.788274
Exploration Returns Min          -0.810799
Exploration Actions Mean          0.00914222
Exploration Actions Std           0.587891
Exploration Actions Max           0.997383
Exploration Actions Min          -0.998214
AverageReturn                    -0.174951
Number of train steps total  830844
Number of env steps total    831000
Number of rollouts total       6574
Train Time (s)                   19.4199
(Previous) Eval Time (s)          1.97301e-06
Sample Time (s)                  16.2959
Epoch Time (s)                   35.7158
Total Train Time (s)         114480
Epoch                           830
---------------------------  ----------------
2018-05-17 04:16:28.305886 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #830 | Epoch Duration: 884.8773128986359
2018-05-17 04:16:28.305999 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #830 | Started Training: True
2018-05-17 04:19:28.854428 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #831 | Epoch Duration: 180.54832887649536
2018-05-17 04:19:28.854668 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #831 | Started Training: True
2018-05-17 04:22:23.480623 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #832 | Epoch Duration: 174.62582683563232
2018-05-17 04:22:23.482658 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #832 | Started Training: True
2018-05-17 04:25:19.851746 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #833 | Epoch Duration: 176.36890649795532
2018-05-17 04:25:19.852005 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #833 | Started Training: True
2018-05-17 04:26:13.820105 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #834 | Epoch Duration: 53.96797204017639
2018-05-17 04:26:13.822431 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #834 | Started Training: True
2018-05-17 04:26:50.708103 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #835 | Epoch Duration: 36.88548541069031
2018-05-17 04:26:50.709352 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #835 | Started Training: True
2018-05-17 04:27:27.493688 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #836 | Epoch Duration: 36.78419518470764
2018-05-17 04:27:27.493911 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #836 | Started Training: True
2018-05-17 04:28:04.436696 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #837 | Epoch Duration: 36.94265794754028
2018-05-17 04:28:04.436964 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #837 | Started Training: True
2018-05-17 04:28:41.458823 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #838 | Epoch Duration: 37.0217022895813
2018-05-17 04:28:41.460803 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #838 | Started Training: True
2018-05-17 04:29:17.525342 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #839 | Epoch Duration: 36.06438755989075
2018-05-17 04:29:17.528804 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #839 | Started Training: True
2018-05-17 04:30:14.738581 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #840 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                           6.30676
VF Loss                           1.74028
Policy Loss                       1.25764
Q Predictions Mean              553.083
Q Predictions Std               250.054
Q Predictions Max               864.578
Q Predictions Min                10.8409
V Predictions Mean              565.325
V Predictions Std               250.427
V Predictions Max               877.771
V Predictions Min                24.4062
Log Pis Mean                    -12.1725
Log Pis Std                       0.667401
Log Pis Max                      -9.95153
Log Pis Min                     -14.6059
Policy mu Mean                    0.00761965
Policy mu Std                     0.108319
Policy mu Max                     0.546652
Policy mu Min                    -0.558626
Policy log std Mean              -0.137756
Policy log std Std                0.0128358
Policy log std Max               -0.100465
Policy log std Min               -0.237557
Test Rewards Mean                -0.00152427
Test Rewards Std                  0.00346309
Test Rewards Max                  0.0164283
Test Rewards Min                 -0.00833775
Test Returns Mean                -0.365521
Test Returns Std                  0.413023
Test Returns Max                  0.460521
Test Returns Min                 -0.57402
Test Actions Mean                -0.0666344
Test Actions Std                  0.258236
Test Actions Max                  0.65868
Test Actions Min                 -0.857545
Num Paths                         9
Exploration Rewards Mean         -0.0064144
Exploration Rewards Std           0.00761751
Exploration Rewards Max           0.00590237
Exploration Rewards Min          -0.0211322
Exploration Returns Mean         -0.798237
Exploration Returns Std           0.00832102
Exploration Returns Max          -0.784842
Exploration Returns Min          -0.80829
Exploration Actions Mean          0.0035676
Exploration Actions Std           0.59019
Exploration Actions Max           0.998992
Exploration Actions Min          -0.998901
AverageReturn                    -0.365521
Number of train steps total  840844
Number of env steps total    841000
Number of rollouts total       6650
Train Time (s)                   19.6083
(Previous) Eval Time (s)          2.40399e-06
Sample Time (s)                  15.9112
Epoch Time (s)                   35.5195
Total Train Time (s)         116170
Epoch                           840
---------------------------  ----------------
2018-05-17 04:44:38.605564 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #840 | Epoch Duration: 921.0765690803528
2018-05-17 04:44:38.605707 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #840 | Started Training: True
2018-05-17 04:47:35.402223 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #841 | Epoch Duration: 176.7963902950287
2018-05-17 04:47:35.402517 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #841 | Started Training: True
2018-05-17 04:50:30.433890 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #842 | Epoch Duration: 175.03124070167542
2018-05-17 04:50:30.434111 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #842 | Started Training: True
2018-05-17 04:53:26.545724 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #843 | Epoch Duration: 176.11143970489502
2018-05-17 04:53:26.548580 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #843 | Started Training: True
2018-05-17 04:56:26.958871 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #844 | Epoch Duration: 180.4101002216339
2018-05-17 04:56:26.960981 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #844 | Started Training: True
2018-05-17 04:57:43.050022 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #845 | Epoch Duration: 76.08885502815247
2018-05-17 04:57:43.050246 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #845 | Started Training: True
2018-05-17 04:58:19.447185 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #846 | Epoch Duration: 36.39680624008179
2018-05-17 04:58:19.447445 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #846 | Started Training: True
2018-05-17 04:58:56.483527 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #847 | Epoch Duration: 37.03591752052307
2018-05-17 04:58:56.483731 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #847 | Started Training: True
2018-05-17 04:59:34.001332 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #848 | Epoch Duration: 37.51747727394104
2018-05-17 04:59:34.001605 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #848 | Started Training: True
2018-05-17 05:00:10.671542 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #849 | Epoch Duration: 36.66977596282959
2018-05-17 05:00:10.672540 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #849 | Started Training: True
2018-05-17 05:01:09.381959 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #850 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           3.3137
VF Loss                           3.95147
Policy Loss                      -2.44181
Q Predictions Mean              565.614
Q Predictions Std               244.283
Q Predictions Max               864.488
Q Predictions Min                 4.38769
V Predictions Mean              578.033
V Predictions Std               244.284
V Predictions Max               886.578
V Predictions Min                14.6466
Log Pis Mean                    -12.1912
Log Pis Std                       0.746567
Log Pis Max                     -10.1432
Log Pis Min                     -14.566
Policy mu Mean                    0.00558739
Policy mu Std                     0.105464
Policy mu Max                     0.528139
Policy mu Min                    -0.530207
Policy log std Mean              -0.142396
Policy log std Std                0.0152736
Policy log std Max               -0.0921381
Policy log std Min               -0.217765
Test Rewards Mean                 0.00292706
Test Rewards Std                  0.00552149
Test Rewards Max                  0.0157231
Test Rewards Min                 -0.00412299
Test Returns Mean                 0.453694
Test Returns Std                  0.00311275
Test Returns Max                  0.459931
Test Returns Min                  0.449632
Test Actions Mean                -0.0408468
Test Actions Std                  0.171153
Test Actions Max                  0.411762
Test Actions Min                 -0.660548
Num Paths                         8
Exploration Rewards Mean         -0.00633217
Exploration Rewards Std           0.00757515
Exploration Rewards Max           0.00551158
Exploration Rewards Min          -0.0211073
Exploration Returns Mean         -0.792313
Exploration Returns Std           0.012507
Exploration Returns Max          -0.775571
Exploration Returns Min          -0.8131
Exploration Actions Mean          0.00588764
Exploration Actions Std           0.588607
Exploration Actions Max           0.998907
Exploration Actions Min          -0.996704
AverageReturn                     0.453694
Number of train steps total  850844
Number of env steps total    851000
Number of rollouts total       6728
Train Time (s)                   20.9033
(Previous) Eval Time (s)          2.229e-06
Sample Time (s)                  16.4823
Epoch Time (s)                   37.3855
Total Train Time (s)         117393
Epoch                           850
---------------------------  ---------------
2018-05-17 05:05:00.968725 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #850 | Epoch Duration: 290.2960412502289
2018-05-17 05:05:00.968838 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #850 | Started Training: True
2018-05-17 05:08:03.973284 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #851 | Epoch Duration: 183.0043342113495
2018-05-17 05:08:03.974575 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #851 | Started Training: True
2018-05-17 05:11:02.271173 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #852 | Epoch Duration: 178.29643273353577
2018-05-17 05:11:02.271380 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #852 | Started Training: True
2018-05-17 05:13:58.291664 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #853 | Epoch Duration: 176.0201542377472
2018-05-17 05:13:58.291903 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #853 | Started Training: True
2018-05-17 05:16:56.097831 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #854 | Epoch Duration: 177.80579543113708
2018-05-17 05:16:56.098062 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #854 | Started Training: True
2018-05-17 05:19:17.966626 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #855 | Epoch Duration: 141.86844062805176
2018-05-17 05:19:17.966832 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #855 | Started Training: True
2018-05-17 05:19:54.423792 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #856 | Epoch Duration: 36.45683312416077
2018-05-17 05:19:54.424616 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #856 | Started Training: True
2018-05-17 05:20:31.563227 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #857 | Epoch Duration: 37.13840341567993
2018-05-17 05:20:31.563435 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #857 | Started Training: True
2018-05-17 05:21:08.858232 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #858 | Epoch Duration: 37.29468631744385
2018-05-17 05:21:08.858473 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #858 | Started Training: True
2018-05-17 05:21:44.879636 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #859 | Epoch Duration: 36.02098870277405
2018-05-17 05:21:44.879845 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #859 | Started Training: True
2018-05-17 05:22:44.123320 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #860 | Collecting samples for evaluation
---------------------------  ----------------
QF Loss                       53592.4
VF Loss                           8.09424
Policy Loss                     -15.3764
Q Predictions Mean              546.045
Q Predictions Std               280.854
Q Predictions Max              1702.96
Q Predictions Min                18.4603
V Predictions Mean              579.529
V Predictions Std               429.56
V Predictions Max              4424.19
V Predictions Min                32.051
Log Pis Mean                    -11.5242
Log Pis Std                       7.65517
Log Pis Max                      74.3427
Log Pis Min                     -14.3425
Policy mu Mean                   -0.00122619
Policy mu Std                     0.319436
Policy mu Max                     4.15445
Policy mu Min                    -4.20729
Policy log std Mean              -0.140415
Policy log std Std                0.0819407
Policy log std Max               -0.0104582
Policy log std Min               -2.67869
Test Rewards Mean                 0.00425526
Test Rewards Std                  0.00595356
Test Rewards Max                  0.0188474
Test Rewards Min                 -0.00168061
Test Returns Mean                 0.617621
Test Returns Std                  0.00366933
Test Returns Max                  0.620942
Test Returns Min                  0.609353
Test Actions Mean                -0.0243233
Test Actions Std                  0.165205
Test Actions Max                  0.430362
Test Actions Min                 -0.505575
Num Paths                         7
Exploration Rewards Mean         -0.00645611
Exploration Rewards Std           0.00761177
Exploration Rewards Max           0.0065028
Exploration Rewards Min          -0.0212875
Exploration Returns Mean         -0.795946
Exploration Returns Std           0.00488736
Exploration Returns Max          -0.785443
Exploration Returns Min          -0.802835
Exploration Actions Mean          0.0166405
Exploration Actions Std           0.588894
Exploration Actions Max           0.995482
Exploration Actions Min          -0.996451
AverageReturn                     0.617621
Number of train steps total  860844
Number of env steps total    861000
Number of rollouts total       6807
Train Time (s)                   20.883
(Previous) Eval Time (s)          1.91601e-06
Sample Time (s)                  16.4013
Epoch Time (s)                   37.2843
Total Train Time (s)         118624
Epoch                           860
---------------------------  ----------------
2018-05-17 05:25:32.487587 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #860 | Epoch Duration: 227.60760235786438
2018-05-17 05:25:32.487702 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #860 | Started Training: True
2018-05-17 05:28:33.548449 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #861 | Epoch Duration: 181.06064820289612
2018-05-17 05:28:33.548695 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #861 | Started Training: True
2018-05-17 05:31:32.013724 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #862 | Epoch Duration: 178.46489143371582
2018-05-17 05:31:32.013970 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #862 | Started Training: True
2018-05-17 05:34:29.090349 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #863 | Epoch Duration: 177.07624125480652
2018-05-17 05:34:29.090608 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #863 | Started Training: True
2018-05-17 05:37:51.181626 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #864 | Epoch Duration: 202.09088230133057
2018-05-17 05:37:51.181876 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #864 | Started Training: True
2018-05-17 05:41:07.557083 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #865 | Epoch Duration: 196.37507462501526
2018-05-17 05:41:07.557293 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #865 | Started Training: True
2018-05-17 05:44:11.662558 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #866 | Epoch Duration: 184.1051025390625
2018-05-17 05:44:11.662768 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #866 | Started Training: True
2018-05-17 05:44:52.703424 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #867 | Epoch Duration: 41.040485858917236
2018-05-17 05:44:52.704569 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #867 | Started Training: True
2018-05-17 05:45:30.183306 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #868 | Epoch Duration: 37.478553771972656
2018-05-17 05:45:30.185494 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #868 | Started Training: True
2018-05-17 05:46:07.502181 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #869 | Epoch Duration: 37.316487312316895
2018-05-17 05:46:07.504605 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #869 | Started Training: True
2018-05-17 05:47:06.905346 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #870 | Collecting samples for evaluation
---------------------------  ---------------
QF Loss                           2.94815
VF Loss                           1.81201
Policy Loss                       1.8546
Q Predictions Mean              538.871
Q Predictions Std               258.034
Q Predictions Max               866.879
Q Predictions Min                 6.71061
V Predictions Mean              550.867
V Predictions Std               257.403
V Predictions Max               877.045
V Predictions Min                21.0303
Log Pis Mean                    -12.1071
Log Pis Std                       0.672084
Log Pis Max                     -10.3234
Log Pis Min                     -13.3904
Policy mu Mean                    0.0186918
Policy mu Std                     0.104224
Policy mu Max                     0.521734
Policy mu Min                    -0.551945
Policy log std Mean              -0.136051
Policy log std Std                0.0125827
Policy log std Max               -0.0726441
Policy log std Min               -0.254903
Test Rewards Mean                 0.0026356
Test Rewards Std                  0.00564943
Test Rewards Max                  0.0135509
Test Rewards Min                 -0.00602496
Test Returns Mean                 0.449371
Test Returns Std                  0.00974866
Test Returns Max                  0.46418
Test Returns Min                  0.433521
Test Actions Mean                -0.0236439
Test Actions Std                  0.176815
Test Actions Max                  0.686446
Test Actions Min                 -0.811176
Num Paths                         6
Exploration Rewards Mean         -0.00634259
Exploration Rewards Std           0.00763259
Exploration Rewards Max           0.00686727
Exploration Rewards Min          -0.0213196
Exploration Returns Mean         -0.80128
Exploration Returns Std           0.0111901
Exploration Returns Max          -0.782984
Exploration Returns Min          -0.818811
Exploration Actions Mean         -0.00152281
Exploration Actions Std           0.588439
Exploration Actions Max           0.997472
Exploration Actions Min          -0.997331
AverageReturn                     0.449371
Number of train steps total  870844
Number of env steps total    871000
Number of rollouts total       6883
Train Time (s)                   21.2909
(Previous) Eval Time (s)          2.954e-06
Sample Time (s)                  15.9146
Epoch Time (s)                   37.2055
Total Train Time (s)         120427
Epoch                           870
---------------------------  ---------------
2018-05-17 05:55:36.302915 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #870 | Epoch Duration: 568.7981293201447
2018-05-17 05:55:36.303063 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #870 | Started Training: True
2018-05-17 06:00:06.000752 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #871 | Epoch Duration: 269.6975667476654
2018-05-17 06:00:06.004046 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #871 | Started Training: True
2018-05-17 06:02:34.875266 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #872 | Epoch Duration: 148.8710265159607
2018-05-17 06:02:34.875852 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #872 | Started Training: True
2018-05-17 06:03:15.626670 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #873 | Epoch Duration: 40.750664472579956
2018-05-17 06:03:15.626880 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #873 | Started Training: True
2018-05-17 06:03:53.455333 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #874 | Epoch Duration: 37.82829165458679
2018-05-17 06:03:53.455551 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #874 | Started Training: True
2018-05-17 06:04:30.271567 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #875 | Epoch Duration: 36.81587791442871
2018-05-17 06:04:30.271936 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #875 | Started Training: True
2018-05-17 06:05:07.561778 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #876 | Epoch Duration: 37.28941607475281
2018-05-17 06:05:07.562027 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #876 | Started Training: True
2018-05-17 06:05:44.163934 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #877 | Epoch Duration: 36.60178804397583
2018-05-17 06:05:44.164143 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #877 | Started Training: True
2018-05-17 06:06:21.027254 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #878 | Epoch Duration: 36.86298489570618
2018-05-17 06:06:21.027458 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #878 | Started Training: True
2018-05-17 06:06:59.003659 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #879 | Epoch Duration: 37.976083755493164
2018-05-17 06:06:59.004893 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #879 | Started Training: True
2018-05-17 06:10:59.534896 UTC | [name-of-experiment_2018_05_15_20_28_07_0000--s-0] Iteration #880 | Collecting samples for evaluation
