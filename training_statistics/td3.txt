2018-05-18 20:16:33.486291 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #0 | Skipping eval for now.
2018-05-18 20:16:33.486536 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #0 | Epoch Duration: 51.98419642448425
2018-05-18 20:16:33.486614 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #0 | Started Training: True
2018-05-18 20:17:53.550879 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #1 | Epoch Duration: 80.06414914131165
2018-05-18 20:17:53.551122 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #1 | Started Training: True
2018-05-18 20:19:10.129352 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #2 | Epoch Duration: 76.57805633544922
2018-05-18 20:19:10.129530 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #2 | Started Training: True
2018-05-18 20:20:06.921749 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #3 | Epoch Duration: 56.7920925617218
2018-05-18 20:20:06.921967 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #3 | Started Training: True
2018-05-18 20:21:00.995056 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #4 | Epoch Duration: 54.07292366027832
2018-05-18 20:21:00.995284 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #4 | Started Training: True
2018-05-18 20:21:57.998314 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #5 | Epoch Duration: 57.00285243988037
2018-05-18 20:21:57.998548 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #5 | Started Training: True
2018-05-18 20:23:00.329355 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #6 | Epoch Duration: 62.33064889907837
2018-05-18 20:23:00.329545 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #6 | Started Training: True
2018-05-18 20:24:06.042853 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #7 | Epoch Duration: 65.71318769454956
2018-05-18 20:24:06.043087 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #7 | Started Training: True
2018-05-18 20:25:17.426197 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #8 | Epoch Duration: 71.38293409347534
2018-05-18 20:25:17.426459 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #8 | Started Training: True
2018-05-18 20:26:25.894690 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #9 | Epoch Duration: 68.46804904937744
2018-05-18 20:26:25.894862 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #9 | Started Training: True
2018-05-18 20:27:39.749527 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #10 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         1.7391e-05
QF2 Loss                         5.81137e-06
Policy Loss                      0.0349002
Q1 Predictions Mean              0.0058505
Q1 Predictions Std               0.00037657
Q1 Predictions Max               0.0067822
Q1 Predictions Min               0.00466648
Q2 Predictions Mean              0.000983596
Q2 Predictions Std               0.000777188
Q2 Predictions Max               0.00228816
Q2 Predictions Min              -0.0011984
Q Targets Mean                   0.00218585
Q Targets Std                    0.00191237
Q Targets Max                    0.00638563
Q Targets Min                   -0.00117084
Bellman Errors 1 Mean            1.7391e-05
Bellman Errors 1 Std             1.44737e-05
Bellman Errors 1 Max             4.96142e-05
Bellman Errors 1 Min             1.12629e-11
Bellman Errors 2 Mean            5.81137e-06
Bellman Errors 2 Std             6.51947e-06
Bellman Errors 2 Max             2.81682e-05
Bellman Errors 2 Min             9.0174e-11
Policy Action Mean               0.000314161
Policy Action Std                0.00498687
Policy Action Max                0.0129917
Policy Action Min               -0.00836575
Test Rewards Mean                0.00227946
Test Rewards Std                 0.00521972
Test Rewards Max                 0.0167695
Test Rewards Min                -0.0191179
Test Returns Mean                0.244799
Test Returns Std                 0.413003
Test Returns Max                 0.581225
Test Returns Min                -1.01632
Test Actions Mean                0.0913284
Test Actions Std                 0.944723
Test Actions Max                 1
Test Actions Min                -1
Num Paths                       21
Exploration Rewards Mean        -0.00196471
Exploration Rewards Std          0.00726475
Exploration Rewards Max          0.0135213
Exploration Rewards Min         -0.0239064
Exploration Returns Mean        -0.21303
Exploration Returns Std          0.618013
Exploration Returns Max          0.560313
Exploration Returns Min         -1.46396
Exploration Actions Mean        -0.00941568
Exploration Actions Std          0.909042
Exploration Actions Max          1
Exploration Actions Min         -1
AverageReturn                    0.244799
Number of train steps total  20987
Number of env steps total    22000
Number of rollouts total       199
Train Time (s)                  36.9708
(Previous) Eval Time (s)         1.882e-06
Sample Time (s)                 31.1549
Epoch Time (s)                  68.1257
Total Train Time (s)          2888.77
Epoch                           10
---------------------------  ---------------
2018-05-18 21:03:50.962877 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #10 | Epoch Duration: 2245.06790971756
2018-05-18 21:03:50.963001 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #10 | Started Training: True
2018-05-18 21:04:52.102202 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #11 | Epoch Duration: 61.139070987701416
2018-05-18 21:04:52.102464 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #11 | Started Training: True
2018-05-18 21:05:56.095242 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #12 | Epoch Duration: 63.99258089065552
2018-05-18 21:05:56.095409 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #12 | Started Training: True
2018-05-18 21:06:58.469109 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #13 | Epoch Duration: 62.37358093261719
2018-05-18 21:06:58.469353 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #13 | Started Training: True
2018-05-18 21:08:19.396001 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #14 | Epoch Duration: 80.92647862434387
2018-05-18 21:08:19.396249 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #14 | Started Training: True
2018-05-18 21:09:34.075953 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #15 | Epoch Duration: 74.67953586578369
2018-05-18 21:09:34.076128 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #15 | Started Training: True
2018-05-18 21:10:41.829453 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #16 | Epoch Duration: 67.75320100784302
2018-05-18 21:10:41.829682 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #16 | Started Training: True
2018-05-18 21:11:38.200734 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #17 | Epoch Duration: 56.37088871002197
2018-05-18 21:11:38.200891 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #17 | Started Training: True
2018-05-18 21:12:31.890808 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #18 | Epoch Duration: 53.689799785614014
2018-05-18 21:12:31.890976 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #18 | Started Training: True
2018-05-18 21:13:23.242530 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #19 | Epoch Duration: 51.351436376571655
2018-05-18 21:13:23.242759 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #19 | Started Training: True
2018-05-18 21:14:22.909059 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #20 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         8.93596e-05
QF2 Loss                         9.39722e-05
Policy Loss                      0.0267625
Q1 Predictions Mean             -0.0362593
Q1 Predictions Std               0.104022
Q1 Predictions Max               0.192149
Q1 Predictions Min              -0.328894
Q2 Predictions Mean             -0.0368693
Q2 Predictions Std               0.103561
Q2 Predictions Max               0.209381
Q2 Predictions Min              -0.3289
Q Targets Mean                  -0.0351019
Q Targets Std                    0.104338
Q Targets Max                    0.19947
Q Targets Min                   -0.320803
Bellman Errors 1 Mean            8.93596e-05
Bellman Errors 1 Std             0.000622188
Bellman Errors 1 Max             0.00706529
Bellman Errors 1 Min             1.50283e-08
Bellman Errors 2 Mean            9.39722e-05
Bellman Errors 2 Std             0.000679195
Bellman Errors 2 Max             0.00772762
Bellman Errors 2 Min             3.95426e-11
Policy Action Mean               0.00605535
Policy Action Std                0.937486
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean                0.00495053
Test Rewards Std                 0.00388957
Test Rewards Max                 0.015398
Test Rewards Min                -0.0173946
Test Returns Mean                0.533858
Test Returns Std                 0.191971
Test Returns Max                 0.700044
Test Returns Min                -0.796282
Test Actions Mean                0.111531
Test Actions Std                 0.928059
Test Actions Max                 1
Test Actions Min                -1
Num Paths                       17
Exploration Rewards Mean         0.00483272
Exploration Rewards Std          0.00366422
Exploration Rewards Max          0.0147062
Exploration Rewards Min         -0.00448067
Exploration Returns Mean         0.550362
Exploration Returns Std          0.130945
Exploration Returns Max          0.685069
Exploration Returns Min          0.12551
Exploration Actions Mean         0.104409
Exploration Actions Std          0.90714
Exploration Actions Max          1
Exploration Actions Min         -1
AverageReturn                    0.533858
Number of train steps total  40987
Number of env steps total    42000
Number of rollouts total       412
Train Time (s)                  29.6571
(Previous) Eval Time (s)         3.327e-06
Sample Time (s)                 22.557
Epoch Time (s)                  52.2142
Total Train Time (s)          5265.34
Epoch                           20
---------------------------  ---------------
2018-05-18 21:43:28.163015 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #20 | Epoch Duration: 1804.920083284378
2018-05-18 21:43:28.163135 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #20 | Started Training: True
2018-05-18 21:44:20.844530 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #21 | Epoch Duration: 52.68128705024719
2018-05-18 21:44:20.844769 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #21 | Started Training: True
2018-05-18 21:45:15.198401 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #22 | Epoch Duration: 54.35345649719238
2018-05-18 21:45:15.198636 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #22 | Started Training: True
2018-05-18 21:46:06.469969 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #23 | Epoch Duration: 51.27116131782532
2018-05-18 21:46:06.470194 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #23 | Started Training: True
2018-05-18 21:46:59.173029 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #24 | Epoch Duration: 52.70267033576965
2018-05-18 21:46:59.173205 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #24 | Started Training: True
2018-05-18 21:47:52.183448 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #25 | Epoch Duration: 53.01010203361511
2018-05-18 21:47:52.183611 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #25 | Started Training: True
2018-05-18 21:48:45.806840 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #26 | Epoch Duration: 53.62311124801636
2018-05-18 21:48:45.807126 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #26 | Started Training: True
2018-05-18 21:49:40.185180 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #27 | Epoch Duration: 54.3778715133667
2018-05-18 21:49:40.185402 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #27 | Started Training: True
2018-05-18 21:50:33.009801 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #28 | Epoch Duration: 52.824235677719116
2018-05-18 21:50:33.009971 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #28 | Started Training: True
2018-05-18 21:51:26.708421 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #29 | Epoch Duration: 53.69831466674805
2018-05-18 21:51:26.708588 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #29 | Started Training: True
2018-05-18 21:52:29.960774 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #30 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000351327
QF2 Loss                         0.000339526
Policy Loss                     -0.0349761
Q1 Predictions Mean              0.0222154
Q1 Predictions Std               0.162164
Q1 Predictions Max               0.319572
Q1 Predictions Min              -0.333505
Q2 Predictions Mean              0.0228194
Q2 Predictions Std               0.162808
Q2 Predictions Max               0.319532
Q2 Predictions Min              -0.333432
Q Targets Mean                   0.0228431
Q Targets Std                    0.162948
Q Targets Max                    0.318158
Q Targets Min                   -0.34844
Bellman Errors 1 Mean            0.000351327
Bellman Errors 1 Std             0.00327737
Bellman Errors 1 Max             0.0372655
Bellman Errors 1 Min             1.75348e-08
Bellman Errors 2 Mean            0.000339526
Bellman Errors 2 Std             0.0033139
Bellman Errors 2 Max             0.0376786
Bellman Errors 2 Min             3.15495e-10
Policy Action Mean               0.0163283
Policy Action Std                0.950088
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean                0.00561185
Test Rewards Std                 0.00440762
Test Rewards Max                 0.016669
Test Rewards Min                -0.00822053
Test Returns Mean                0.712564
Test Returns Std                 0.241262
Test Returns Max                 0.856098
Test Returns Min                -0.218328
Test Actions Mean               -0.179411
Test Actions Std                 0.930096
Test Actions Max                 1
Test Actions Min                -1
Num Paths                       15
Exploration Rewards Mean         0.00533148
Exploration Rewards Std          0.00534392
Exploration Rewards Max          0.0169373
Exploration Rewards Min         -0.0218728
Exploration Returns Mean         0.699135
Exploration Returns Std          0.367005
Exploration Returns Max          0.831696
Exploration Returns Min         -0.671349
Exploration Actions Mean        -0.145775
Exploration Actions Std          0.900043
Exploration Actions Max          1
Exploration Actions Min         -1
AverageReturn                    0.712564
Number of train steps total  60987
Number of env steps total    62000
Number of rollouts total       545
Train Time (s)                  31.7216
(Previous) Eval Time (s)         2.105e-06
Sample Time (s)                 23.3242
Epoch Time (s)                  55.0459
Total Train Time (s)          7563.97
Epoch                           30
---------------------------  ---------------
2018-05-18 22:21:47.353921 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #30 | Epoch Duration: 1820.6452283859253
2018-05-18 22:21:47.354045 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #30 | Started Training: True
2018-05-18 22:22:43.706802 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #31 | Epoch Duration: 56.35265588760376
2018-05-18 22:22:43.706962 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #31 | Started Training: True
2018-05-18 22:23:40.948353 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #32 | Epoch Duration: 57.241270303726196
2018-05-18 22:23:40.948602 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #32 | Started Training: True
2018-05-18 22:24:38.664249 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #33 | Epoch Duration: 57.715481996536255
2018-05-18 22:24:38.664508 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #33 | Started Training: True
2018-05-18 22:25:36.660541 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #34 | Epoch Duration: 57.995880365371704
2018-05-18 22:25:36.660756 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #34 | Started Training: True
2018-05-18 22:26:36.202400 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #35 | Epoch Duration: 59.540931701660156
2018-05-18 22:26:36.202624 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #35 | Started Training: True
2018-05-18 22:27:34.913725 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #36 | Epoch Duration: 58.71094608306885
2018-05-18 22:27:34.913897 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #36 | Started Training: True
2018-05-18 22:28:33.776405 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #37 | Epoch Duration: 58.86237668991089
2018-05-18 22:28:33.776576 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #37 | Started Training: True
2018-05-18 22:29:33.154256 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #38 | Epoch Duration: 59.377554416656494
2018-05-18 22:29:33.154424 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #38 | Started Training: True
2018-05-18 22:30:30.445119 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #39 | Epoch Duration: 57.29057049751282
2018-05-18 22:30:30.445338 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #39 | Started Training: True
2018-05-18 22:31:37.301407 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #40 | Collecting samples for evaluation
---------------------------  ---------------
QF1 Loss                         0.000409761
QF2 Loss                         0.000440869
Policy Loss                     -0.139685
Q1 Predictions Mean              0.1242
Q1 Predictions Std               0.19655
Q1 Predictions Max               0.401111
Q1 Predictions Min              -0.382238
Q2 Predictions Mean              0.123193
Q2 Predictions Std               0.197556
Q2 Predictions Max               0.396814
Q2 Predictions Min              -0.394326
Q Targets Mean                   0.126635
Q Targets Std                    0.198849
Q Targets Max                    0.4031
Q Targets Min                   -0.390414
Bellman Errors 1 Mean            0.000409761
Bellman Errors 1 Std             0.00264468
Bellman Errors 1 Max             0.0249058
Bellman Errors 1 Min             9.2835e-09
Bellman Errors 2 Mean            0.000440869
Bellman Errors 2 Std             0.00290587
Bellman Errors 2 Max             0.0285235
Bellman Errors 2 Min             1.44385e-09
Policy Action Mean              -0.123843
Policy Action Std                0.946
Policy Action Max                1
Policy Action Min               -1
Test Rewards Mean                0.00580649
Test Rewards Std                 0.00455455
Test Rewards Max                 0.0160297
Test Rewards Min                -0.0205627
Test Returns Mean                0.755145
Test Returns Std                 0.251682
Test Returns Max                 0.958193
Test Returns Min                -0.762016
Test Actions Mean               -0.0555489
Test Actions Std                 0.946389
Test Actions Max                 1
Test Actions Min                -1
Num Paths                       19
Exploration Rewards Mean         0.0068107
Exploration Rewards Std          0.00419759
Exploration Rewards Max          0.0174538
Exploration Rewards Min         -0.00115407
Exploration Returns Mean         0.803304
Exploration Returns Std          0.0479838
Exploration Returns Max          0.879741
Exploration Returns Min          0.716347
Exploration Actions Mean        -0.103869
Exploration Actions Std          0.913687
Exploration Actions Max          1
Exploration Actions Min         -1
AverageReturn                    0.755145
Number of train steps total  80987
Number of env steps total    82000
Number of rollouts total       699
Train Time (s)                  33.1591
(Previous) Eval Time (s)         3.097e-06
Sample Time (s)                 24.8569
Epoch Time (s)                  58.016
Total Train Time (s)          9896.76
Epoch                           40
---------------------------  ---------------
2018-05-18 23:00:40.682249 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #40 | Epoch Duration: 1810.236752986908
2018-05-18 23:00:40.682370 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #40 | Started Training: True
2018-05-18 23:01:38.567177 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #41 | Epoch Duration: 57.88469386100769
2018-05-18 23:01:38.567404 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #41 | Started Training: True
2018-05-18 23:02:35.841419 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #42 | Epoch Duration: 57.273839235305786
2018-05-18 23:02:35.841641 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #42 | Started Training: True
2018-05-18 23:03:32.761563 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #43 | Epoch Duration: 56.91974091529846
2018-05-18 23:03:32.761740 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #43 | Started Training: True
2018-05-18 23:04:30.343731 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #44 | Epoch Duration: 57.58187651634216
2018-05-18 23:04:30.343912 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #44 | Started Training: True
2018-05-18 23:05:27.579620 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #45 | Epoch Duration: 57.235588788986206
2018-05-18 23:05:27.579851 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #45 | Started Training: True
2018-05-18 23:06:24.850490 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #46 | Epoch Duration: 57.27046084403992
2018-05-18 23:06:24.850658 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #46 | Started Training: True
2018-05-18 23:07:21.592492 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #47 | Epoch Duration: 56.74172115325928
2018-05-18 23:07:21.592651 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #47 | Started Training: True
2018-05-18 23:08:19.515035 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #48 | Epoch Duration: 57.92225885391235
2018-05-18 23:08:19.515267 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #48 | Started Training: True
2018-05-18 23:09:17.289047 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #49 | Epoch Duration: 57.773611545562744
2018-05-18 23:09:17.289215 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #49 | Started Training: True
2018-05-18 23:10:24.665446 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #50 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000130119
QF2 Loss                          0.000123287
Policy Loss                      -0.259224
Q1 Predictions Mean               0.247035
Q1 Predictions Std                0.264893
Q1 Predictions Max                0.569227
Q1 Predictions Min               -0.392716
Q2 Predictions Mean               0.245955
Q2 Predictions Std                0.265263
Q2 Predictions Max                0.56957
Q2 Predictions Min               -0.383063
Q Targets Mean                    0.247262
Q Targets Std                     0.265993
Q Targets Max                     0.576212
Q Targets Min                    -0.391695
Bellman Errors 1 Mean             0.000130119
Bellman Errors 1 Std              0.000318918
Bellman Errors 1 Max              0.00233188
Bellman Errors 1 Min              9.36788e-10
Bellman Errors 2 Mean             0.000123287
Bellman Errors 2 Std              0.000259146
Bellman Errors 2 Max              0.00140619
Bellman Errors 2 Min              6.29385e-09
Policy Action Mean               -0.0707917
Policy Action Std                 0.952496
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00682066
Test Rewards Std                  0.00443355
Test Rewards Max                  0.0185889
Test Rewards Min                 -0.00209333
Test Returns Mean                 0.833368
Test Returns Std                  0.0704478
Test Returns Max                  0.927991
Test Returns Min                  0.558892
Test Actions Mean                 0.00660204
Test Actions Std                  0.96745
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        16
Exploration Rewards Mean          0.00577552
Exploration Rewards Std           0.00566242
Exploration Rewards Max           0.0183617
Exploration Rewards Min          -0.0201383
Exploration Returns Mean          0.690175
Exploration Returns Std           0.374111
Exploration Returns Max           0.838336
Exploration Returns Min          -0.755121
Exploration Actions Mean         -0.0722652
Exploration Actions Std           0.925331
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.833368
Number of train steps total  100987
Number of env steps total    102000
Number of rollouts total        853
Train Time (s)                   33.6314
(Previous) Eval Time (s)          2.028e-06
Sample Time (s)                  24.3781
Epoch Time (s)                   58.0095
Total Train Time (s)          12216.9
Epoch                            50
---------------------------  ----------------
2018-05-18 23:39:21.367850 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #50 | Epoch Duration: 1804.0785324573517
2018-05-18 23:39:21.367972 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #50 | Started Training: True
2018-05-18 23:40:19.782032 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #51 | Epoch Duration: 58.41395330429077
2018-05-18 23:40:19.782255 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #51 | Started Training: True
2018-05-18 23:41:18.160958 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #52 | Epoch Duration: 58.37853407859802
2018-05-18 23:41:18.161187 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #52 | Started Training: True
2018-05-18 23:42:22.270591 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #53 | Epoch Duration: 64.10925030708313
2018-05-18 23:42:22.270760 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #53 | Started Training: True
2018-05-18 23:43:19.739369 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #54 | Epoch Duration: 57.46849298477173
2018-05-18 23:43:19.739602 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #54 | Started Training: True
2018-05-18 23:44:17.343241 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #55 | Epoch Duration: 57.603450536727905
2018-05-18 23:44:17.343400 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #55 | Started Training: True
2018-05-18 23:45:15.688480 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #56 | Epoch Duration: 58.34496331214905
2018-05-18 23:45:15.688733 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #56 | Started Training: True
2018-05-18 23:46:13.138663 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #57 | Epoch Duration: 57.44977140426636
2018-05-18 23:46:13.138847 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #57 | Started Training: True
2018-05-18 23:47:10.396946 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #58 | Epoch Duration: 57.25798058509827
2018-05-18 23:47:10.397139 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #58 | Started Training: True
2018-05-18 23:48:08.221485 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #59 | Epoch Duration: 57.82421898841858
2018-05-18 23:48:08.221652 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #59 | Started Training: True
2018-05-18 23:49:15.865526 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #60 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000260745
QF2 Loss                          0.00022907
Policy Loss                      -0.347421
Q1 Predictions Mean               0.335289
Q1 Predictions Std                0.274332
Q1 Predictions Max                0.626648
Q1 Predictions Min               -0.624081
Q2 Predictions Mean               0.337825
Q2 Predictions Std                0.270577
Q2 Predictions Max                0.621828
Q2 Predictions Min               -0.583861
Q Targets Mean                    0.33367
Q Targets Std                     0.2692
Q Targets Max                     0.605186
Q Targets Min                    -0.587672
Bellman Errors 1 Mean             0.000260745
Bellman Errors 1 Std              0.000848991
Bellman Errors 1 Max              0.0070805
Bellman Errors 1 Min              2.2313e-09
Bellman Errors 2 Mean             0.00022907
Bellman Errors 2 Std              0.000765136
Bellman Errors 2 Max              0.00560447
Bellman Errors 2 Min              8.62373e-09
Policy Action Mean               -0.00221809
Policy Action Std                 0.971242
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.0068254
Test Rewards Std                  0.00501285
Test Rewards Max                  0.0207746
Test Rewards Min                 -0.00308095
Test Returns Mean                 0.907869
Test Returns Std                  0.0504398
Test Returns Max                  0.997346
Test Returns Min                  0.657964
Test Actions Mean                -0.261305
Test Actions Std                  0.933098
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        18
Exploration Rewards Mean          0.00660631
Exploration Rewards Std           0.0047402
Exploration Rewards Max           0.0204385
Exploration Rewards Min          -0.00150452
Exploration Returns Mean          0.823953
Exploration Returns Std           0.070307
Exploration Returns Max           0.934572
Exploration Returns Min           0.725461
Exploration Actions Mean         -0.244304
Exploration Actions Std           0.906745
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.907869
Number of train steps total  120987
Number of env steps total    122000
Number of rollouts total       1005
Train Time (s)                   32.7069
(Previous) Eval Time (s)          2.182e-06
Sample Time (s)                  25.0391
Epoch Time (s)                   57.7461
Total Train Time (s)          14505.9
Epoch                            60
---------------------------  ----------------
2018-05-19 00:17:30.889117 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #60 | Epoch Duration: 1762.667349100113
2018-05-19 00:17:30.889246 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #60 | Started Training: True
2018-05-19 00:18:28.369293 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #61 | Epoch Duration: 57.479942083358765
2018-05-19 00:18:28.369457 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #61 | Started Training: True
2018-05-19 00:19:25.774517 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #62 | Epoch Duration: 57.40495157241821
2018-05-19 00:19:25.774686 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #62 | Started Training: True
2018-05-19 00:20:24.686972 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #63 | Epoch Duration: 58.91217517852783
2018-05-19 00:20:24.687137 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #63 | Started Training: True
2018-05-19 00:21:23.881534 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #64 | Epoch Duration: 59.1942834854126
2018-05-19 00:21:23.881713 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #64 | Started Training: True
2018-05-19 00:22:23.975870 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #65 | Epoch Duration: 60.09403991699219
2018-05-19 00:22:23.976121 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #65 | Started Training: True
2018-05-19 00:23:24.462235 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #66 | Epoch Duration: 60.48595404624939
2018-05-19 00:23:24.462473 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #66 | Started Training: True
2018-05-19 00:24:24.421135 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #67 | Epoch Duration: 59.958492040634155
2018-05-19 00:24:24.421304 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #67 | Started Training: True
2018-05-19 00:25:24.016269 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #68 | Epoch Duration: 59.59484243392944
2018-05-19 00:25:24.016467 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #68 | Started Training: True
2018-05-19 00:26:23.355097 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #69 | Epoch Duration: 59.338502407073975
2018-05-19 00:26:23.355270 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #69 | Started Training: True
2018-05-19 00:27:33.227058 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #70 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000150603
QF2 Loss                          0.000132012
Policy Loss                      -0.288983
Q1 Predictions Mean               0.279144
Q1 Predictions Std                0.222514
Q1 Predictions Max                0.550675
Q1 Predictions Min               -0.294275
Q2 Predictions Mean               0.281379
Q2 Predictions Std                0.223746
Q2 Predictions Max                0.557393
Q2 Predictions Min               -0.302464
Q Targets Mean                    0.276903
Q Targets Std                     0.223307
Q Targets Max                     0.558757
Q Targets Min                    -0.298875
Bellman Errors 1 Mean             0.000150603
Bellman Errors 1 Std              0.000491141
Bellman Errors 1 Max              0.00341633
Bellman Errors 1 Min              3.91687e-09
Bellman Errors 2 Mean             0.000132012
Bellman Errors 2 Std              0.000325587
Bellman Errors 2 Max              0.00243621
Bellman Errors 2 Min              7.52118e-11
Policy Action Mean               -0.174822
Policy Action Std                 0.964691
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00340569
Test Rewards Std                  0.005508
Test Rewards Max                  0.0192912
Test Rewards Min                 -0.021934
Test Returns Mean                 0.663193
Test Returns Std                  0.577849
Test Returns Max                  1.29645
Test Returns Min                 -0.799196
Test Actions Mean                 0.0307947
Test Actions Std                  0.970812
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        14
Exploration Rewards Mean          0.00524324
Exploration Rewards Std           0.00459881
Exploration Rewards Max           0.0165357
Exploration Rewards Min          -0.00308163
Exploration Returns Mean          0.946031
Exploration Returns Std           0.151974
Exploration Returns Max           1.48906
Exploration Returns Min           0.864327
Exploration Actions Mean         -0.0612345
Exploration Actions Std           0.936552
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.663193
Number of train steps total  140987
Number of env steps total    142000
Number of rollouts total       1142
Train Time (s)                   34.2054
(Previous) Eval Time (s)          2.17e-06
Sample Time (s)                  25.0269
Epoch Time (s)                   59.2322
Total Train Time (s)          16827.1
Epoch                            70
---------------------------  ----------------
2018-05-19 00:56:12.568072 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #70 | Epoch Duration: 1789.2126970291138
2018-05-19 00:56:12.568200 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #70 | Started Training: True
2018-05-19 00:57:12.178015 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #71 | Epoch Duration: 59.60969805717468
2018-05-19 00:57:12.178239 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #71 | Started Training: True
2018-05-19 00:58:12.598027 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #72 | Epoch Duration: 60.41961359977722
2018-05-19 00:58:12.598190 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #72 | Started Training: True
2018-05-19 00:59:12.175193 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #73 | Epoch Duration: 59.57689452171326
2018-05-19 00:59:12.175354 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #73 | Started Training: True
2018-05-19 01:00:12.250129 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #74 | Epoch Duration: 60.07465744018555
2018-05-19 01:00:12.250363 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #74 | Started Training: True
2018-05-19 01:01:11.506376 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #75 | Epoch Duration: 59.255842447280884
2018-05-19 01:01:11.506543 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #75 | Started Training: True
2018-05-19 01:02:11.097752 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #76 | Epoch Duration: 59.59109163284302
2018-05-19 01:02:11.097915 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #76 | Started Training: True
2018-05-19 01:03:09.118471 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #77 | Epoch Duration: 58.02044486999512
2018-05-19 01:03:09.118631 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #77 | Started Training: True
2018-05-19 01:04:07.561885 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #78 | Epoch Duration: 58.443150758743286
2018-05-19 01:04:07.562052 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #78 | Started Training: True
2018-05-19 01:05:06.483422 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #79 | Epoch Duration: 58.92125082015991
2018-05-19 01:05:06.483589 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #79 | Started Training: True
2018-05-19 01:06:17.020869 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #80 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000114441
QF2 Loss                          0.000105192
Policy Loss                      -0.271499
Q1 Predictions Mean               0.26319
Q1 Predictions Std                0.238165
Q1 Predictions Max                0.510267
Q1 Predictions Min               -0.615691
Q2 Predictions Mean               0.261429
Q2 Predictions Std                0.240314
Q2 Predictions Max                0.503533
Q2 Predictions Min               -0.633504
Q Targets Mean                    0.264101
Q Targets Std                     0.243854
Q Targets Max                     0.514841
Q Targets Min                    -0.642472
Bellman Errors 1 Mean             0.000114441
Bellman Errors 1 Std              0.000193211
Bellman Errors 1 Max              0.000947145
Bellman Errors 1 Min              2.02935e-10
Bellman Errors 2 Mean             0.000105192
Bellman Errors 2 Std              0.000249707
Bellman Errors 2 Max              0.00224765
Bellman Errors 2 Min              2.0588e-09
Policy Action Mean                0.0158343
Policy Action Std                 0.980087
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00688575
Test Rewards Std                  0.0040818
Test Rewards Max                  0.0166162
Test Rewards Min                 -0.00172994
Test Returns Mean                 0.870703
Test Returns Std                  0.0242092
Test Returns Max                  0.930627
Test Returns Min                  0.832088
Test Actions Mean                 0.0817574
Test Actions Std                  0.979723
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        14
Exploration Rewards Mean          0.00648685
Exploration Rewards Std           0.00371989
Exploration Rewards Max           0.0167542
Exploration Rewards Min          -0.00202031
Exploration Returns Mean          0.825684
Exploration Returns Std           0.0350439
Exploration Returns Max           0.908239
Exploration Returns Min           0.749668
Exploration Actions Mean          0.208689
Exploration Actions Std           0.924633
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.870703
Number of train steps total  160987
Number of env steps total    162000
Number of rollouts total       1281
Train Time (s)                   33.4277
(Previous) Eval Time (s)          2.319e-06
Sample Time (s)                  25.637
Epoch Time (s)                   59.0647
Total Train Time (s)          19124.2
Epoch                            80
---------------------------  ----------------
2018-05-19 01:34:30.198516 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #80 | Epoch Duration: 1763.7148132324219
2018-05-19 01:34:30.198638 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #80 | Started Training: True
2018-05-19 01:35:29.383986 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #81 | Epoch Duration: 59.18524980545044
2018-05-19 01:35:29.384161 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #81 | Started Training: True
2018-05-19 01:36:28.389233 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #82 | Epoch Duration: 59.00495624542236
2018-05-19 01:36:28.389396 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #82 | Started Training: True
2018-05-19 01:37:28.347741 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #83 | Epoch Duration: 59.95822501182556
2018-05-19 01:37:28.347905 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #83 | Started Training: True
2018-05-19 01:38:27.913157 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #84 | Epoch Duration: 59.56513333320618
2018-05-19 01:38:27.913340 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #84 | Started Training: True
2018-05-19 01:39:28.281614 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #85 | Epoch Duration: 60.36815333366394
2018-05-19 01:39:28.281774 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #85 | Started Training: True
2018-05-19 01:40:29.024875 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #86 | Epoch Duration: 60.742971420288086
2018-05-19 01:40:29.025100 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #86 | Started Training: True
2018-05-19 01:41:30.769154 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #87 | Epoch Duration: 61.743887186050415
2018-05-19 01:41:30.769396 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #87 | Started Training: True
2018-05-19 01:42:33.112629 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #88 | Epoch Duration: 62.34306788444519
2018-05-19 01:42:33.112810 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #88 | Started Training: True
2018-05-19 01:43:34.797617 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #89 | Epoch Duration: 61.68468475341797
2018-05-19 01:43:34.797784 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #89 | Started Training: True
2018-05-19 01:44:51.973066 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #90 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00017059
QF2 Loss                          6.90155e-05
Policy Loss                      -0.271574
Q1 Predictions Mean               0.266369
Q1 Predictions Std                0.221169
Q1 Predictions Max                0.518809
Q1 Predictions Min               -0.381962
Q2 Predictions Mean               0.263399
Q2 Predictions Std                0.219845
Q2 Predictions Max                0.513327
Q2 Predictions Min               -0.386209
Q Targets Mean                    0.264252
Q Targets Std                     0.218692
Q Targets Max                     0.517106
Q Targets Min                    -0.390155
Bellman Errors 1 Mean             0.00017059
Bellman Errors 1 Std              0.000624768
Bellman Errors 1 Max              0.00601537
Bellman Errors 1 Min              2.10302e-08
Bellman Errors 2 Mean             6.90155e-05
Bellman Errors 2 Std              0.000197552
Bellman Errors 2 Max              0.00142421
Bellman Errors 2 Min              9.67226e-11
Policy Action Mean                0.0520103
Policy Action Std                 0.979959
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00540847
Test Rewards Std                  0.00548505
Test Rewards Max                  0.0246073
Test Rewards Min                 -0.0137957
Test Returns Mean                 1.1611
Test Returns Std                  0.534538
Test Returns Max                  1.85124
Test Returns Min                 -0.179673
Test Actions Mean                -0.0270108
Test Actions Std                  0.980296
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         9
Exploration Rewards Mean          0.00662979
Exploration Rewards Std           0.00440512
Exploration Rewards Max           0.0206146
Exploration Rewards Min          -0.000935646
Exploration Returns Mean          1.05929
Exploration Returns Std           0.188657
Exploration Returns Max           1.46133
Exploration Returns Min           0.832102
Exploration Actions Mean         -0.129877
Exploration Actions Std           0.935845
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.1611
Number of train steps total  180987
Number of env steps total    182000
Number of rollouts total       1422
Train Time (s)                   38.7999
(Previous) Eval Time (s)          2.261e-06
Sample Time (s)                  27.0572
Epoch Time (s)                   65.8571
Total Train Time (s)          22367.5
Epoch                            90
---------------------------  ----------------
2018-05-19 02:28:34.047478 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #90 | Epoch Duration: 2699.2495918273926
2018-05-19 02:28:34.047598 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #90 | Started Training: True
2018-05-19 02:29:37.826415 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #91 | Epoch Duration: 63.77871561050415
2018-05-19 02:29:37.826580 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #91 | Started Training: True
2018-05-19 02:30:41.680736 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #92 | Epoch Duration: 63.854036808013916
2018-05-19 02:30:41.681013 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #92 | Started Training: True
2018-05-19 02:31:46.301798 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #93 | Epoch Duration: 64.62061214447021
2018-05-19 02:31:46.301978 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #93 | Started Training: True
2018-05-19 02:32:47.341621 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #94 | Epoch Duration: 61.039536476135254
2018-05-19 02:32:47.341792 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #94 | Started Training: True
2018-05-19 02:33:51.636893 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #95 | Epoch Duration: 64.29498982429504
2018-05-19 02:33:51.637066 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #95 | Started Training: True
2018-05-19 02:34:54.438021 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #96 | Epoch Duration: 62.800846099853516
2018-05-19 02:34:54.438193 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #96 | Started Training: True
2018-05-19 02:35:54.714716 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #97 | Epoch Duration: 60.2763991355896
2018-05-19 02:35:54.714971 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #97 | Started Training: True
2018-05-19 02:37:03.760443 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #98 | Epoch Duration: 69.04530620574951
2018-05-19 02:37:03.760620 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #98 | Started Training: True
2018-05-19 02:38:05.782809 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #99 | Epoch Duration: 62.022074699401855
2018-05-19 02:38:05.782996 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #99 | Started Training: True
2018-05-19 02:39:22.431038 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #100 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00135728
QF2 Loss                          0.00073241
Policy Loss                      -0.238006
Q1 Predictions Mean               0.232609
Q1 Predictions Std                0.216847
Q1 Predictions Max                0.539537
Q1 Predictions Min               -0.60817
Q2 Predictions Mean               0.231551
Q2 Predictions Std                0.215042
Q2 Predictions Max                0.540955
Q2 Predictions Min               -0.578488
Q Targets Mean                    0.228911
Q Targets Std                     0.215344
Q Targets Max                     0.542322
Q Targets Min                    -0.582702
Bellman Errors 1 Mean             0.00135728
Bellman Errors 1 Std              0.0114984
Bellman Errors 1 Max              0.130179
Bellman Errors 1 Min              3.71075e-09
Bellman Errors 2 Mean             0.00073241
Bellman Errors 2 Std              0.00759154
Bellman Errors 2 Max              0.0862735
Bellman Errors 2 Min              6.1341e-09
Policy Action Mean                0.0394864
Policy Action Std                 0.984585
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00386882
Test Rewards Std                  0.00398807
Test Rewards Max                  0.0166456
Test Rewards Min                 -0.0114946
Test Returns Mean                 0.693348
Test Returns Std                  0.403059
Test Returns Max                  0.958267
Test Returns Min                 -0.386024
Test Actions Mean                 0.218852
Test Actions Std                  0.950893
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         7
Exploration Rewards Mean          0.00126722
Exploration Rewards Std           0.00466712
Exploration Rewards Max           0.0183175
Exploration Rewards Min          -0.0167168
Exploration Returns Mean          0.334365
Exploration Returns Std           0.638806
Exploration Returns Max           0.895722
Exploration Returns Min          -0.692772
Exploration Actions Mean          0.109627
Exploration Actions Std           0.933445
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.693348
Number of train steps total  200987
Number of env steps total    202000
Number of rollouts total       1494
Train Time (s)                   37.4201
(Previous) Eval Time (s)          2.602e-06
Sample Time (s)                  26.1913
Epoch Time (s)                   63.6114
Total Train Time (s)          24840.5
Epoch                           100
---------------------------  ----------------
2018-05-19 03:09:47.601213 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #100 | Epoch Duration: 1901.8181092739105
2018-05-19 03:09:47.601341 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #100 | Started Training: True
2018-05-19 03:10:48.920497 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #101 | Epoch Duration: 61.319042444229126
2018-05-19 03:10:48.920653 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #101 | Started Training: True
2018-05-19 03:11:46.888596 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #102 | Epoch Duration: 57.9678213596344
2018-05-19 03:11:46.889346 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #102 | Started Training: True
2018-05-19 03:12:46.442685 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #103 | Epoch Duration: 59.55317306518555
2018-05-19 03:12:46.442876 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #103 | Started Training: True
2018-05-19 03:13:46.274301 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #104 | Epoch Duration: 59.831308126449585
2018-05-19 03:13:46.274482 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #104 | Started Training: True
2018-05-19 03:14:46.856792 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #105 | Epoch Duration: 60.582191944122314
2018-05-19 03:14:46.856963 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #105 | Started Training: True
2018-05-19 03:15:47.065602 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #106 | Epoch Duration: 60.20852303504944
2018-05-19 03:15:47.065835 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #106 | Started Training: True
2018-05-19 03:16:47.748818 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #107 | Epoch Duration: 60.6828031539917
2018-05-19 03:16:47.748988 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #107 | Started Training: True
2018-05-19 03:17:47.714866 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #108 | Epoch Duration: 59.96577024459839
2018-05-19 03:17:47.715029 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #108 | Started Training: True
2018-05-19 03:18:46.694746 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #109 | Epoch Duration: 58.97961235046387
2018-05-19 03:18:46.694919 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #109 | Started Training: True
2018-05-19 03:19:58.962194 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #110 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000108033
QF2 Loss                          9.56866e-05
Policy Loss                      -0.222164
Q1 Predictions Mean               0.211882
Q1 Predictions Std                0.172417
Q1 Predictions Max                0.453494
Q1 Predictions Min               -0.516136
Q2 Predictions Mean               0.211826
Q2 Predictions Std                0.172566
Q2 Predictions Max                0.454908
Q2 Predictions Min               -0.497867
Q Targets Mean                    0.208974
Q Targets Std                     0.171512
Q Targets Max                     0.450133
Q Targets Min                    -0.482005
Bellman Errors 1 Mean             0.000108033
Bellman Errors 1 Std              0.000263115
Bellman Errors 1 Max              0.00207864
Bellman Errors 1 Min              1.39222e-09
Bellman Errors 2 Mean             9.56866e-05
Bellman Errors 2 Std              0.000226006
Bellman Errors 2 Max              0.0014327
Bellman Errors 2 Min              2.06088e-08
Policy Action Mean                0.185185
Policy Action Std                 0.967599
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00600906
Test Rewards Std                  0.00433722
Test Rewards Max                  0.0159185
Test Rewards Min                 -0.010347
Test Returns Mean                 0.850832
Test Returns Std                  0.125776
Test Returns Max                  0.939566
Test Returns Min                 -0.183305
Test Actions Mean                 0.168388
Test Actions Std                  0.974379
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        14
Exploration Rewards Mean          0.0040629
Exploration Rewards Std           0.004104
Exploration Rewards Max           0.0161617
Exploration Rewards Min          -0.00315029
Exploration Returns Mean          0.866268
Exploration Returns Std           0.0453363
Exploration Returns Max           0.972423
Exploration Returns Min           0.810261
Exploration Actions Mean          0.101106
Exploration Actions Std           0.932713
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.850832
Number of train steps total  220987
Number of env steps total    222000
Number of rollouts total       1576
Train Time (s)                   33.6029
(Previous) Eval Time (s)          2.189e-06
Sample Time (s)                  25.5898
Epoch Time (s)                   59.1926
Total Train Time (s)          27075.2
Epoch                           110
---------------------------  ----------------
2018-05-19 03:47:02.798283 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #110 | Epoch Duration: 1696.1032588481903
2018-05-19 03:47:02.798404 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #110 | Started Training: True
2018-05-19 03:48:01.454739 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #111 | Epoch Duration: 58.65623593330383
2018-05-19 03:48:01.454910 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #111 | Started Training: True
2018-05-19 03:48:59.318408 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #112 | Epoch Duration: 57.863380670547485
2018-05-19 03:48:59.318568 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #112 | Started Training: True
2018-05-19 03:49:57.883242 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #113 | Epoch Duration: 58.56455993652344
2018-05-19 03:49:57.883464 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #113 | Started Training: True
2018-05-19 03:50:56.787004 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #114 | Epoch Duration: 58.90337347984314
2018-05-19 03:50:56.787170 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #114 | Started Training: True
2018-05-19 03:51:57.013914 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #115 | Epoch Duration: 60.226624488830566
2018-05-19 03:51:57.014083 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #115 | Started Training: True
2018-05-19 03:52:57.520324 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #116 | Epoch Duration: 60.506125926971436
2018-05-19 03:52:57.520568 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #116 | Started Training: True
2018-05-19 03:53:58.218997 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #117 | Epoch Duration: 60.69825720787048
2018-05-19 03:53:58.219221 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #117 | Started Training: True
2018-05-19 03:55:00.819076 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #118 | Epoch Duration: 62.59967374801636
2018-05-19 03:55:00.819306 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #118 | Started Training: True
2018-05-19 03:56:01.445690 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #119 | Epoch Duration: 60.62621545791626
2018-05-19 03:56:01.445859 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #119 | Started Training: True
2018-05-19 03:57:14.619070 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #120 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00013218
QF2 Loss                          0.0001562
Policy Loss                      -0.261601
Q1 Predictions Mean               0.25376
Q1 Predictions Std                0.239955
Q1 Predictions Max                0.581755
Q1 Predictions Min               -0.460473
Q2 Predictions Mean               0.252983
Q2 Predictions Std                0.241839
Q2 Predictions Max                0.581139
Q2 Predictions Min               -0.460499
Q Targets Mean                    0.251038
Q Targets Std                     0.239189
Q Targets Max                     0.57456
Q Targets Min                    -0.477486
Bellman Errors 1 Mean             0.00013218
Bellman Errors 1 Std              0.00032138
Bellman Errors 1 Max              0.00268376
Bellman Errors 1 Min              1.95865e-08
Bellman Errors 2 Mean             0.0001562
Bellman Errors 2 Std              0.000307132
Bellman Errors 2 Max              0.00166452
Bellman Errors 2 Min              6.97576e-09
Policy Action Mean                0.121106
Policy Action Std                 0.981
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00800811
Test Rewards Std                  0.00521702
Test Rewards Max                  0.0186012
Test Rewards Min                 -0.000806846
Test Returns Mean                 0.911833
Test Returns Std                  0.0288115
Test Returns Max                  0.968843
Test Returns Min                  0.821299
Test Actions Mean                 0.105276
Test Actions Std                  0.986404
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        18
Exploration Rewards Mean          0.00736792
Exploration Rewards Std           0.00515662
Exploration Rewards Max           0.0176592
Exploration Rewards Min          -0.00605483
Exploration Returns Mean          0.802694
Exploration Returns Std           0.24221
Exploration Returns Max           0.946544
Exploration Returns Min          -0.182395
Exploration Actions Mean          0.121714
Exploration Actions Std           0.94696
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.911833
Number of train steps total  240987
Number of env steps total    242000
Number of rollouts total       1741
Train Time (s)                   33.4779
(Previous) Eval Time (s)          2.264e-06
Sample Time (s)                  25.8581
Epoch Time (s)                   59.336
Total Train Time (s)          29325.8
Epoch                           120
---------------------------  ----------------
2018-05-19 04:24:33.997381 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #120 | Epoch Duration: 1712.5514175891876
2018-05-19 04:24:33.997505 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #120 | Started Training: True
2018-05-19 04:25:33.484889 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #121 | Epoch Duration: 59.48728084564209
2018-05-19 04:25:33.485050 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #121 | Started Training: True
2018-05-19 04:26:32.666285 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #122 | Epoch Duration: 59.18112659454346
2018-05-19 04:26:32.666454 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #122 | Started Training: True
2018-05-19 04:27:31.850619 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #123 | Epoch Duration: 59.18404841423035
2018-05-19 04:27:31.850787 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #123 | Started Training: True
2018-05-19 04:28:31.139909 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #124 | Epoch Duration: 59.28900980949402
2018-05-19 04:28:31.140069 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #124 | Started Training: True
2018-05-19 04:29:30.667731 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #125 | Epoch Duration: 59.52754497528076
2018-05-19 04:29:30.667964 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #125 | Started Training: True
2018-05-19 04:30:30.237804 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #126 | Epoch Duration: 59.56967806816101
2018-05-19 04:30:30.238017 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #126 | Started Training: True
2018-05-19 04:31:30.920070 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #127 | Epoch Duration: 60.6818950176239
2018-05-19 04:31:30.920244 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #127 | Started Training: True
2018-05-19 04:32:32.150372 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #128 | Epoch Duration: 61.23000431060791
2018-05-19 04:32:32.150606 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #128 | Started Training: True
2018-05-19 04:33:33.849832 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #129 | Epoch Duration: 61.699031591415405
2018-05-19 04:33:33.850059 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #129 | Started Training: True
2018-05-19 04:34:50.291492 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #130 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000374046
QF2 Loss                          0.00031791
Policy Loss                      -0.402873
Q1 Predictions Mean               0.390251
Q1 Predictions Std                0.225698
Q1 Predictions Max                0.62751
Q1 Predictions Min               -0.57398
Q2 Predictions Mean               0.393013
Q2 Predictions Std                0.224028
Q2 Predictions Max                0.623362
Q2 Predictions Min               -0.556206
Q Targets Mean                    0.394465
Q Targets Std                     0.225941
Q Targets Max                     0.638047
Q Targets Min                    -0.56503
Bellman Errors 1 Mean             0.000374046
Bellman Errors 1 Std              0.00206967
Bellman Errors 1 Max              0.0231639
Bellman Errors 1 Min              2.54165e-08
Bellman Errors 2 Mean             0.00031791
Bellman Errors 2 Std              0.00206804
Bellman Errors 2 Max              0.0232811
Bellman Errors 2 Min              2.8141e-11
Policy Action Mean                0.0629574
Policy Action Std                 0.987809
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00729829
Test Rewards Std                  0.00406432
Test Rewards Max                  0.0186169
Test Rewards Min                 -0.00267035
Test Returns Mean                 0.94045
Test Returns Std                  0.0598378
Test Returns Max                  1.08156
Test Returns Min                  0.807344
Test Actions Mean                 0.049608
Test Actions Std                  0.986933
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        13
Exploration Rewards Mean          0.00702901
Exploration Rewards Std           0.00428535
Exploration Rewards Max           0.0184981
Exploration Rewards Min          -0.00103958
Exploration Returns Mean          0.919719
Exploration Returns Std           0.0371059
Exploration Returns Max           0.980602
Exploration Returns Min           0.86159
Exploration Actions Mean          0.0193558
Exploration Actions Std           0.949444
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.94045
Number of train steps total  260987
Number of env steps total    262000
Number of rollouts total       1905
Train Time (s)                   36.0018
(Previous) Eval Time (s)          2.901e-06
Sample Time (s)                  25.7958
Epoch Time (s)                   61.7976
Total Train Time (s)          31792.7
Epoch                           130
---------------------------  ----------------
2018-05-19 05:05:41.385576 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #130 | Epoch Duration: 1927.5353531837463
2018-05-19 05:05:41.385701 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #130 | Started Training: True
2018-05-19 05:06:43.623693 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #131 | Epoch Duration: 62.237881660461426
2018-05-19 05:06:43.623925 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #131 | Started Training: True
2018-05-19 05:07:46.664455 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #132 | Epoch Duration: 63.04037570953369
2018-05-19 05:07:46.664637 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #132 | Started Training: True
2018-05-19 05:08:49.115529 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #133 | Epoch Duration: 62.450775146484375
2018-05-19 05:08:49.115764 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #133 | Started Training: True
2018-05-19 05:09:52.535250 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #134 | Epoch Duration: 63.41931748390198
2018-05-19 05:09:52.535424 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #134 | Started Training: True
2018-05-19 05:10:55.038499 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #135 | Epoch Duration: 62.5029513835907
2018-05-19 05:10:55.038724 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #135 | Started Training: True
2018-05-19 05:11:58.070823 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #136 | Epoch Duration: 63.031943559646606
2018-05-19 05:11:58.070993 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #136 | Started Training: True
2018-05-19 05:13:01.198975 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #137 | Epoch Duration: 63.1278600692749
2018-05-19 05:13:01.199140 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #137 | Started Training: True
2018-05-19 05:14:04.470267 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #138 | Epoch Duration: 63.2710165977478
2018-05-19 05:14:04.470451 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #138 | Started Training: True
2018-05-19 05:15:08.420730 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #139 | Epoch Duration: 63.95015001296997
2018-05-19 05:15:08.420899 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #139 | Started Training: True
2018-05-19 05:16:27.684064 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #140 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.0016479
QF2 Loss                          0.0016653
Policy Loss                      -0.416688
Q1 Predictions Mean               0.412609
Q1 Predictions Std                0.182089
Q1 Predictions Max                0.61315
Q1 Predictions Min               -0.184601
Q2 Predictions Mean               0.412554
Q2 Predictions Std                0.182429
Q2 Predictions Max                0.607998
Q2 Predictions Min               -0.186731
Q Targets Mean                    0.408975
Q Targets Std                     0.190399
Q Targets Max                     0.610278
Q Targets Min                    -0.200105
Bellman Errors 1 Mean             0.0016479
Bellman Errors 1 Std              0.0123275
Bellman Errors 1 Max              0.100342
Bellman Errors 1 Min              5.30712e-10
Bellman Errors 2 Mean             0.0016653
Bellman Errors 2 Std              0.0123426
Bellman Errors 2 Max              0.100415
Bellman Errors 2 Min              7.0832e-09
Policy Action Mean                0.0204457
Policy Action Std                 0.990374
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00599776
Test Rewards Std                  0.00354123
Test Rewards Max                  0.0160067
Test Rewards Min                 -0.00099148
Test Returns Mean                 0.881932
Test Returns Std                  0.0330747
Test Returns Max                  0.969647
Test Returns Min                  0.830084
Test Actions Mean                 0.127808
Test Actions Std                  0.981955
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        13
Exploration Rewards Mean          0.00633496
Exploration Rewards Std           0.00372389
Exploration Rewards Max           0.0163747
Exploration Rewards Min           0.000243794
Exploration Returns Mean          0.91662
Exploration Returns Std           0.0316706
Exploration Returns Max           0.985377
Exploration Returns Min           0.860124
Exploration Actions Mean          0.0251376
Exploration Actions Std           0.954782
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.881932
Number of train steps total  280987
Number of env steps total    282000
Number of rollouts total       2027
Train Time (s)                   38.1316
(Previous) Eval Time (s)          2.15e-06
Sample Time (s)                  25.867
Epoch Time (s)                   63.9986
Total Train Time (s)          34365.8
Epoch                           140
---------------------------  ----------------
2018-05-19 05:48:35.046786 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #140 | Epoch Duration: 2006.6257843971252
2018-05-19 05:48:35.046910 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #140 | Started Training: True
2018-05-19 05:49:37.324652 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #141 | Epoch Duration: 62.27764272689819
2018-05-19 05:49:37.324823 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #141 | Started Training: True
2018-05-19 05:50:41.157608 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #142 | Epoch Duration: 63.83266544342041
2018-05-19 05:50:41.157844 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #142 | Started Training: True
2018-05-19 05:51:45.853666 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #143 | Epoch Duration: 64.6956512928009
2018-05-19 05:51:45.853838 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #143 | Started Training: True
2018-05-19 05:52:48.690951 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #144 | Epoch Duration: 62.83699369430542
2018-05-19 05:52:48.691190 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #144 | Started Training: True
2018-05-19 05:53:52.282984 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #145 | Epoch Duration: 63.59159708023071
2018-05-19 05:53:52.283915 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #145 | Started Training: True
2018-05-19 05:54:54.014503 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #146 | Epoch Duration: 61.73036551475525
2018-05-19 05:54:54.014727 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #146 | Started Training: True
2018-05-19 05:55:55.276729 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #147 | Epoch Duration: 61.261831521987915
2018-05-19 05:55:55.276955 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #147 | Started Training: True
2018-05-19 05:56:55.616379 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #148 | Epoch Duration: 60.33922290802002
2018-05-19 05:56:55.616613 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #148 | Started Training: True
2018-05-19 05:57:55.749733 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #149 | Epoch Duration: 60.132960081100464
2018-05-19 05:57:55.749892 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #149 | Started Training: True
2018-05-19 05:59:12.546963 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #150 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00120372
QF2 Loss                          0.00127068
Policy Loss                      -0.402853
Q1 Predictions Mean               0.399653
Q1 Predictions Std                0.162609
Q1 Predictions Max                0.552953
Q1 Predictions Min               -0.288921
Q2 Predictions Mean               0.39919
Q2 Predictions Std                0.16338
Q2 Predictions Max                0.552934
Q2 Predictions Min               -0.299326
Q Targets Mean                    0.396941
Q Targets Std                     0.163613
Q Targets Max                     0.55473
Q Targets Min                    -0.286642
Bellman Errors 1 Mean             0.00120372
Bellman Errors 1 Std              0.0129136
Bellman Errors 1 Max              0.146677
Bellman Errors 1 Min              3.76907e-11
Bellman Errors 2 Mean             0.00127068
Bellman Errors 2 Std              0.013325
Bellman Errors 2 Max              0.151391
Bellman Errors 2 Min              3.38423e-09
Policy Action Mean                0.0687062
Policy Action Std                 0.989618
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00569683
Test Rewards Std                  0.00354276
Test Rewards Max                  0.0196118
Test Rewards Min                 -0.00242666
Test Returns Mean                 0.745693
Test Returns Std                  0.0436475
Test Returns Max                  0.854717
Test Returns Min                  0.652875
Test Actions Mean                -0.244416
Test Actions Std                  0.965041
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        14
Exploration Rewards Mean          0.0063751
Exploration Rewards Std           0.00446288
Exploration Rewards Max           0.0203493
Exploration Rewards Min          -0.00131763
Exploration Returns Mean          0.840147
Exploration Returns Std           0.115194
Exploration Returns Max           0.993906
Exploration Returns Min           0.599867
Exploration Actions Mean         -0.213496
Exploration Actions Std           0.932648
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.745693
Number of train steps total  300987
Number of env steps total    302000
Number of rollouts total       2140
Train Time (s)                   34.469
(Previous) Eval Time (s)          2.252e-06
Sample Time (s)                  26.3606
Epoch Time (s)                   60.8296
Total Train Time (s)          36797.9
Epoch                           150
---------------------------  ----------------
2018-05-19 06:29:07.632042 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #150 | Epoch Duration: 1871.8815276622772
2018-05-19 06:29:07.632164 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #150 | Started Training: True
2018-05-19 06:30:07.917371 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #151 | Epoch Duration: 60.2851026058197
2018-05-19 06:30:07.917533 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #151 | Started Training: True
2018-05-19 06:31:06.658653 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #152 | Epoch Duration: 58.741002798080444
2018-05-19 06:31:06.658819 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #152 | Started Training: True
2018-05-19 06:32:06.653614 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #153 | Epoch Duration: 59.9946813583374
2018-05-19 06:32:06.653784 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #153 | Started Training: True
2018-05-19 06:33:06.731508 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #154 | Epoch Duration: 60.0775990486145
2018-05-19 06:33:06.731662 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #154 | Started Training: True
2018-05-19 06:34:08.259975 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #155 | Epoch Duration: 61.528194427490234
2018-05-19 06:34:08.260143 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #155 | Started Training: True
2018-05-19 06:35:09.817457 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #156 | Epoch Duration: 61.55720233917236
2018-05-19 06:35:09.817622 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #156 | Started Training: True
2018-05-19 06:36:10.173682 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #157 | Epoch Duration: 60.355947732925415
2018-05-19 06:36:10.173839 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #157 | Started Training: True
2018-05-19 06:37:09.940752 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #158 | Epoch Duration: 59.7668035030365
2018-05-19 06:37:09.940922 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #158 | Started Training: True
2018-05-19 06:38:09.792797 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #159 | Epoch Duration: 59.85176944732666
2018-05-19 06:38:09.792976 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #159 | Started Training: True
2018-05-19 06:39:26.988315 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #160 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00021549
QF2 Loss                          8.90046e-05
Policy Loss                      -0.379424
Q1 Predictions Mean               0.367875
Q1 Predictions Std                0.200362
Q1 Predictions Max                0.498294
Q1 Predictions Min               -0.551478
Q2 Predictions Mean               0.368172
Q2 Predictions Std                0.197852
Q2 Predictions Max                0.494352
Q2 Predictions Min               -0.496724
Q Targets Mean                    0.370595
Q Targets Std                     0.196924
Q Targets Max                     0.490865
Q Targets Min                    -0.503698
Bellman Errors 1 Mean             0.00021549
Bellman Errors 1 Std              0.00155378
Bellman Errors 1 Max              0.0175189
Bellman Errors 1 Min              1.3989e-09
Bellman Errors 2 Mean             8.90046e-05
Bellman Errors 2 Std              0.00041663
Bellman Errors 2 Max              0.00450126
Bellman Errors 2 Min              5.78444e-09
Policy Action Mean               -0.255051
Policy Action Std                 0.963891
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00805252
Test Rewards Std                  0.00547404
Test Rewards Max                  0.0206507
Test Rewards Min                 -0.00197048
Test Returns Mean                 0.957871
Test Returns Std                  0.0324412
Test Returns Max                  1.03395
Test Returns Min                  0.849315
Test Actions Mean                 0.0217408
Test Actions Std                  0.994485
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        16
Exploration Rewards Mean          0.00781435
Exploration Rewards Std           0.00537974
Exploration Rewards Max           0.020411
Exploration Rewards Min           9.66904e-05
Exploration Returns Mean          0.939676
Exploration Returns Std           0.0394096
Exploration Returns Max           1.02375
Exploration Returns Min           0.864115
Exploration Actions Mean          0.0991012
Exploration Actions Std           0.953269
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.957871
Number of train steps total  320987
Number of env steps total    322000
Number of rollouts total       2297
Train Time (s)                   34.0937
(Previous) Eval Time (s)          2.254e-06
Sample Time (s)                  26.4446
Epoch Time (s)                   60.5382
Total Train Time (s)          39118.2
Epoch                           160
---------------------------  ----------------
2018-05-19 07:07:48.503670 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #160 | Epoch Duration: 1778.7105894088745
2018-05-19 07:07:48.503796 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #160 | Started Training: True
2018-05-19 07:08:49.972785 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #161 | Epoch Duration: 61.46888017654419
2018-05-19 07:08:49.973024 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #161 | Started Training: True
2018-05-19 07:09:51.163815 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #162 | Epoch Duration: 61.190624952316284
2018-05-19 07:09:51.163978 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #162 | Started Training: True
2018-05-19 07:10:52.561396 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #163 | Epoch Duration: 61.397308111190796
2018-05-19 07:10:52.561568 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #163 | Started Training: True
2018-05-19 07:11:54.436704 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #164 | Epoch Duration: 61.875014543533325
2018-05-19 07:11:54.436886 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #164 | Started Training: True
2018-05-19 07:12:56.594755 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #165 | Epoch Duration: 62.15775465965271
2018-05-19 07:12:56.594925 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #165 | Started Training: True
2018-05-19 07:13:58.330713 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #166 | Epoch Duration: 61.735660552978516
2018-05-19 07:13:58.330958 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #166 | Started Training: True
2018-05-19 07:15:02.135720 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #167 | Epoch Duration: 63.8045654296875
2018-05-19 07:15:02.135897 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #167 | Started Training: True
2018-05-19 07:16:05.166261 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #168 | Epoch Duration: 63.030250549316406
2018-05-19 07:16:05.166462 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #168 | Started Training: True
2018-05-19 07:17:07.988503 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #169 | Epoch Duration: 62.82192516326904
2018-05-19 07:17:07.988673 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #169 | Started Training: True
2018-05-19 07:18:29.289969 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #170 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000163253
QF2 Loss                          0.000147216
Policy Loss                      -0.419061
Q1 Predictions Mean               0.40846
Q1 Predictions Std                0.269049
Q1 Predictions Max                0.725098
Q1 Predictions Min               -0.432306
Q2 Predictions Mean               0.406736
Q2 Predictions Std                0.268164
Q2 Predictions Max                0.72014
Q2 Predictions Min               -0.46033
Q Targets Mean                    0.406786
Q Targets Std                     0.268069
Q Targets Max                     0.731023
Q Targets Min                    -0.471761
Bellman Errors 1 Mean             0.000163253
Bellman Errors 1 Std              0.000502456
Bellman Errors 1 Max              0.0038244
Bellman Errors 1 Min              1.13832e-10
Bellman Errors 2 Mean             0.000147216
Bellman Errors 2 Std              0.000450081
Bellman Errors 2 Max              0.00394053
Bellman Errors 2 Min              3.30925e-08
Policy Action Mean                0.0152674
Policy Action Std                 0.995079
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00652831
Test Rewards Std                  0.00345018
Test Rewards Max                  0.0180875
Test Rewards Min                 -0.00152802
Test Returns Mean                 0.918135
Test Returns Std                  0.0670333
Test Returns Max                  1.09155
Test Returns Min                  0.700076
Test Actions Mean                -0.0846671
Test Actions Std                  0.988198
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         9
Exploration Rewards Mean          0.0056406
Exploration Rewards Std           0.00340849
Exploration Rewards Max           0.0149076
Exploration Rewards Min           0.000413869
Exploration Returns Mean          0.872412
Exploration Returns Std           0.0575666
Exploration Returns Max           1.02151
Exploration Returns Min           0.808057
Exploration Actions Mean         -0.118135
Exploration Actions Std           0.948237
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.918135
Number of train steps total  340987
Number of env steps total    342000
Number of rollouts total       2435
Train Time (s)                   36.9116
(Previous) Eval Time (s)          1.998e-06
Sample Time (s)                  27.171
Epoch Time (s)                   64.0827
Total Train Time (s)          41670.4
Epoch                           170
---------------------------  ----------------
2018-05-19 07:50:21.285498 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #170 | Epoch Duration: 1993.2967216968536
2018-05-19 07:50:21.285623 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #170 | Started Training: True
2018-05-19 07:51:24.509346 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #171 | Epoch Duration: 63.223605155944824
2018-05-19 07:51:24.509527 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #171 | Started Training: True
2018-05-19 07:52:28.339935 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #172 | Epoch Duration: 63.83027982711792
2018-05-19 07:52:28.340184 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #172 | Started Training: True
2018-05-19 07:53:31.313558 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #173 | Epoch Duration: 62.973159313201904
2018-05-19 07:53:31.313739 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #173 | Started Training: True
2018-05-19 07:54:35.382770 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #174 | Epoch Duration: 64.06890034675598
2018-05-19 07:54:35.383018 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #174 | Started Training: True
2018-05-19 07:55:38.335123 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #175 | Epoch Duration: 62.951932430267334
2018-05-19 07:55:38.335288 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #175 | Started Training: True
2018-05-19 07:56:41.113532 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #176 | Epoch Duration: 62.778128147125244
2018-05-19 07:56:41.113779 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #176 | Started Training: True
2018-05-19 07:57:44.221989 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #177 | Epoch Duration: 63.108031034469604
2018-05-19 07:57:44.222171 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #177 | Started Training: True
2018-05-19 07:58:47.378130 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #178 | Epoch Duration: 63.15584063529968
2018-05-19 07:58:47.378362 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #178 | Started Training: True
2018-05-19 07:59:51.150745 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #179 | Epoch Duration: 63.77220582962036
2018-05-19 07:59:51.150918 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #179 | Started Training: True
2018-05-19 08:01:12.493270 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #180 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.0011954
QF2 Loss                          0.00117376
Policy Loss                      -0.451041
Q1 Predictions Mean               0.446292
Q1 Predictions Std                0.205573
Q1 Predictions Max                0.710298
Q1 Predictions Min               -0.841498
Q2 Predictions Mean               0.447605
Q2 Predictions Std                0.202603
Q2 Predictions Max                0.709831
Q2 Predictions Min               -0.771466
Q Targets Mean                    0.446769
Q Targets Std                     0.204365
Q Targets Max                     0.704275
Q Targets Min                    -0.754445
Bellman Errors 1 Mean             0.0011954
Bellman Errors 1 Std              0.0114922
Bellman Errors 1 Max              0.130437
Bellman Errors 1 Min              9.88445e-09
Bellman Errors 2 Mean             0.00117376
Bellman Errors 2 Std              0.0115207
Bellman Errors 2 Max              0.130713
Bellman Errors 2 Min              1.3481e-09
Policy Action Mean               -0.0757239
Policy Action Std                 0.991538
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00066895
Test Rewards Std                  0.00276623
Test Rewards Max                  0.0170938
Test Rewards Min                 -0.0173254
Test Returns Mean                 0.298296
Test Returns Std                  0.497935
Test Returns Max                  0.951305
Test Returns Min                 -0.728299
Test Actions Mean                 0.223102
Test Actions Std                  0.961752
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        10
Exploration Rewards Mean          0.0045203
Exploration Rewards Std           0.003512
Exploration Rewards Max           0.0181373
Exploration Rewards Min          -8.38709e-05
Exploration Returns Mean          0.875583
Exploration Returns Std           0.0433906
Exploration Returns Max           0.943417
Exploration Returns Min           0.827953
Exploration Actions Mean          0.050716
Exploration Actions Std           0.952496
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.298296
Number of train steps total  360987
Number of env steps total    362000
Number of rollouts total       2551
Train Time (s)                   36.785
(Previous) Eval Time (s)          2.024e-06
Sample Time (s)                  26.3102
Epoch Time (s)                   63.0952
Total Train Time (s)          44079.8
Epoch                           180
---------------------------  ----------------
2018-05-19 08:30:31.136594 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #180 | Epoch Duration: 1839.98557138443
2018-05-19 08:30:31.136717 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #180 | Started Training: True
2018-05-19 08:31:32.266595 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #181 | Epoch Duration: 61.12977623939514
2018-05-19 08:31:32.266772 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #181 | Started Training: True
2018-05-19 08:32:33.946992 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #182 | Epoch Duration: 61.680097341537476
2018-05-19 08:32:33.947160 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #182 | Started Training: True
2018-05-19 08:33:34.181796 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #183 | Epoch Duration: 60.23451042175293
2018-05-19 08:33:34.181962 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #183 | Started Training: True
2018-05-19 08:34:36.904243 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #184 | Epoch Duration: 62.72215557098389
2018-05-19 08:34:36.904430 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #184 | Started Training: True
2018-05-19 08:35:35.617866 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #185 | Epoch Duration: 58.71332144737244
2018-05-19 08:35:35.618032 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #185 | Started Training: True
2018-05-19 08:36:34.047834 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #186 | Epoch Duration: 58.42967748641968
2018-05-19 08:36:34.048066 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #186 | Started Training: True
2018-05-19 08:37:36.589066 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #187 | Epoch Duration: 62.540826082229614
2018-05-19 08:37:36.589234 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #187 | Started Training: True
2018-05-19 08:38:38.614715 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #188 | Epoch Duration: 62.02537298202515
2018-05-19 08:38:38.614902 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #188 | Started Training: True
2018-05-19 08:39:39.972539 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #189 | Epoch Duration: 61.35751938819885
2018-05-19 08:39:39.972703 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #189 | Started Training: True
2018-05-19 08:41:02.295730 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #190 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000210086
QF2 Loss                          0.000132417
Policy Loss                      -0.439187
Q1 Predictions Mean               0.433048
Q1 Predictions Std                0.169827
Q1 Predictions Max                0.630263
Q1 Predictions Min               -0.575577
Q2 Predictions Mean               0.434593
Q2 Predictions Std                0.167811
Q2 Predictions Max                0.631438
Q2 Predictions Min               -0.551144
Q Targets Mean                    0.439058
Q Targets Std                     0.161261
Q Targets Max                     0.622806
Q Targets Min                    -0.504594
Bellman Errors 1 Mean             0.000210086
Bellman Errors 1 Std              0.000850115
Bellman Errors 1 Max              0.00655528
Bellman Errors 1 Min              3.39811e-09
Bellman Errors 2 Mean             0.000132417
Bellman Errors 2 Std              0.000358808
Bellman Errors 2 Max              0.00253777
Bellman Errors 2 Min              2.70453e-09
Policy Action Mean                0.127682
Policy Action Std                 0.987548
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00125024
Test Rewards Std                  0.00381701
Test Rewards Max                  0.0183796
Test Rewards Min                 -0.0206042
Test Returns Mean                 0.512069
Test Returns Std                  0.608236
Test Returns Max                  1.04635
Test Returns Min                 -0.757278
Test Actions Mean                 0.043745
Test Actions Std                  0.990416
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         5
Exploration Rewards Mean          0.00200956
Exploration Rewards Std           0.00403429
Exploration Rewards Max           0.015851
Exploration Rewards Min          -0.0119624
Exploration Returns Mean          0.671596
Exploration Returns Std           0.538346
Exploration Returns Max           0.982678
Exploration Returns Min          -0.402184
Exploration Actions Mean          0.0904528
Exploration Actions Std           0.944192
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.512069
Number of train steps total  380987
Number of env steps total    382000
Number of rollouts total       2586
Train Time (s)                   36.6362
(Previous) Eval Time (s)          2.309e-06
Sample Time (s)                  26.531
Epoch Time (s)                   63.1672
Total Train Time (s)          46619.1
Epoch                           190
---------------------------  ----------------
2018-05-19 09:12:50.972263 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #190 | Epoch Duration: 1990.9994575977325
2018-05-19 09:12:50.972403 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #190 | Started Training: True
2018-05-19 09:13:52.347042 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #191 | Epoch Duration: 61.37453269958496
2018-05-19 09:13:52.347217 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #191 | Started Training: True
2018-05-19 09:14:55.371366 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #192 | Epoch Duration: 63.02402400970459
2018-05-19 09:14:55.371536 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #192 | Started Training: True
2018-05-19 09:16:00.258866 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #193 | Epoch Duration: 64.88721227645874
2018-05-19 09:16:00.259104 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #193 | Started Training: True
2018-05-19 09:17:04.658395 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #194 | Epoch Duration: 64.3991072177887
2018-05-19 09:17:04.658560 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #194 | Started Training: True
2018-05-19 09:18:08.060886 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #195 | Epoch Duration: 63.40220332145691
2018-05-19 09:18:08.061064 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #195 | Started Training: True
2018-05-19 09:19:10.422473 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #196 | Epoch Duration: 62.3612847328186
2018-05-19 09:19:10.422707 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #196 | Started Training: True
2018-05-19 09:20:13.906746 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #197 | Epoch Duration: 63.48387122154236
2018-05-19 09:20:13.906930 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #197 | Started Training: True
2018-05-19 09:21:17.727169 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #198 | Epoch Duration: 63.82010889053345
2018-05-19 09:21:17.727403 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #198 | Started Training: True
2018-05-19 09:22:22.117731 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #199 | Epoch Duration: 64.3901674747467
2018-05-19 09:22:22.117895 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #199 | Started Training: True
2018-05-19 09:23:45.915349 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #200 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          6.41408e-05
QF2 Loss                          9.15943e-05
Policy Loss                      -0.411927
Q1 Predictions Mean               0.410366
Q1 Predictions Std                0.200217
Q1 Predictions Max                0.508434
Q1 Predictions Min               -0.943565
Q2 Predictions Mean               0.411472
Q2 Predictions Std                0.196766
Q2 Predictions Max                0.507107
Q2 Predictions Min               -0.890715
Q Targets Mean                    0.412701
Q Targets Std                     0.201896
Q Targets Max                     0.511189
Q Targets Min                    -0.937524
Bellman Errors 1 Mean             6.41408e-05
Bellman Errors 1 Std              0.000299763
Bellman Errors 1 Max              0.00331952
Bellman Errors 1 Min              1.10675e-10
Bellman Errors 2 Mean             9.15943e-05
Bellman Errors 2 Std              0.000352382
Bellman Errors 2 Max              0.0027772
Bellman Errors 2 Min              4.81123e-10
Policy Action Mean                0.211876
Policy Action Std                 0.973633
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00532472
Test Rewards Std                  0.00416883
Test Rewards Max                  0.0144078
Test Rewards Min                 -0.0123987
Test Returns Mean                 0.715216
Test Returns Std                  0.227329
Test Returns Max                  0.835652
Test Returns Min                 -0.29117
Test Actions Mean                -0.00637638
Test Actions Std                  0.995668
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        17
Exploration Rewards Mean          0.00505537
Exploration Rewards Std           0.00474364
Exploration Rewards Max           0.0177442
Exploration Rewards Min          -0.0098546
Exploration Returns Mean          0.720539
Exploration Returns Std           0.345406
Exploration Returns Max           0.908911
Exploration Returns Min          -0.281823
Exploration Actions Mean          0.0222549
Exploration Actions Std           0.957969
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.715216
Number of train steps total  400987
Number of env steps total    402000
Number of rollouts total       2699
Train Time (s)                   37.1703
(Previous) Eval Time (s)          2.01599e-06
Sample Time (s)                  27.2726
Epoch Time (s)                   64.4429
Total Train Time (s)          49268.9
Epoch                           200
---------------------------  ----------------
2018-05-19 09:57:01.398984 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #200 | Epoch Duration: 2079.2809805870056
2018-05-19 09:57:01.399110 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #200 | Started Training: True
2018-05-19 09:58:05.211038 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #201 | Epoch Duration: 63.811805963516235
2018-05-19 09:58:05.211285 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #201 | Started Training: True
2018-05-19 09:59:11.597551 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #202 | Epoch Duration: 66.38608884811401
2018-05-19 09:59:11.597791 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #202 | Started Training: True
2018-05-19 10:00:15.818548 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #203 | Epoch Duration: 64.22059893608093
2018-05-19 10:00:15.818731 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #203 | Started Training: True
2018-05-19 10:01:20.790386 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #204 | Epoch Duration: 64.97153329849243
2018-05-19 10:01:20.790619 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #204 | Started Training: True
2018-05-19 10:02:24.106632 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #205 | Epoch Duration: 63.315836906433105
2018-05-19 10:02:24.106812 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #205 | Started Training: True
2018-05-19 10:03:27.356361 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #206 | Epoch Duration: 63.24939823150635
2018-05-19 10:03:27.356596 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #206 | Started Training: True
2018-05-19 10:04:30.375233 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #207 | Epoch Duration: 63.0184690952301
2018-05-19 10:04:30.375403 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #207 | Started Training: True
2018-05-19 10:05:32.456602 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #208 | Epoch Duration: 62.08108115196228
2018-05-19 10:05:32.456764 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #208 | Started Training: True
2018-05-19 10:06:35.069525 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #209 | Epoch Duration: 62.61265182495117
2018-05-19 10:06:35.069697 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #209 | Started Training: True
2018-05-19 10:07:58.493399 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #210 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00180264
QF2 Loss                          0.00175263
Policy Loss                      -0.387122
Q1 Predictions Mean               0.382115
Q1 Predictions Std                0.189392
Q1 Predictions Max                0.518834
Q1 Predictions Min               -0.485588
Q2 Predictions Mean               0.384621
Q2 Predictions Std                0.186233
Q2 Predictions Max                0.520335
Q2 Predictions Min               -0.494006
Q Targets Mean                    0.381004
Q Targets Std                     0.195667
Q Targets Max                     0.526596
Q Targets Min                    -0.469861
Bellman Errors 1 Mean             0.00180264
Bellman Errors 1 Std              0.0174162
Bellman Errors 1 Max              0.197829
Bellman Errors 1 Min              1.20029e-11
Bellman Errors 2 Mean             0.00175263
Bellman Errors 2 Std              0.0174146
Bellman Errors 2 Max              0.19784
Bellman Errors 2 Min              6.20433e-09
Policy Action Mean               -0.0060912
Policy Action Std                 0.995224
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00588789
Test Rewards Std                  0.0039651
Test Rewards Max                  0.0166854
Test Rewards Min                 -0.00245221
Test Returns Mean                 0.803219
Test Returns Std                  0.0620148
Test Returns Max                  0.971674
Test Returns Min                  0.59568
Test Actions Mean                 0.0361971
Test Actions Std                  0.995197
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        14
Exploration Rewards Mean          0.00541875
Exploration Rewards Std           0.00414851
Exploration Rewards Max           0.0159578
Exploration Rewards Min          -0.0029163
Exploration Returns Mean          0.77643
Exploration Returns Std           0.069325
Exploration Returns Max           0.840078
Exploration Returns Min           0.570848
Exploration Actions Mean          0.028647
Exploration Actions Std           0.958137
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.803219
Number of train steps total  420987
Number of env steps total    422000
Number of rollouts total       2848
Train Time (s)                   36.9656
(Previous) Eval Time (s)          2.145e-06
Sample Time (s)                  26.6501
Epoch Time (s)                   63.6157
Total Train Time (s)          51747.6
Epoch                           210
---------------------------  ----------------
2018-05-19 10:38:20.628544 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #210 | Epoch Duration: 1905.5587413311005
2018-05-19 10:38:20.628668 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #210 | Started Training: True
2018-05-19 10:39:23.794210 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #211 | Epoch Duration: 63.16542601585388
2018-05-19 10:39:23.794375 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #211 | Started Training: True
2018-05-19 10:40:29.205568 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #212 | Epoch Duration: 65.41108512878418
2018-05-19 10:40:29.205733 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #212 | Started Training: True
2018-05-19 10:41:34.586044 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #213 | Epoch Duration: 65.38019824028015
2018-05-19 10:41:34.586209 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #213 | Started Training: True
2018-05-19 10:42:37.644141 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #214 | Epoch Duration: 63.05781435966492
2018-05-19 10:42:37.644947 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #214 | Started Training: True
2018-05-19 10:43:41.232887 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #215 | Epoch Duration: 63.58771586418152
2018-05-19 10:43:41.233697 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #215 | Started Training: True
2018-05-19 10:44:45.630930 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #216 | Epoch Duration: 64.39703345298767
2018-05-19 10:44:45.631718 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #216 | Started Training: True
2018-05-19 10:45:50.531405 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #217 | Epoch Duration: 64.89946269989014
2018-05-19 10:45:50.531589 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #217 | Started Training: True
2018-05-19 10:46:52.675966 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #218 | Epoch Duration: 62.14425802230835
2018-05-19 10:46:52.676194 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #218 | Started Training: True
2018-05-19 10:47:57.549993 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #219 | Epoch Duration: 64.87360978126526
2018-05-19 10:47:57.550224 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #219 | Started Training: True
2018-05-19 10:49:21.758421 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #220 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000303367
QF2 Loss                          0.000345046
Policy Loss                      -0.388903
Q1 Predictions Mean               0.384779
Q1 Predictions Std                0.227619
Q1 Predictions Max                0.521298
Q1 Predictions Min               -0.58954
Q2 Predictions Mean               0.383951
Q2 Predictions Std                0.228683
Q2 Predictions Max                0.51526
Q2 Predictions Min               -0.572894
Q Targets Mean                    0.385898
Q Targets Std                     0.231412
Q Targets Max                     0.516665
Q Targets Min                    -0.594686
Bellman Errors 1 Mean             0.000303368
Bellman Errors 1 Std              0.00251028
Bellman Errors 1 Max              0.0282879
Bellman Errors 1 Min              8.81087e-10
Bellman Errors 2 Mean             0.000345046
Bellman Errors 2 Std              0.002904
Bellman Errors 2 Max              0.0328472
Bellman Errors 2 Min              1.2291e-10
Policy Action Mean                0.0252222
Policy Action Std                 0.995398
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00542913
Test Rewards Std                  0.00255957
Test Rewards Max                  0.0142372
Test Rewards Min                 -0.000159662
Test Returns Mean                 0.573202
Test Returns Std                  0.017948
Test Returns Max                  0.617536
Test Returns Min                  0.546733
Test Actions Mean                -0.222516
Test Actions Std                  0.9731
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        16
Exploration Rewards Mean          0.00488218
Exploration Rewards Std           0.00314954
Exploration Rewards Max           0.0140536
Exploration Rewards Min          -0.00558914
Exploration Returns Mean          0.537345
Exploration Returns Std           0.17429
Exploration Returns Max           0.681165
Exploration Returns Min          -0.0978361
Exploration Actions Mean         -0.231696
Exploration Actions Std           0.930691
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.573202
Number of train steps total  440987
Number of env steps total    442000
Number of rollouts total       2996
Train Time (s)                   36.458
(Previous) Eval Time (s)          3.20401e-06
Sample Time (s)                  26.7905
Epoch Time (s)                   63.2485
Total Train Time (s)          54089.9
Epoch                           220
---------------------------  ----------------
2018-05-19 11:17:23.420563 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #220 | Epoch Duration: 1765.8701763153076
2018-05-19 11:17:23.420686 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #220 | Started Training: True
2018-05-19 11:18:24.833550 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #221 | Epoch Duration: 61.412752866744995
2018-05-19 11:18:24.833715 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #221 | Started Training: True
2018-05-19 11:19:27.049967 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #222 | Epoch Duration: 62.21613073348999
2018-05-19 11:19:27.050186 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #222 | Started Training: True
2018-05-19 11:20:26.028820 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #223 | Epoch Duration: 58.97847366333008
2018-05-19 11:20:26.028999 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #223 | Started Training: True
2018-05-19 11:21:24.987684 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #224 | Epoch Duration: 58.95856475830078
2018-05-19 11:21:24.987853 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #224 | Started Training: True
2018-05-19 11:22:23.774691 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #225 | Epoch Duration: 58.78672742843628
2018-05-19 11:22:23.774849 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #225 | Started Training: True
2018-05-19 11:23:25.367410 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #226 | Epoch Duration: 61.59245419502258
2018-05-19 11:23:25.367592 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #226 | Started Training: True
2018-05-19 11:24:25.577896 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #227 | Epoch Duration: 60.210182905197144
2018-05-19 11:24:25.578054 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #227 | Started Training: True
2018-05-19 11:25:25.980898 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #228 | Epoch Duration: 60.40272760391235
2018-05-19 11:25:25.981079 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #228 | Started Training: True
2018-05-19 11:26:28.930805 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #229 | Epoch Duration: 62.9496054649353
2018-05-19 11:26:28.930976 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #229 | Started Training: True
2018-05-19 11:27:53.670885 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #230 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000162929
QF2 Loss                          0.00015562
Policy Loss                      -0.392637
Q1 Predictions Mean               0.388357
Q1 Predictions Std                0.201396
Q1 Predictions Max                0.544749
Q1 Predictions Min               -0.481512
Q2 Predictions Mean               0.388308
Q2 Predictions Std                0.200224
Q2 Predictions Max                0.543807
Q2 Predictions Min               -0.481403
Q Targets Mean                    0.388618
Q Targets Std                     0.20445
Q Targets Max                     0.549026
Q Targets Min                    -0.49721
Bellman Errors 1 Mean             0.000162929
Bellman Errors 1 Std              0.000471653
Bellman Errors 1 Max              0.00297234
Bellman Errors 1 Min              1.80656e-10
Bellman Errors 2 Mean             0.00015562
Bellman Errors 2 Std              0.000769959
Bellman Errors 2 Max              0.00842154
Bellman Errors 2 Min              1.01229e-08
Policy Action Mean               -0.0882327
Policy Action Std                 0.993464
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00520442
Test Rewards Std                  0.00447518
Test Rewards Max                  0.0191778
Test Rewards Min                 -0.0067281
Test Returns Mean                 0.734337
Test Returns Std                  0.0941954
Test Returns Max                  1.01716
Test Returns Min                  0.470878
Test Actions Mean                 0.0473909
Test Actions Std                  0.997249
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        11
Exploration Rewards Mean          0.00486088
Exploration Rewards Std           0.00433263
Exploration Rewards Max           0.0183963
Exploration Rewards Min          -0.00264747
Exploration Returns Mean          0.697315
Exploration Returns Std           0.0906512
Exploration Returns Max           0.81167
Exploration Returns Min           0.539811
Exploration Actions Mean          0.0161887
Exploration Actions Std           0.960128
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.734337
Number of train steps total  460987
Number of env steps total    462000
Number of rollouts total       3163
Train Time (s)                   36.7332
(Previous) Eval Time (s)          2.07699e-06
Sample Time (s)                  26.7896
Epoch Time (s)                   63.5228
Total Train Time (s)          56586.3
Epoch                           230
---------------------------  ----------------
2018-05-19 11:59:00.336129 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #230 | Epoch Duration: 1951.4050476551056
2018-05-19 11:59:00.336258 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #230 | Started Training: True
2018-05-19 12:00:05.166854 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #231 | Epoch Duration: 64.83046364784241
2018-05-19 12:00:05.167100 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #231 | Started Training: True
2018-05-19 12:01:07.917310 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #232 | Epoch Duration: 62.75003695487976
2018-05-19 12:01:07.917485 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #232 | Started Training: True
2018-05-19 12:02:09.379315 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #233 | Epoch Duration: 61.46170163154602
2018-05-19 12:02:09.379481 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #233 | Started Training: True
2018-05-19 12:03:10.422491 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #234 | Epoch Duration: 61.042882680892944
2018-05-19 12:03:10.422647 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #234 | Started Training: True
2018-05-19 12:04:11.237345 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #235 | Epoch Duration: 60.81458282470703
2018-05-19 12:04:11.237574 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #235 | Started Training: True
2018-05-19 12:05:12.576977 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #236 | Epoch Duration: 61.339234352111816
2018-05-19 12:05:12.577204 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #236 | Started Training: True
2018-05-19 12:06:13.842635 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #237 | Epoch Duration: 61.26526951789856
2018-05-19 12:06:13.842797 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #237 | Started Training: True
2018-05-19 12:07:15.972501 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #238 | Epoch Duration: 62.129597425460815
2018-05-19 12:07:15.972670 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #238 | Started Training: True
2018-05-19 12:08:17.816638 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #239 | Epoch Duration: 61.84385657310486
2018-05-19 12:08:17.816812 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #239 | Started Training: True
2018-05-19 12:09:41.155291 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #240 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00035929
QF2 Loss                          0.000365347
Policy Loss                      -0.364101
Q1 Predictions Mean               0.358234
Q1 Predictions Std                0.22361
Q1 Predictions Max                0.572061
Q1 Predictions Min               -0.5003
Q2 Predictions Mean               0.358109
Q2 Predictions Std                0.225177
Q2 Predictions Max                0.578129
Q2 Predictions Min               -0.504065
Q Targets Mean                    0.355655
Q Targets Std                     0.230289
Q Targets Max                     0.573398
Q Targets Min                    -0.567285
Bellman Errors 1 Mean             0.00035929
Bellman Errors 1 Std              0.00195594
Bellman Errors 1 Max              0.0157971
Bellman Errors 1 Min              9.49601e-10
Bellman Errors 2 Mean             0.000365347
Bellman Errors 2 Std              0.00194015
Bellman Errors 2 Max              0.0157181
Bellman Errors 2 Min              5.56e-09
Policy Action Mean                0.0169403
Policy Action Std                 0.998842
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00591205
Test Rewards Std                  0.00351239
Test Rewards Max                  0.0161949
Test Rewards Min                 -0.0079709
Test Returns Mean                 0.799565
Test Returns Std                  0.112388
Test Returns Max                  0.90103
Test Returns Min                 -0.115686
Test Actions Mean                 0.0373786
Test Actions Std                  0.997387
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        15
Exploration Rewards Mean          0.0065079
Exploration Rewards Std           0.00347412
Exploration Rewards Max           0.0160645
Exploration Rewards Min           0.000539623
Exploration Returns Mean          0.829974
Exploration Returns Std           0.0379876
Exploration Returns Max           0.894765
Exploration Returns Min           0.728443
Exploration Actions Mean          0.0708742
Exploration Actions Std           0.958125
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.799565
Number of train steps total  480987
Number of env steps total    482000
Number of rollouts total       3310
Train Time (s)                   35.5296
(Previous) Eval Time (s)          2.11199e-06
Sample Time (s)                  25.8553
Epoch Time (s)                   61.3849
Total Train Time (s)          58965.1
Epoch                           240
---------------------------  ----------------
2018-05-19 12:38:39.734465 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #240 | Epoch Duration: 1821.917545080185
2018-05-19 12:38:39.734600 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #240 | Started Training: True
2018-05-19 12:39:41.888534 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #241 | Epoch Duration: 62.15380382537842
2018-05-19 12:39:41.888764 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #241 | Started Training: True
2018-05-19 12:40:43.032516 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #242 | Epoch Duration: 61.14359140396118
2018-05-19 12:40:43.032712 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #242 | Started Training: True
2018-05-19 12:41:45.942903 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #243 | Epoch Duration: 62.910072326660156
2018-05-19 12:41:45.943608 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #243 | Started Training: True
2018-05-19 12:42:48.702882 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #244 | Epoch Duration: 62.75914645195007
2018-05-19 12:42:48.703897 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #244 | Started Training: True
2018-05-19 12:43:52.114775 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #245 | Epoch Duration: 63.41072225570679
2018-05-19 12:43:52.114989 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #245 | Started Training: True
2018-05-19 12:44:55.132783 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #246 | Epoch Duration: 63.0176362991333
2018-05-19 12:44:55.132959 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #246 | Started Training: True
2018-05-19 12:45:57.786149 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #247 | Epoch Duration: 62.653077840805054
2018-05-19 12:45:57.786334 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #247 | Started Training: True
2018-05-19 12:47:01.116663 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #248 | Epoch Duration: 63.3301956653595
2018-05-19 12:47:01.116832 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #248 | Started Training: True
2018-05-19 12:48:04.506771 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #249 | Epoch Duration: 63.38981509208679
2018-05-19 12:48:04.506996 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #249 | Started Training: True
2018-05-19 12:49:30.157560 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #250 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000226125
QF2 Loss                          0.000145093
Policy Loss                      -0.366884
Q1 Predictions Mean               0.362069
Q1 Predictions Std                0.218246
Q1 Predictions Max                0.587965
Q1 Predictions Min               -0.618886
Q2 Predictions Mean               0.362875
Q2 Predictions Std                0.215557
Q2 Predictions Max                0.587461
Q2 Predictions Min               -0.537861
Q Targets Mean                    0.365528
Q Targets Std                     0.213586
Q Targets Max                     0.589289
Q Targets Min                    -0.538664
Bellman Errors 1 Mean             0.000226125
Bellman Errors 1 Std              0.00108312
Bellman Errors 1 Max              0.00990667
Bellman Errors 1 Min              5.25324e-09
Bellman Errors 2 Mean             0.000145093
Bellman Errors 2 Std              0.000546645
Bellman Errors 2 Max              0.00525182
Bellman Errors 2 Min              1.50102e-09
Policy Action Mean                0.029121
Policy Action Std                 0.998192
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00567904
Test Rewards Std                  0.0032055
Test Rewards Max                  0.0161184
Test Rewards Min                  0.000356101
Test Returns Mean                 0.849143
Test Returns Std                  0.0558551
Test Returns Max                  1.11064
Test Returns Min                  0.773635
Test Actions Mean                -0.140977
Test Actions Std                  0.987032
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        13
Exploration Rewards Mean          0.00576958
Exploration Rewards Std           0.00357506
Exploration Rewards Max           0.0161749
Exploration Rewards Min          -0.00150846
Exploration Returns Mean          0.943992
Exploration Returns Std           0.0587427
Exploration Returns Max           1.03523
Exploration Returns Min           0.845254
Exploration Actions Mean         -0.147488
Exploration Actions Std           0.946959
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.849143
Number of train steps total  500987
Number of env steps total    502000
Number of rollouts total       3434
Train Time (s)                   36.7404
(Previous) Eval Time (s)          2.933e-06
Sample Time (s)                  26.222
Epoch Time (s)                   62.9624
Total Train Time (s)          61400.4
Epoch                           250
---------------------------  ----------------
2018-05-19 13:19:15.608205 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #250 | Epoch Duration: 1871.1010394096375
2018-05-19 13:19:15.608326 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #250 | Started Training: True
2018-05-19 13:20:17.395425 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #251 | Epoch Duration: 61.786985635757446
2018-05-19 13:20:17.395592 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #251 | Started Training: True
2018-05-19 13:21:19.505820 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #252 | Epoch Duration: 62.11012077331543
2018-05-19 13:21:19.505997 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #252 | Started Training: True
2018-05-19 13:22:20.887882 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #253 | Epoch Duration: 61.381765365600586
2018-05-19 13:22:20.888109 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #253 | Started Training: True
2018-05-19 13:23:23.499754 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #254 | Epoch Duration: 62.61146688461304
2018-05-19 13:23:23.499919 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #254 | Started Training: True
2018-05-19 13:24:24.259201 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #255 | Epoch Duration: 60.75916314125061
2018-05-19 13:24:24.259369 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #255 | Started Training: True
2018-05-19 13:25:25.469194 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #256 | Epoch Duration: 61.20971488952637
2018-05-19 13:25:25.469389 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #256 | Started Training: True
2018-05-19 13:26:27.181446 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #257 | Epoch Duration: 61.71193265914917
2018-05-19 13:26:27.181667 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #257 | Started Training: True
2018-05-19 13:27:28.364786 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #258 | Epoch Duration: 61.182966232299805
2018-05-19 13:27:28.364956 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #258 | Started Training: True
2018-05-19 13:28:29.050892 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #259 | Epoch Duration: 60.685827016830444
2018-05-19 13:28:29.051057 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #259 | Started Training: True
2018-05-19 13:29:53.428765 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #260 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000370706
QF2 Loss                          0.00030467
Policy Loss                      -0.357268
Q1 Predictions Mean               0.353424
Q1 Predictions Std                0.177543
Q1 Predictions Max                0.558199
Q1 Predictions Min               -0.378668
Q2 Predictions Mean               0.354854
Q2 Predictions Std                0.17895
Q2 Predictions Max                0.556621
Q2 Predictions Min               -0.39009
Q Targets Mean                    0.352806
Q Targets Std                     0.178888
Q Targets Max                     0.560244
Q Targets Min                    -0.414767
Bellman Errors 1 Mean             0.000370706
Bellman Errors 1 Std              0.00257959
Bellman Errors 1 Max              0.0291999
Bellman Errors 1 Min              2.45096e-10
Bellman Errors 2 Mean             0.00030467
Bellman Errors 2 Std              0.00189731
Bellman Errors 2 Max              0.0212265
Bellman Errors 2 Min              4.45652e-11
Policy Action Mean               -0.0765922
Policy Action Std                 0.994463
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00676573
Test Rewards Std                  0.00458549
Test Rewards Max                  0.0190725
Test Rewards Min                 -0.0151867
Test Returns Mean                 0.893343
Test Returns Std                  0.170471
Test Returns Max                  1.1783
Test Returns Min                 -0.366373
Test Actions Mean                -0.0233111
Test Actions Std                  0.996857
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        15
Exploration Rewards Mean          0.0069468
Exploration Rewards Std           0.00453851
Exploration Rewards Max           0.0171569
Exploration Rewards Min          -0.000570097
Exploration Returns Mean          0.89521
Exploration Returns Std           0.0382571
Exploration Returns Max           0.945667
Exploration Returns Min           0.831956
Exploration Actions Mean         -0.0022732
Exploration Actions Std           0.959483
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.893343
Number of train steps total  520987
Number of env steps total    522000
Number of rollouts total       3583
Train Time (s)                   35.4364
(Previous) Eval Time (s)          2.09399e-06
Sample Time (s)                  25.3335
Epoch Time (s)                   60.7699
Total Train Time (s)          63771.5
Epoch                           260
---------------------------  ----------------
2018-05-19 13:58:47.222521 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #260 | Epoch Duration: 1818.1713604927063
2018-05-19 13:58:47.222644 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #260 | Started Training: True
2018-05-19 13:59:48.835249 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #261 | Epoch Duration: 61.6124804019928
2018-05-19 13:59:48.835500 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #261 | Started Training: True
2018-05-19 14:00:51.198012 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #262 | Epoch Duration: 62.362351417541504
2018-05-19 14:00:51.198241 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #262 | Started Training: True
2018-05-19 14:01:53.102130 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #263 | Epoch Duration: 61.903708696365356
2018-05-19 14:01:53.102298 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #263 | Started Training: True
2018-05-19 14:02:56.591205 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #264 | Epoch Duration: 63.488797187805176
2018-05-19 14:02:56.591380 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #264 | Started Training: True
2018-05-19 14:03:58.227043 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #265 | Epoch Duration: 61.63554382324219
2018-05-19 14:03:58.227211 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #265 | Started Training: True
2018-05-19 14:04:59.460970 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #266 | Epoch Duration: 61.23364233970642
2018-05-19 14:04:59.461153 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #266 | Started Training: True
2018-05-19 14:06:01.184926 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #267 | Epoch Duration: 61.72366380691528
2018-05-19 14:06:01.185109 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #267 | Started Training: True
2018-05-19 14:07:03.088827 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #268 | Epoch Duration: 61.903594732284546
2018-05-19 14:07:03.088997 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #268 | Started Training: True
2018-05-19 14:08:04.447450 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #269 | Epoch Duration: 61.35834002494812
2018-05-19 14:08:04.447613 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #269 | Started Training: True
2018-05-19 14:09:29.834143 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #270 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000241456
QF2 Loss                          0.000201181
Policy Loss                      -0.390445
Q1 Predictions Mean               0.385469
Q1 Predictions Std                0.184701
Q1 Predictions Max                0.51894
Q1 Predictions Min               -0.42144
Q2 Predictions Mean               0.387822
Q2 Predictions Std                0.185115
Q2 Predictions Max                0.51127
Q2 Predictions Min               -0.430425
Q Targets Mean                    0.389387
Q Targets Std                     0.183395
Q Targets Max                     0.512973
Q Targets Min                    -0.391307
Bellman Errors 1 Mean             0.000241456
Bellman Errors 1 Std              0.00143281
Bellman Errors 1 Max              0.0156727
Bellman Errors 1 Min              6.47482e-11
Bellman Errors 2 Mean             0.00020118
Bellman Errors 2 Std              0.000885513
Bellman Errors 2 Max              0.00943108
Bellman Errors 2 Min              1.89576e-10
Policy Action Mean               -0.0200074
Policy Action Std                 0.996866
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00718944
Test Rewards Std                  0.00442535
Test Rewards Max                  0.0180378
Test Rewards Min                 -0.0101861
Test Returns Mean                 0.888029
Test Returns Std                  0.122351
Test Returns Max                  0.965557
Test Returns Min                 -0.169734
Test Actions Mean                 0.0525981
Test Actions Std                  0.996395
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        16
Exploration Rewards Mean          0.00708137
Exploration Rewards Std           0.00408171
Exploration Rewards Max           0.0160339
Exploration Rewards Min           0.000202534
Exploration Returns Mean          0.881189
Exploration Returns Std           0.0352396
Exploration Returns Max           0.928386
Exploration Returns Min           0.806064
Exploration Actions Mean          0.0964545
Exploration Actions Std           0.955972
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.888029
Number of train steps total  540987
Number of env steps total    542000
Number of rollouts total       3726
Train Time (s)                   34.7705
(Previous) Eval Time (s)          1.99901e-06
Sample Time (s)                  26.3631
Epoch Time (s)                   61.1336
Total Train Time (s)          66094.7
Epoch                           270
---------------------------  ----------------
2018-05-19 14:37:30.957896 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #270 | Epoch Duration: 1766.5101721286774
2018-05-19 14:37:30.958019 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #270 | Started Training: True
2018-05-19 14:38:32.283100 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #271 | Epoch Duration: 61.32496953010559
2018-05-19 14:38:32.283269 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #271 | Started Training: True
2018-05-19 14:39:32.629727 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #272 | Epoch Duration: 60.3463294506073
2018-05-19 14:39:32.629887 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #272 | Started Training: True
2018-05-19 14:40:33.006611 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #273 | Epoch Duration: 60.37660002708435
2018-05-19 14:40:33.006793 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #273 | Started Training: True
2018-05-19 14:41:34.429173 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #274 | Epoch Duration: 61.422261476516724
2018-05-19 14:41:34.429342 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #274 | Started Training: True
2018-05-19 14:42:34.858068 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #275 | Epoch Duration: 60.428619146347046
2018-05-19 14:42:34.858261 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #275 | Started Training: True
2018-05-19 14:43:35.609099 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #276 | Epoch Duration: 60.75072121620178
2018-05-19 14:43:35.609270 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #276 | Started Training: True
2018-05-19 14:44:36.110463 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #277 | Epoch Duration: 60.50108599662781
2018-05-19 14:44:36.110630 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #277 | Started Training: True
2018-05-19 14:45:37.419124 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #278 | Epoch Duration: 61.308382987976074
2018-05-19 14:45:37.419299 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #278 | Started Training: True
2018-05-19 14:46:39.018523 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #279 | Epoch Duration: 61.59910249710083
2018-05-19 14:46:39.018686 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #279 | Started Training: True
2018-05-19 14:48:05.478526 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #280 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000214817
QF2 Loss                          0.000223897
Policy Loss                      -0.415765
Q1 Predictions Mean               0.410327
Q1 Predictions Std                0.193121
Q1 Predictions Max                0.543014
Q1 Predictions Min               -0.485833
Q2 Predictions Mean               0.410523
Q2 Predictions Std                0.191511
Q2 Predictions Max                0.542003
Q2 Predictions Min               -0.458379
Q Targets Mean                    0.414805
Q Targets Std                     0.194526
Q Targets Max                     0.548489
Q Targets Min                    -0.551758
Bellman Errors 1 Mean             0.000214817
Bellman Errors 1 Std              0.000872471
Bellman Errors 1 Max              0.00855767
Bellman Errors 1 Min              1.63795e-09
Bellman Errors 2 Mean             0.000223897
Bellman Errors 2 Std              0.000903958
Bellman Errors 2 Max              0.00871957
Bellman Errors 2 Min              1.86308e-10
Policy Action Mean                0.0649027
Policy Action Std                 0.996215
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00710539
Test Rewards Std                  0.00439419
Test Rewards Max                  0.0186508
Test Rewards Min                 -0.0026789
Test Returns Mean                 0.897766
Test Returns Std                  0.0709505
Test Returns Max                  1.21706
Test Returns Min                  0.828721
Test Actions Mean                 0.0961173
Test Actions Std                  0.993572
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        17
Exploration Rewards Mean          0.00751213
Exploration Rewards Std           0.0049362
Exploration Rewards Max           0.0201804
Exploration Rewards Min          -0.00068452
Exploration Returns Mean          0.931063
Exploration Returns Std           0.0950343
Exploration Returns Max           1.16867
Exploration Returns Min           0.750594
Exploration Actions Mean          0.0288915
Exploration Actions Std           0.959535
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.897766
Number of train steps total  560987
Number of env steps total    562000
Number of rollouts total       3881
Train Time (s)                   35.2194
(Previous) Eval Time (s)          2.24399e-06
Sample Time (s)                  26.1309
Epoch Time (s)                   61.3503
Total Train Time (s)          68448.6
Epoch                           280
---------------------------  ----------------
2018-05-19 15:16:45.312282 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #280 | Epoch Duration: 1806.2934918403625
2018-05-19 15:16:45.312420 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #280 | Started Training: True
2018-05-19 15:17:46.776449 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #281 | Epoch Duration: 61.46391534805298
2018-05-19 15:17:46.776614 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #281 | Started Training: True
2018-05-19 15:18:48.411456 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #282 | Epoch Duration: 61.63471698760986
2018-05-19 15:18:48.411687 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #282 | Started Training: True
2018-05-19 15:19:50.587823 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #283 | Epoch Duration: 62.17596793174744
2018-05-19 15:19:50.587992 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #283 | Started Training: True
2018-05-19 15:20:52.890500 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #284 | Epoch Duration: 62.30239152908325
2018-05-19 15:20:52.890723 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #284 | Started Training: True
2018-05-19 15:21:54.810475 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #285 | Epoch Duration: 61.919557332992554
2018-05-19 15:21:54.810661 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #285 | Started Training: True
2018-05-19 15:22:56.046127 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #286 | Epoch Duration: 61.235352516174316
2018-05-19 15:22:56.046303 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #286 | Started Training: True
2018-05-19 15:23:58.293843 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #287 | Epoch Duration: 62.247432231903076
2018-05-19 15:23:58.294022 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #287 | Started Training: True
2018-05-19 15:25:01.193077 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #288 | Epoch Duration: 62.89895033836365
2018-05-19 15:25:01.193256 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #288 | Started Training: True
2018-05-19 15:26:03.987880 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #289 | Epoch Duration: 62.79451298713684
2018-05-19 15:26:03.988053 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #289 | Started Training: True
2018-05-19 15:27:32.391421 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #290 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000241872
QF2 Loss                          0.000236432
Policy Loss                      -0.393917
Q1 Predictions Mean               0.388428
Q1 Predictions Std                0.268395
Q1 Predictions Max                0.569426
Q1 Predictions Min               -0.767482
Q2 Predictions Mean               0.39309
Q2 Predictions Std                0.26619
Q2 Predictions Max                0.56993
Q2 Predictions Min               -0.810773
Q Targets Mean                    0.390871
Q Targets Std                     0.271946
Q Targets Max                     0.574836
Q Targets Min                    -0.829034
Bellman Errors 1 Mean             0.000241872
Bellman Errors 1 Std              0.000862209
Bellman Errors 1 Max              0.00712133
Bellman Errors 1 Min              2.16147e-11
Bellman Errors 2 Mean             0.000236432
Bellman Errors 2 Std              0.00127818
Bellman Errors 2 Max              0.0138956
Bellman Errors 2 Min              5.3484e-10
Policy Action Mean                0.112109
Policy Action Std                 0.992188
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00752021
Test Rewards Std                  0.00447541
Test Rewards Max                  0.0182162
Test Rewards Min                  0.000426454
Test Returns Mean                 1.10176
Test Returns Std                  0.0865195
Test Returns Max                  1.25886
Test Returns Min                  0.893543
Test Actions Mean                 0.110887
Test Actions Std                  0.990862
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        15
Exploration Rewards Mean          0.00771859
Exploration Rewards Std           0.0046471
Exploration Rewards Max           0.0181117
Exploration Rewards Min          -0.0011076
Exploration Returns Mean          1.04716
Exploration Returns Std           0.115879
Exploration Returns Max           1.26005
Exploration Returns Min           0.859859
Exploration Actions Mean          0.0688082
Exploration Actions Std           0.957246
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.10176
Number of train steps total  580987
Number of env steps total    582000
Number of rollouts total       4027
Train Time (s)                   37.0788
(Previous) Eval Time (s)          1.985e-06
Sample Time (s)                  25.7488
Epoch Time (s)                   62.8276
Total Train Time (s)          70962.9
Epoch                           290
---------------------------  ----------------
2018-05-19 15:58:40.179701 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #290 | Epoch Duration: 1956.1915454864502
2018-05-19 15:58:40.179832 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #290 | Started Training: True
2018-05-19 15:59:43.608891 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #291 | Epoch Duration: 63.42894959449768
2018-05-19 15:59:43.609074 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #291 | Started Training: True
2018-05-19 16:00:45.773967 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #292 | Epoch Duration: 62.16477084159851
2018-05-19 16:00:45.774129 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #292 | Started Training: True
2018-05-19 16:01:48.365555 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #293 | Epoch Duration: 62.59131383895874
2018-05-19 16:01:48.365728 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #293 | Started Training: True
2018-05-19 16:02:49.805678 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #294 | Epoch Duration: 61.439836740493774
2018-05-19 16:02:49.805835 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #294 | Started Training: True
2018-05-19 16:03:52.021272 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #295 | Epoch Duration: 62.215319871902466
2018-05-19 16:03:52.021443 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #295 | Started Training: True
2018-05-19 16:04:53.182773 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #296 | Epoch Duration: 61.161217212677
2018-05-19 16:04:53.182955 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #296 | Started Training: True
2018-05-19 16:05:54.387558 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #297 | Epoch Duration: 61.20448613166809
2018-05-19 16:05:54.387783 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #297 | Started Training: True
2018-05-19 16:06:53.969022 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #298 | Epoch Duration: 59.58107614517212
2018-05-19 16:06:53.969185 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #298 | Started Training: True
2018-05-19 16:07:54.845418 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #299 | Epoch Duration: 60.87610697746277
2018-05-19 16:07:54.845655 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #299 | Started Training: True
2018-05-19 16:09:23.775219 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #300 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000225359
QF2 Loss                          0.000333426
Policy Loss                      -0.410504
Q1 Predictions Mean               0.40485
Q1 Predictions Std                0.24517
Q1 Predictions Max                0.576286
Q1 Predictions Min               -0.521393
Q2 Predictions Mean               0.40961
Q2 Predictions Std                0.240199
Q2 Predictions Max                0.58136
Q2 Predictions Min               -0.532507
Q Targets Mean                    0.406958
Q Targets Std                     0.243922
Q Targets Max                     0.582425
Q Targets Min                    -0.536613
Bellman Errors 1 Mean             0.000225359
Bellman Errors 1 Std              0.001714
Bellman Errors 1 Max              0.0192042
Bellman Errors 1 Min              2.22045e-12
Bellman Errors 2 Mean             0.000333426
Bellman Errors 2 Std              0.00192804
Bellman Errors 2 Max              0.0164875
Bellman Errors 2 Min              3.20632e-09
Policy Action Mean                0.0789334
Policy Action Std                 0.993578
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00752163
Test Rewards Std                  0.00519938
Test Rewards Max                  0.0197664
Test Rewards Min                 -0.00636268
Test Returns Mean                 0.920299
Test Returns Std                  0.109331
Test Returns Max                  1.05254
Test Returns Min                 -0.0273176
Test Actions Mean                 0.0537371
Test Actions Std                  0.996603
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        16
Exploration Rewards Mean          0.0070186
Exploration Rewards Std           0.0051936
Exploration Rewards Max           0.019151
Exploration Rewards Min          -0.00462015
Exploration Returns Mean          0.883906
Exploration Returns Std           0.197577
Exploration Returns Max           1.03132
Exploration Returns Min           0.1295
Exploration Actions Mean          0.102177
Exploration Actions Std           0.954307
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.920299
Number of train steps total  600987
Number of env steps total    602000
Number of rollouts total       4166
Train Time (s)                   36.0172
(Previous) Eval Time (s)          3.47001e-06
Sample Time (s)                  26.3246
Epoch Time (s)                   62.3418
Total Train Time (s)          73263.8
Epoch                           300
---------------------------  ----------------
2018-05-19 16:37:01.552909 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #300 | Epoch Duration: 1746.7070882320404
2018-05-19 16:37:01.553037 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #300 | Started Training: True
2018-05-19 16:38:02.424583 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #301 | Epoch Duration: 60.87144351005554
2018-05-19 16:38:02.424764 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #301 | Started Training: True
2018-05-19 16:39:02.873174 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #302 | Epoch Duration: 60.44827437400818
2018-05-19 16:39:02.873343 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #302 | Started Training: True
2018-05-19 16:40:03.260728 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #303 | Epoch Duration: 60.387256383895874
2018-05-19 16:40:03.260963 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #303 | Started Training: True
2018-05-19 16:41:04.692101 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #304 | Epoch Duration: 61.43096995353699
2018-05-19 16:41:04.692265 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #304 | Started Training: True
2018-05-19 16:42:05.753874 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #305 | Epoch Duration: 61.061474561691284
2018-05-19 16:42:05.754105 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #305 | Started Training: True
2018-05-19 16:43:07.751123 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #306 | Epoch Duration: 61.996851444244385
2018-05-19 16:43:07.751302 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #306 | Started Training: True
2018-05-19 16:44:09.826304 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #307 | Epoch Duration: 62.07489538192749
2018-05-19 16:44:09.826481 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #307 | Started Training: True
2018-05-19 16:45:12.038519 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #308 | Epoch Duration: 62.21192669868469
2018-05-19 16:45:12.038707 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #308 | Started Training: True
2018-05-19 16:46:14.371468 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #309 | Epoch Duration: 62.332639932632446
2018-05-19 16:46:14.371627 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #309 | Started Training: True
2018-05-19 16:47:43.626407 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #310 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000232293
QF2 Loss                          0.000228523
Policy Loss                      -0.403791
Q1 Predictions Mean               0.398623
Q1 Predictions Std                0.22495
Q1 Predictions Max                0.565143
Q1 Predictions Min               -0.421341
Q2 Predictions Mean               0.402056
Q2 Predictions Std                0.222131
Q2 Predictions Max                0.565637
Q2 Predictions Min               -0.44381
Q Targets Mean                    0.404193
Q Targets Std                     0.221992
Q Targets Max                     0.568968
Q Targets Min                    -0.409678
Bellman Errors 1 Mean             0.000232293
Bellman Errors 1 Std              0.00121643
Bellman Errors 1 Max              0.0131033
Bellman Errors 1 Min              3.71799e-10
Bellman Errors 2 Mean             0.000228523
Bellman Errors 2 Std              0.000848482
Bellman Errors 2 Max              0.00689237
Bellman Errors 2 Min              1.00272e-10
Policy Action Mean                0.0181077
Policy Action Std                 0.997411
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00811324
Test Rewards Std                  0.0050472
Test Rewards Max                  0.0213056
Test Rewards Min                 -0.000365023
Test Returns Mean                 1.13022
Test Returns Std                  0.120763
Test Returns Max                  1.31084
Test Returns Min                  0.888334
Test Actions Mean                 0.00646862
Test Actions Std                  0.997764
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        16
Exploration Rewards Mean          0.00784599
Exploration Rewards Std           0.00517963
Exploration Rewards Max           0.0202803
Exploration Rewards Min          -0.000711042
Exploration Returns Mean          1.05774
Exploration Returns Std           0.0962193
Exploration Returns Max           1.23204
Exploration Returns Min           0.88904
Exploration Actions Mean         -0.0482468
Exploration Actions Std           0.958407
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.13022
Number of train steps total  620987
Number of env steps total    622000
Number of rollouts total       4319
Train Time (s)                   36.3517
(Previous) Eval Time (s)          2.245e-06
Sample Time (s)                  25.6496
Epoch Time (s)                   62.0013
Total Train Time (s)          75686.6
Epoch                           310
---------------------------  ----------------
2018-05-19 17:17:24.871311 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #310 | Epoch Duration: 1870.4995782375336
2018-05-19 17:17:24.871434 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #310 | Started Training: True
2018-05-19 17:18:27.191715 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #311 | Epoch Duration: 62.320176124572754
2018-05-19 17:18:27.191880 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #311 | Started Training: True
2018-05-19 17:19:28.828982 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #312 | Epoch Duration: 61.636982917785645
2018-05-19 17:19:28.829144 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #312 | Started Training: True
2018-05-19 17:20:31.117181 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #313 | Epoch Duration: 62.28792095184326
2018-05-19 17:20:31.117428 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #313 | Started Training: True
2018-05-19 17:21:32.710645 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #314 | Epoch Duration: 61.593053340911865
2018-05-19 17:21:32.710887 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #314 | Started Training: True
2018-05-19 17:22:34.138451 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #315 | Epoch Duration: 61.42737936973572
2018-05-19 17:22:34.138618 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #315 | Started Training: True
2018-05-19 17:23:35.747633 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #316 | Epoch Duration: 61.60889267921448
2018-05-19 17:23:35.747856 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #316 | Started Training: True
2018-05-19 17:24:37.070972 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #317 | Epoch Duration: 61.322951555252075
2018-05-19 17:24:37.071137 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #317 | Started Training: True
2018-05-19 17:25:38.724576 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #318 | Epoch Duration: 61.65331768989563
2018-05-19 17:25:38.724788 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #318 | Started Training: True
2018-05-19 17:26:40.538581 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #319 | Epoch Duration: 61.81362295150757
2018-05-19 17:26:40.538805 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #319 | Started Training: True
2018-05-19 17:28:10.166974 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #320 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          7.51663e-05
QF2 Loss                          8.90139e-05
Policy Loss                      -0.457053
Q1 Predictions Mean               0.451686
Q1 Predictions Std                0.161836
Q1 Predictions Max                0.585365
Q1 Predictions Min               -0.0950214
Q2 Predictions Mean               0.453926
Q2 Predictions Std                0.159409
Q2 Predictions Max                0.586033
Q2 Predictions Min               -0.101156
Q Targets Mean                    0.453063
Q Targets Std                     0.162013
Q Targets Max                     0.590096
Q Targets Min                    -0.117316
Bellman Errors 1 Mean             7.51663e-05
Bellman Errors 1 Std              0.00016847
Bellman Errors 1 Max              0.00109133
Bellman Errors 1 Min              5.82077e-09
Bellman Errors 2 Mean             8.90139e-05
Bellman Errors 2 Std              0.000291111
Bellman Errors 2 Max              0.0022864
Bellman Errors 2 Min              7.55026e-10
Policy Action Mean               -0.0246126
Policy Action Std                 0.997509
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00786017
Test Rewards Std                  0.00503505
Test Rewards Max                  0.0212779
Test Rewards Min                 -0.000672902
Test Returns Mean                 1.02958
Test Returns Std                  0.122122
Test Returns Max                  1.26094
Test Returns Min                  0.857537
Test Actions Mean                 0.0332872
Test Actions Std                  0.996531
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        15
Exploration Rewards Mean          0.00764288
Exploration Rewards Std           0.00485025
Exploration Rewards Max           0.0195688
Exploration Rewards Min          -0.00159425
Exploration Returns Mean          0.989498
Exploration Returns Std           0.145669
Exploration Returns Max           1.22502
Exploration Returns Min           0.851716
Exploration Actions Mean          0.0367603
Exploration Actions Std           0.959207
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.02958
Number of train steps total  640987
Number of env steps total    642000
Number of rollouts total       4463
Train Time (s)                   35.789
(Previous) Eval Time (s)          2.974e-06
Sample Time (s)                  25.9079
Epoch Time (s)                   61.697
Total Train Time (s)          78080.2
Epoch                           320
---------------------------  ----------------
2018-05-19 17:57:19.046541 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #320 | Epoch Duration: 1838.5075514316559
2018-05-19 17:57:19.046663 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #320 | Started Training: True
2018-05-19 17:58:20.891340 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #321 | Epoch Duration: 61.8445611000061
2018-05-19 17:58:20.891562 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #321 | Started Training: True
2018-05-19 17:59:22.598727 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #322 | Epoch Duration: 61.70699381828308
2018-05-19 17:59:22.598894 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #322 | Started Training: True
2018-05-19 18:00:24.850899 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #323 | Epoch Duration: 62.25189566612244
2018-05-19 18:00:24.851081 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #323 | Started Training: True
2018-05-19 18:01:26.442765 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #324 | Epoch Duration: 61.59156036376953
2018-05-19 18:01:26.442924 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #324 | Started Training: True
2018-05-19 18:02:27.893451 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #325 | Epoch Duration: 61.450416803359985
2018-05-19 18:02:27.893624 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #325 | Started Training: True
2018-05-19 18:03:29.935843 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #326 | Epoch Duration: 62.042102575302124
2018-05-19 18:03:29.936010 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #326 | Started Training: True
2018-05-19 18:04:31.960735 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #327 | Epoch Duration: 62.02460050582886
2018-05-19 18:04:31.960968 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #327 | Started Training: True
2018-05-19 18:05:33.839592 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #328 | Epoch Duration: 61.87844800949097
2018-05-19 18:05:33.839830 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #328 | Started Training: True
2018-05-19 18:06:35.999680 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #329 | Epoch Duration: 62.15967535972595
2018-05-19 18:06:35.999845 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #329 | Started Training: True
2018-05-19 18:08:07.036092 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #330 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000116129
QF2 Loss                          0.0001493
Policy Loss                      -0.465908
Q1 Predictions Mean               0.459121
Q1 Predictions Std                0.22762
Q1 Predictions Max                0.601141
Q1 Predictions Min               -0.385451
Q2 Predictions Mean               0.460607
Q2 Predictions Std                0.22806
Q2 Predictions Max                0.601822
Q2 Predictions Min               -0.399555
Q Targets Mean                    0.45963
Q Targets Std                     0.22951
Q Targets Max                     0.605578
Q Targets Min                    -0.403984
Bellman Errors 1 Mean             0.000116129
Bellman Errors 1 Std              0.000354723
Bellman Errors 1 Max              0.00296994
Bellman Errors 1 Min              1.20608e-10
Bellman Errors 2 Mean             0.0001493
Bellman Errors 2 Std              0.000573884
Bellman Errors 2 Max              0.00507099
Bellman Errors 2 Min              4.29878e-13
Policy Action Mean                0.00491659
Policy Action Std                 0.997783
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00829293
Test Rewards Std                  0.0056064
Test Rewards Max                  0.0254803
Test Rewards Min                 -0.000774541
Test Returns Mean                 1.22504
Test Returns Std                  0.0965871
Test Returns Max                  1.40828
Test Returns Min                  0.962182
Test Actions Mean                 0.0441021
Test Actions Std                  0.996267
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        15
Exploration Rewards Mean          0.00815306
Exploration Rewards Std           0.00571749
Exploration Rewards Max           0.022816
Exploration Rewards Min          -9.82276e-05
Exploration Returns Mean          1.18817
Exploration Returns Std           0.087632
Exploration Returns Max           1.3366
Exploration Returns Min           0.955922
Exploration Actions Mean          0.0132262
Exploration Actions Std           0.958617
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.22504
Number of train steps total  660987
Number of env steps total    662000
Number of rollouts total       4602
Train Time (s)                   36.1988
(Previous) Eval Time (s)          2.147e-06
Sample Time (s)                  26.3454
Epoch Time (s)                   62.5443
Total Train Time (s)          80504.8
Epoch                           330
---------------------------  ----------------
2018-05-19 18:37:44.201725 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #330 | Epoch Duration: 1868.2017748355865
2018-05-19 18:37:44.201851 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #330 | Started Training: True
2018-05-19 18:38:47.265588 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #331 | Epoch Duration: 63.0636260509491
2018-05-19 18:38:47.265817 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #331 | Started Training: True
2018-05-19 18:39:50.075912 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #332 | Epoch Duration: 62.809916496276855
2018-05-19 18:39:50.076151 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #332 | Started Training: True
2018-05-19 18:40:52.443372 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #333 | Epoch Duration: 62.36703324317932
2018-05-19 18:40:52.443604 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #333 | Started Training: True
2018-05-19 18:41:55.891269 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #334 | Epoch Duration: 63.447500467300415
2018-05-19 18:41:55.891448 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #334 | Started Training: True
2018-05-19 18:42:58.815963 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #335 | Epoch Duration: 62.924405336380005
2018-05-19 18:42:58.816133 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #335 | Started Training: True
2018-05-19 18:44:00.822751 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #336 | Epoch Duration: 62.00650954246521
2018-05-19 18:44:00.822933 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #336 | Started Training: True
2018-05-19 18:45:02.950771 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #337 | Epoch Duration: 62.12772560119629
2018-05-19 18:45:02.950934 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #337 | Started Training: True
2018-05-19 18:46:05.284311 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #338 | Epoch Duration: 62.333266735076904
2018-05-19 18:46:05.284491 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #338 | Started Training: True
2018-05-19 18:47:08.898868 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #339 | Epoch Duration: 63.6142635345459
2018-05-19 18:47:08.899046 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #339 | Started Training: True
2018-05-19 18:48:40.647827 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #340 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000110261
QF2 Loss                          0.000129945
Policy Loss                      -0.453291
Q1 Predictions Mean               0.450814
Q1 Predictions Std                0.239404
Q1 Predictions Max                0.609309
Q1 Predictions Min               -0.507508
Q2 Predictions Mean               0.449666
Q2 Predictions Std                0.241482
Q2 Predictions Max                0.609772
Q2 Predictions Min               -0.505917
Q Targets Mean                    0.448258
Q Targets Std                     0.246176
Q Targets Max                     0.612762
Q Targets Min                    -0.505954
Bellman Errors 1 Mean             0.000110261
Bellman Errors 1 Std              0.000271992
Bellman Errors 1 Max              0.00155297
Bellman Errors 1 Min              1.59481e-11
Bellman Errors 2 Mean             0.000129945
Bellman Errors 2 Std              0.000672629
Bellman Errors 2 Max              0.00742033
Bellman Errors 2 Min              1.37449e-09
Policy Action Mean                0.0325971
Policy Action Std                 0.997863
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00715679
Test Rewards Std                  0.00512279
Test Rewards Max                  0.0229653
Test Rewards Min                 -0.0105717
Test Returns Mean                 1.18005
Test Returns Std                  0.3299
Test Returns Max                  1.45269
Test Returns Min                 -0.342635
Test Actions Mean                 0.0723598
Test Actions Std                  0.993641
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        12
Exploration Rewards Mean          0.00742312
Exploration Rewards Std           0.00565333
Exploration Rewards Max           0.0230524
Exploration Rewards Min          -0.000413608
Exploration Returns Mean          1.18894
Exploration Returns Std           0.105331
Exploration Returns Max           1.32101
Exploration Returns Min           0.99438
Exploration Actions Mean          0.0896381
Exploration Actions Std           0.954777
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.18005
Number of train steps total  680987
Number of env steps total    682000
Number of rollouts total       4730
Train Time (s)                   36.61
(Previous) Eval Time (s)          1.84201e-06
Sample Time (s)                  25.8087
Epoch Time (s)                   62.4188
Total Train Time (s)          83043
Epoch                           340
---------------------------  ----------------
2018-05-19 19:20:02.910506 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #340 | Epoch Duration: 1974.0113537311554
2018-05-19 19:20:02.910636 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #340 | Started Training: True
2018-05-19 19:21:06.196907 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #341 | Epoch Duration: 63.28616118431091
2018-05-19 19:21:06.197134 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #341 | Started Training: True
2018-05-19 19:22:09.152628 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #342 | Epoch Duration: 62.955318212509155
2018-05-19 19:22:09.152801 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #342 | Started Training: True
2018-05-19 19:23:12.399533 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #343 | Epoch Duration: 63.24661374092102
2018-05-19 19:23:12.399701 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #343 | Started Training: True
2018-05-19 19:24:15.131426 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #344 | Epoch Duration: 62.731608629226685
2018-05-19 19:24:15.131664 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #344 | Started Training: True
2018-05-19 19:25:18.491698 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #345 | Epoch Duration: 63.35987949371338
2018-05-19 19:25:18.491865 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #345 | Started Training: True
2018-05-19 19:26:20.717017 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #346 | Epoch Duration: 62.225037574768066
2018-05-19 19:26:20.717185 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #346 | Started Training: True
2018-05-19 19:27:23.618016 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #347 | Epoch Duration: 62.90070843696594
2018-05-19 19:27:23.618182 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #347 | Started Training: True
2018-05-19 19:28:26.387905 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #348 | Epoch Duration: 62.769609451293945
2018-05-19 19:28:26.388088 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #348 | Started Training: True
2018-05-19 19:29:29.181213 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #349 | Epoch Duration: 62.793001651763916
2018-05-19 19:29:29.181441 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #349 | Started Training: True
2018-05-19 19:31:02.764188 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #350 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000138692
QF2 Loss                          0.000239036
Policy Loss                      -0.480287
Q1 Predictions Mean               0.472691
Q1 Predictions Std                0.21513
Q1 Predictions Max                0.622826
Q1 Predictions Min               -0.384597
Q2 Predictions Mean               0.472926
Q2 Predictions Std                0.213513
Q2 Predictions Max                0.622843
Q2 Predictions Min               -0.406128
Q Targets Mean                    0.473489
Q Targets Std                     0.215477
Q Targets Max                     0.625475
Q Targets Min                    -0.384462
Bellman Errors 1 Mean             0.000138691
Bellman Errors 1 Std              0.000695563
Bellman Errors 1 Max              0.00762111
Bellman Errors 1 Min              1.79856e-10
Bellman Errors 2 Mean             0.000239036
Bellman Errors 2 Std              0.000740901
Bellman Errors 2 Max              0.00511513
Bellman Errors 2 Min              8.91735e-10
Policy Action Mean                0.054005
Policy Action Std                 0.994845
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00747257
Test Rewards Std                  0.00501798
Test Rewards Max                  0.0200066
Test Rewards Min                 -0.000590438
Test Returns Mean                 1.16492
Test Returns Std                  0.112132
Test Returns Max                  1.3882
Test Returns Min                  0.934822
Test Actions Mean                 0.0856803
Test Actions Std                  0.994152
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        12
Exploration Rewards Mean          0.00724858
Exploration Rewards Std           0.00534183
Exploration Rewards Max           0.0247762
Exploration Rewards Min          -0.00254161
Exploration Returns Mean          1.22561
Exploration Returns Std           0.097066
Exploration Returns Max           1.41074
Exploration Returns Min           1.07937
Exploration Actions Mean          0.0617872
Exploration Actions Std           0.957101
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.16492
Number of train steps total  700987
Number of env steps total    702000
Number of rollouts total       4850
Train Time (s)                   37.0841
(Previous) Eval Time (s)          3.07201e-06
Sample Time (s)                  26.0062
Epoch Time (s)                   63.0903
Total Train Time (s)          85560
Epoch                           350
---------------------------  ----------------
2018-05-19 20:02:00.420504 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #350 | Epoch Duration: 1951.2389051914215
2018-05-19 20:02:00.420629 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #350 | Started Training: True
2018-05-19 20:03:04.251828 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #351 | Epoch Duration: 63.83108973503113
2018-05-19 20:03:04.252059 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #351 | Started Training: True
2018-05-19 20:04:08.135454 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #352 | Epoch Duration: 63.88323736190796
2018-05-19 20:04:08.135640 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #352 | Started Training: True
2018-05-19 20:05:11.825006 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #353 | Epoch Duration: 63.689244747161865
2018-05-19 20:05:11.825175 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #353 | Started Training: True
2018-05-19 20:06:15.577757 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #354 | Epoch Duration: 63.75245952606201
2018-05-19 20:06:15.577933 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #354 | Started Training: True
2018-05-19 20:07:18.847590 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #355 | Epoch Duration: 63.26953077316284
2018-05-19 20:07:18.847802 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #355 | Started Training: True
2018-05-19 20:08:22.594064 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #356 | Epoch Duration: 63.746118783950806
2018-05-19 20:08:22.594288 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #356 | Started Training: True
2018-05-19 20:09:25.544317 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #357 | Epoch Duration: 62.94986367225647
2018-05-19 20:09:25.544519 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #357 | Started Training: True
2018-05-19 20:10:28.246677 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #358 | Epoch Duration: 62.70203948020935
2018-05-19 20:10:28.246854 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #358 | Started Training: True
2018-05-19 20:11:30.404889 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #359 | Epoch Duration: 62.15792512893677
2018-05-19 20:11:30.405062 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #359 | Started Training: True
2018-05-19 20:13:04.774992 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #360 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000335294
QF2 Loss                          0.000348971
Policy Loss                      -0.455529
Q1 Predictions Mean               0.450419
Q1 Predictions Std                0.279458
Q1 Predictions Max                0.638578
Q1 Predictions Min               -0.536264
Q2 Predictions Mean               0.451811
Q2 Predictions Std                0.273562
Q2 Predictions Max                0.63777
Q2 Predictions Min               -0.525256
Q Targets Mean                    0.448899
Q Targets Std                     0.285749
Q Targets Max                     0.64753
Q Targets Min                    -0.560973
Bellman Errors 1 Mean             0.000335294
Bellman Errors 1 Std              0.00107669
Bellman Errors 1 Max              0.00694126
Bellman Errors 1 Min              2.6032e-09
Bellman Errors 2 Mean             0.000348971
Bellman Errors 2 Std              0.000993004
Bellman Errors 2 Max              0.00572641
Bellman Errors 2 Min              4.32226e-09
Policy Action Mean                0.00837269
Policy Action Std                 0.998225
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.0083533
Test Rewards Std                  0.00591188
Test Rewards Max                  0.0234391
Test Rewards Min                 -0.00373096
Test Returns Mean                 1.17259
Test Returns Std                  0.114446
Test Returns Max                  1.41429
Test Returns Min                  0.872824
Test Actions Mean                 0.0174339
Test Actions Std                  0.997598
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        10
Exploration Rewards Mean          0.00752186
Exploration Rewards Std           0.00479961
Exploration Rewards Max           0.0205764
Exploration Rewards Min          -6.43228e-05
Exploration Returns Mean          1.23885
Exploration Returns Std           0.162367
Exploration Returns Max           1.4431
Exploration Returns Min           0.97356
Exploration Actions Mean          0.118723
Exploration Actions Std           0.951413
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.17259
Number of train steps total  720987
Number of env steps total    722000
Number of rollouts total       4952
Train Time (s)                   36.9556
(Previous) Eval Time (s)          2.21601e-06
Sample Time (s)                  26.1889
Epoch Time (s)                   63.1446
Total Train Time (s)          88009.4
Epoch                           360
---------------------------  ----------------
2018-05-19 20:42:50.396462 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #360 | Epoch Duration: 1879.9912934303284
2018-05-19 20:42:50.396587 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #360 | Started Training: True
2018-05-19 20:43:53.443925 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #361 | Epoch Duration: 63.04722332954407
2018-05-19 20:43:53.444086 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #361 | Started Training: True
2018-05-19 20:44:56.521975 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #362 | Epoch Duration: 63.07778191566467
2018-05-19 20:44:56.522145 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #362 | Started Training: True
2018-05-19 20:45:59.656304 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #363 | Epoch Duration: 63.134034156799316
2018-05-19 20:45:59.656500 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #363 | Started Training: True
2018-05-19 20:47:02.373305 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #364 | Epoch Duration: 62.716681241989136
2018-05-19 20:47:02.373485 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #364 | Started Training: True
2018-05-19 20:48:05.402120 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #365 | Epoch Duration: 63.028523206710815
2018-05-19 20:48:05.402289 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #365 | Started Training: True
2018-05-19 20:49:07.632762 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #366 | Epoch Duration: 62.230358362197876
2018-05-19 20:49:07.632994 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #366 | Started Training: True
2018-05-19 20:50:11.087348 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #367 | Epoch Duration: 63.45418405532837
2018-05-19 20:50:11.087575 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #367 | Started Training: True
2018-05-19 20:51:13.091741 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #368 | Epoch Duration: 62.00399827957153
2018-05-19 20:51:13.091933 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #368 | Started Training: True
2018-05-19 20:52:16.055573 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #369 | Epoch Duration: 62.963510513305664
2018-05-19 20:52:16.055808 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #369 | Started Training: True
2018-05-19 20:53:51.476550 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #370 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000270279
QF2 Loss                          0.000191593
Policy Loss                      -0.493024
Q1 Predictions Mean               0.486536
Q1 Predictions Std                0.257142
Q1 Predictions Max                0.655208
Q1 Predictions Min               -0.446724
Q2 Predictions Mean               0.484676
Q2 Predictions Std                0.255756
Q2 Predictions Max                0.654738
Q2 Predictions Min               -0.439788
Q Targets Mean                    0.483823
Q Targets Std                     0.256717
Q Targets Max                     0.662119
Q Targets Min                    -0.415135
Bellman Errors 1 Mean             0.000270279
Bellman Errors 1 Std              0.00129805
Bellman Errors 1 Max              0.014106
Bellman Errors 1 Min              3.14586e-09
Bellman Errors 2 Mean             0.000191593
Bellman Errors 2 Std              0.00110885
Bellman Errors 2 Max              0.0124682
Bellman Errors 2 Min              6.44732e-10
Policy Action Mean               -0.0802535
Policy Action Std                 0.99459
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00805577
Test Rewards Std                  0.00511632
Test Rewards Max                  0.0214319
Test Rewards Min                 -0.000337236
Test Returns Mean                 1.14528
Test Returns Std                  0.102232
Test Returns Max                  1.29855
Test Returns Min                  0.901541
Test Actions Mean                 0.0804669
Test Actions Std                  0.99299
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        15
Exploration Rewards Mean          0.00734463
Exploration Rewards Std           0.00596818
Exploration Rewards Max           0.0204098
Exploration Rewards Min          -0.0182807
Exploration Returns Mean          1.04588
Exploration Returns Std           0.428153
Exploration Returns Max           1.33222
Exploration Returns Min          -0.465334
Exploration Actions Mean          0.066927
Exploration Actions Std           0.95751
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.14528
Number of train steps total  740987
Number of env steps total    742000
Number of rollouts total       5079
Train Time (s)                   37.3159
(Previous) Eval Time (s)          3.21401e-06
Sample Time (s)                  26.3497
Epoch Time (s)                   63.6657
Total Train Time (s)          90443.3
Epoch                           370
---------------------------  ----------------
2018-05-19 21:23:24.844865 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #370 | Epoch Duration: 1868.7888898849487
2018-05-19 21:23:24.844986 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #370 | Started Training: True
2018-05-19 21:24:28.300084 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #371 | Epoch Duration: 63.45498442649841
2018-05-19 21:24:28.300254 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #371 | Started Training: True
2018-05-19 21:25:32.417241 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #372 | Epoch Duration: 64.11685132980347
2018-05-19 21:25:32.417411 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #372 | Started Training: True
2018-05-19 21:26:34.795506 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #373 | Epoch Duration: 62.37798285484314
2018-05-19 21:26:34.795684 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #373 | Started Training: True
2018-05-19 21:27:35.919434 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #374 | Epoch Duration: 61.12362456321716
2018-05-19 21:27:35.919654 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #374 | Started Training: True
2018-05-19 21:28:38.011418 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #375 | Epoch Duration: 62.0915846824646
2018-05-19 21:28:38.011639 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #375 | Started Training: True
2018-05-19 21:29:39.927748 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #376 | Epoch Duration: 61.915931701660156
2018-05-19 21:29:39.927911 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #376 | Started Training: True
2018-05-19 21:30:42.215963 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #377 | Epoch Duration: 62.28793287277222
2018-05-19 21:30:42.216189 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #377 | Started Training: True
2018-05-19 21:31:43.970255 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #378 | Epoch Duration: 61.7538902759552
2018-05-19 21:31:43.970420 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #378 | Started Training: True
2018-05-19 21:32:45.170559 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #379 | Epoch Duration: 61.20002603530884
2018-05-19 21:32:45.170721 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #379 | Started Training: True
2018-05-19 21:34:19.924890 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #380 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000353539
QF2 Loss                          0.000340937
Policy Loss                      -0.476701
Q1 Predictions Mean               0.46711
Q1 Predictions Std                0.238208
Q1 Predictions Max                0.663982
Q1 Predictions Min               -0.338377
Q2 Predictions Mean               0.466708
Q2 Predictions Std                0.236759
Q2 Predictions Max                0.663652
Q2 Predictions Min               -0.360571
Q Targets Mean                    0.47355
Q Targets Std                     0.235971
Q Targets Max                     0.667568
Q Targets Min                    -0.356207
Bellman Errors 1 Mean             0.000353539
Bellman Errors 1 Std              0.00211101
Bellman Errors 1 Max              0.022822
Bellman Errors 1 Min              1.02673e-10
Bellman Errors 2 Mean             0.000340937
Bellman Errors 2 Std              0.00196131
Bellman Errors 2 Max              0.0213449
Bellman Errors 2 Min              7.21423e-09
Policy Action Mean                0.0536809
Policy Action Std                 0.995623
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00876478
Test Rewards Std                  0.00601432
Test Rewards Max                  0.0226545
Test Rewards Min                 -0.00107914
Test Returns Mean                 1.13965
Test Returns Std                  0.0989157
Test Returns Max                  1.27828
Test Returns Min                  0.918228
Test Actions Mean                -0.0588183
Test Actions Std                  0.995875
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        14
Exploration Rewards Mean          0.0086124
Exploration Rewards Std           0.00592994
Exploration Rewards Max           0.0217905
Exploration Rewards Min          -0.000326334
Exploration Returns Mean          1.18974
Exploration Returns Std           0.133684
Exploration Returns Max           1.32664
Exploration Returns Min           0.877679
Exploration Actions Mean         -0.0324398
Exploration Actions Std           0.958093
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.13965
Number of train steps total  760987
Number of env steps total    762000
Number of rollouts total       5211
Train Time (s)                   35.5405
(Previous) Eval Time (s)          2.22299e-06
Sample Time (s)                  26.1395
Epoch Time (s)                   61.68
Total Train Time (s)          92833.4
Epoch                           380
---------------------------  ----------------
2018-05-19 22:03:15.416621 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #380 | Epoch Duration: 1830.2457919120789
2018-05-19 22:03:15.416748 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #380 | Started Training: True
2018-05-19 22:04:17.202405 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #381 | Epoch Duration: 61.78554630279541
2018-05-19 22:04:17.202571 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #381 | Started Training: True
2018-05-19 22:05:18.569570 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #382 | Epoch Duration: 61.36688804626465
2018-05-19 22:05:18.569748 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #382 | Started Training: True
2018-05-19 22:06:20.075072 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #383 | Epoch Duration: 61.505206823349
2018-05-19 22:06:20.075231 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #383 | Started Training: True
2018-05-19 22:07:22.057480 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #384 | Epoch Duration: 61.982136249542236
2018-05-19 22:07:22.057636 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #384 | Started Training: True
2018-05-19 22:08:23.596096 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #385 | Epoch Duration: 61.53834056854248
2018-05-19 22:08:23.596319 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #385 | Started Training: True
2018-05-19 22:09:25.889122 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #386 | Epoch Duration: 62.292624711990356
2018-05-19 22:09:25.889303 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #386 | Started Training: True
2018-05-19 22:10:28.263791 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #387 | Epoch Duration: 62.37436866760254
2018-05-19 22:10:28.264024 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #387 | Started Training: True
2018-05-19 22:11:30.543101 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #388 | Epoch Duration: 62.27890062332153
2018-05-19 22:11:30.543331 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #388 | Started Training: True
2018-05-19 22:12:33.547490 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #389 | Epoch Duration: 63.00398921966553
2018-05-19 22:12:33.547705 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #389 | Started Training: True
2018-05-19 22:14:09.574891 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #390 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000155231
QF2 Loss                          0.000145079
Policy Loss                      -0.487704
Q1 Predictions Mean               0.480171
Q1 Predictions Std                0.293507
Q1 Predictions Max                0.676229
Q1 Predictions Min               -0.615226
Q2 Predictions Mean               0.480941
Q2 Predictions Std                0.289096
Q2 Predictions Max                0.675765
Q2 Predictions Min               -0.598435
Q Targets Mean                    0.479758
Q Targets Std                     0.292446
Q Targets Max                     0.68368
Q Targets Min                    -0.575334
Bellman Errors 1 Mean             0.000155231
Bellman Errors 1 Std              0.000525633
Bellman Errors 1 Max              0.00346906
Bellman Errors 1 Min              2.80027e-10
Bellman Errors 2 Mean             0.000145079
Bellman Errors 2 Std              0.000540216
Bellman Errors 2 Max              0.0042998
Bellman Errors 2 Min              1.94021e-09
Policy Action Mean               -0.0476817
Policy Action Std                 0.996266
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00860526
Test Rewards Std                  0.00569169
Test Rewards Max                  0.0220403
Test Rewards Min                 -0.00108868
Test Returns Mean                 1.1385
Test Returns Std                  0.0969121
Test Returns Max                  1.26843
Test Returns Min                  0.840501
Test Actions Mean                -0.116817
Test Actions Std                  0.991468
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        18
Exploration Rewards Mean          0.00855941
Exploration Rewards Std           0.00529614
Exploration Rewards Max           0.0212653
Exploration Rewards Min           0.000306183
Exploration Returns Mean          1.12604
Exploration Returns Std           0.104928
Exploration Returns Max           1.3347
Exploration Returns Min           0.900567
Exploration Actions Mean         -0.113101
Exploration Actions Std           0.953448
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.1385
Number of train steps total  780987
Number of env steps total    782000
Number of rollouts total       5358
Train Time (s)                   36.262
(Previous) Eval Time (s)          3.088e-06
Sample Time (s)                  26.2194
Epoch Time (s)                   62.4815
Total Train Time (s)          95255.7
Epoch                           390
---------------------------  ----------------
2018-05-19 22:43:38.211478 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #390 | Epoch Duration: 1864.6636183261871
2018-05-19 22:43:38.211603 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #390 | Started Training: True
2018-05-19 22:44:40.938861 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #391 | Epoch Duration: 62.727155447006226
2018-05-19 22:44:40.939036 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #391 | Started Training: True
2018-05-19 22:45:43.057631 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #392 | Epoch Duration: 62.11847805976868
2018-05-19 22:45:43.057861 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #392 | Started Training: True
2018-05-19 22:46:44.899613 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #393 | Epoch Duration: 61.84158730506897
2018-05-19 22:46:44.899798 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #393 | Started Training: True
2018-05-19 22:47:46.964722 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #394 | Epoch Duration: 62.06481409072876
2018-05-19 22:47:46.964899 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #394 | Started Training: True
2018-05-19 22:48:47.854690 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #395 | Epoch Duration: 60.889678716659546
2018-05-19 22:48:47.854860 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #395 | Started Training: True
2018-05-19 22:49:49.312567 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #396 | Epoch Duration: 61.457594871520996
2018-05-19 22:49:49.312751 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #396 | Started Training: True
2018-05-19 22:50:51.831410 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #397 | Epoch Duration: 62.518548250198364
2018-05-19 22:50:51.831586 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #397 | Started Training: True
2018-05-19 22:51:55.369518 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #398 | Epoch Duration: 63.53782343864441
2018-05-19 22:51:55.369722 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #398 | Started Training: True
2018-05-19 22:52:58.875727 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #399 | Epoch Duration: 63.5058856010437
2018-05-19 22:52:58.875900 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #399 | Started Training: True
2018-05-19 22:54:35.450676 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #400 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00142891
QF2 Loss                          0.00133375
Policy Loss                      -0.506737
Q1 Predictions Mean               0.505059
Q1 Predictions Std                0.222733
Q1 Predictions Max                0.687785
Q1 Predictions Min               -0.211029
Q2 Predictions Mean               0.504268
Q2 Predictions Std                0.223867
Q2 Predictions Max                0.688306
Q2 Predictions Min               -0.192259
Q Targets Mean                    0.498855
Q Targets Std                     0.227537
Q Targets Max                     0.692745
Q Targets Min                    -0.201536
Bellman Errors 1 Mean             0.00142891
Bellman Errors 1 Std              0.0123785
Bellman Errors 1 Max              0.13612
Bellman Errors 1 Min              9.11628e-11
Bellman Errors 2 Mean             0.00133375
Bellman Errors 2 Std              0.0123504
Bellman Errors 2 Max              0.139378
Bellman Errors 2 Min              7.02313e-09
Policy Action Mean               -0.103414
Policy Action Std                 0.992293
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00791842
Test Rewards Std                  0.00463098
Test Rewards Max                  0.0197259
Test Rewards Min                  0.000553122
Test Returns Mean                 1.18315
Test Returns Std                  0.101815
Test Returns Max                  1.30782
Test Returns Min                  0.934207
Test Actions Mean                -0.0165566
Test Actions Std                  0.99759
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        13
Exploration Rewards Mean          0.00813831
Exploration Rewards Std           0.00481631
Exploration Rewards Max           0.0211144
Exploration Rewards Min           0.000805149
Exploration Returns Mean          1.26895
Exploration Returns Std           0.0641083
Exploration Returns Max           1.36512
Exploration Returns Min           1.15459
Exploration Actions Mean          0.0169126
Exploration Actions Std           0.959551
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.18315
Number of train steps total  800987
Number of env steps total    802000
Number of rollouts total       5491
Train Time (s)                   36.2221
(Previous) Eval Time (s)          2.306e-06
Sample Time (s)                  26.2998
Epoch Time (s)                   62.522
Total Train Time (s)          97716.5
Epoch                           400
---------------------------  ----------------
2018-05-19 23:24:39.608290 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #400 | Epoch Duration: 1900.73228597641
2018-05-19 23:24:39.608429 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #400 | Started Training: True
2018-05-19 23:25:42.083998 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #401 | Epoch Duration: 62.47546315193176
2018-05-19 23:25:42.084158 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #401 | Started Training: True
2018-05-19 23:26:44.405490 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #402 | Epoch Duration: 62.32121133804321
2018-05-19 23:26:44.405715 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #402 | Started Training: True
2018-05-19 23:27:46.557416 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #403 | Epoch Duration: 62.151520013809204
2018-05-19 23:27:46.557647 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #403 | Started Training: True
2018-05-19 23:28:48.960241 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #404 | Epoch Duration: 62.40242671966553
2018-05-19 23:28:48.960883 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #404 | Started Training: True
2018-05-19 23:29:51.999892 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #405 | Epoch Duration: 63.03882622718811
2018-05-19 23:29:52.000144 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #405 | Started Training: True
2018-05-19 23:30:55.458151 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #406 | Epoch Duration: 63.457823753356934
2018-05-19 23:30:55.458314 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #406 | Started Training: True
2018-05-19 23:31:59.138124 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #407 | Epoch Duration: 63.6797034740448
2018-05-19 23:31:59.138301 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #407 | Started Training: True
2018-05-19 23:33:02.754830 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #408 | Epoch Duration: 63.61640381813049
2018-05-19 23:33:02.754996 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #408 | Started Training: True
2018-05-19 23:34:07.245475 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #409 | Epoch Duration: 64.49035501480103
2018-05-19 23:34:07.245642 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #409 | Started Training: True
2018-05-19 23:35:44.820506 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #410 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000573838
QF2 Loss                          0.000727477
Policy Loss                      -0.503767
Q1 Predictions Mean               0.495996
Q1 Predictions Std                0.256572
Q1 Predictions Max                0.692205
Q1 Predictions Min               -0.606875
Q2 Predictions Mean               0.500125
Q2 Predictions Std                0.25208
Q2 Predictions Max                0.693041
Q2 Predictions Min               -0.544657
Q Targets Mean                    0.497908
Q Targets Std                     0.254929
Q Targets Max                     0.698209
Q Targets Min                    -0.606183
Bellman Errors 1 Mean             0.000573838
Bellman Errors 1 Std              0.00321554
Bellman Errors 1 Max              0.0268378
Bellman Errors 1 Min              8.93648e-09
Bellman Errors 2 Mean             0.000727477
Bellman Errors 2 Std              0.0036221
Bellman Errors 2 Max              0.0360254
Bellman Errors 2 Min              1.42803e-09
Policy Action Mean                0.00247822
Policy Action Std                 0.997112
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00511597
Test Rewards Std                  0.00561143
Test Rewards Max                  0.0217448
Test Rewards Min                 -0.020236
Test Returns Mean                 0.955454
Test Returns Std                  0.627039
Test Returns Max                  1.46694
Test Returns Min                 -1.21023
Test Actions Mean                -0.0330016
Test Actions Std                  0.997392
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        11
Exploration Rewards Mean          0.00557671
Exploration Rewards Std           0.00505724
Exploration Rewards Max           0.0189716
Exploration Rewards Min          -0.00910066
Exploration Returns Mean          1.09709
Exploration Returns Std           0.221784
Exploration Returns Max           1.35125
Exploration Returns Min           0.53225
Exploration Actions Mean         -0.0283995
Exploration Actions Std           0.959458
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.955454
Number of train steps total  820987
Number of env steps total    822000
Number of rollouts total       5609
Train Time (s)                   36.7031
(Previous) Eval Time (s)          2.33699e-06
Sample Time (s)                  26.2493
Epoch Time (s)                   62.9524
Total Train Time (s)         100349
Epoch                           410
---------------------------  ----------------
2018-05-20 00:08:32.753308 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #410 | Epoch Duration: 2065.5075619220734
2018-05-20 00:08:32.753432 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #410 | Started Training: True
2018-05-20 00:09:36.596333 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #411 | Epoch Duration: 63.842795848846436
2018-05-20 00:09:36.596526 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #411 | Started Training: True
2018-05-20 00:10:40.843496 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #412 | Epoch Duration: 64.24684429168701
2018-05-20 00:10:40.843660 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #412 | Started Training: True
2018-05-20 00:11:43.687690 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #413 | Epoch Duration: 62.84391927719116
2018-05-20 00:11:43.687859 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #413 | Started Training: True
2018-05-20 00:12:46.610920 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #414 | Epoch Duration: 62.92294979095459
2018-05-20 00:12:46.611096 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #414 | Started Training: True
2018-05-20 00:13:50.835310 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #415 | Epoch Duration: 64.2240982055664
2018-05-20 00:13:50.835510 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #415 | Started Training: True
2018-05-20 00:14:55.915265 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #416 | Epoch Duration: 65.07962703704834
2018-05-20 00:14:55.915437 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #416 | Started Training: True
2018-05-20 00:16:00.366499 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #417 | Epoch Duration: 64.45093989372253
2018-05-20 00:16:00.366728 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #417 | Started Training: True
2018-05-20 00:17:04.302549 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #418 | Epoch Duration: 63.93565344810486
2018-05-20 00:17:04.302714 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #418 | Started Training: True
2018-05-20 00:18:08.150375 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #419 | Epoch Duration: 63.84753966331482
2018-05-20 00:18:08.150538 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #419 | Started Training: True
2018-05-20 00:19:48.471890 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #420 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000532327
QF2 Loss                          0.000582717
Policy Loss                      -0.500366
Q1 Predictions Mean               0.495631
Q1 Predictions Std                0.256173
Q1 Predictions Max                0.688075
Q1 Predictions Min               -0.677542
Q2 Predictions Mean               0.495738
Q2 Predictions Std                0.26067
Q2 Predictions Max                0.688143
Q2 Predictions Min               -0.717299
Q Targets Mean                    0.496717
Q Targets Std                     0.259641
Q Targets Max                     0.693678
Q Targets Min                    -0.729925
Bellman Errors 1 Mean             0.000532327
Bellman Errors 1 Std              0.00322434
Bellman Errors 1 Max              0.0291147
Bellman Errors 1 Min              8.37099e-09
Bellman Errors 2 Mean             0.000582717
Bellman Errors 2 Std              0.00274968
Bellman Errors 2 Max              0.0210012
Bellman Errors 2 Min              1.91926e-09
Policy Action Mean               -0.0556773
Policy Action Std                 0.996562
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00581535
Test Rewards Std                  0.00590838
Test Rewards Max                  0.0208675
Test Rewards Min                 -0.0210013
Test Returns Mean                 1.04676
Test Returns Std                  0.646119
Test Returns Max                  1.94071
Test Returns Min                 -0.795563
Test Actions Mean                -0.0166761
Test Actions Std                  0.997752
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                         6
Exploration Rewards Mean          0.00194717
Exploration Rewards Std           0.00405346
Exploration Rewards Max           0.0171358
Exploration Rewards Min          -0.00990172
Exploration Returns Mean          1.19069
Exploration Returns Std           0.762379
Exploration Returns Max           2.0374
Exploration Returns Min           0.228698
Exploration Actions Mean          0.259519
Exploration Actions Std           0.924345
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.04676
Number of train steps total  840987
Number of env steps total    842000
Number of rollouts total       5688
Train Time (s)                   37.8666
(Previous) Eval Time (s)          2.16599e-06
Sample Time (s)                  26.5116
Epoch Time (s)                   64.3782
Total Train Time (s)         102887
Epoch                           420
---------------------------  ----------------
2018-05-20 00:50:50.726347 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #420 | Epoch Duration: 1962.575704574585
2018-05-20 00:50:50.726471 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #420 | Started Training: True
2018-05-20 00:51:53.929383 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #421 | Epoch Duration: 63.20279312133789
2018-05-20 00:51:53.929625 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #421 | Started Training: True
2018-05-20 00:52:57.195121 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #422 | Epoch Duration: 63.26532292366028
2018-05-20 00:52:57.195351 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #422 | Started Training: True
2018-05-20 00:54:00.824428 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #423 | Epoch Duration: 63.628891706466675
2018-05-20 00:54:00.824593 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #423 | Started Training: True
2018-05-20 00:55:05.758051 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #424 | Epoch Duration: 64.93332767486572
2018-05-20 00:55:05.758285 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #424 | Started Training: True
2018-05-20 00:56:08.134354 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #425 | Epoch Duration: 62.375898599624634
2018-05-20 00:56:08.134530 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #425 | Started Training: True
2018-05-20 00:57:09.835035 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #426 | Epoch Duration: 61.70038819313049
2018-05-20 00:57:09.835216 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #426 | Started Training: True
2018-05-20 00:58:11.448389 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #427 | Epoch Duration: 61.613030195236206
2018-05-20 00:58:11.448552 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #427 | Started Training: True
2018-05-20 00:59:13.833283 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #428 | Epoch Duration: 62.38460898399353
2018-05-20 00:59:13.833463 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #428 | Started Training: True
2018-05-20 01:00:17.048609 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #429 | Epoch Duration: 63.21503019332886
2018-05-20 01:00:17.048792 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #429 | Started Training: True
2018-05-20 01:01:56.141111 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #430 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000422215
QF2 Loss                          0.000336752
Policy Loss                      -0.525765
Q1 Predictions Mean               0.524019
Q1 Predictions Std                0.274323
Q1 Predictions Max                0.694308
Q1 Predictions Min               -0.863332
Q2 Predictions Mean               0.526134
Q2 Predictions Std                0.27322
Q2 Predictions Max                0.695362
Q2 Predictions Min               -0.883873
Q Targets Mean                    0.529466
Q Targets Std                     0.274619
Q Targets Max                     0.703191
Q Targets Min                    -0.928277
Bellman Errors 1 Mean             0.000422215
Bellman Errors 1 Std              0.00223876
Bellman Errors 1 Max              0.0182911
Bellman Errors 1 Min              2.68905e-11
Bellman Errors 2 Mean             0.000336752
Bellman Errors 2 Std              0.00206519
Bellman Errors 2 Max              0.0167134
Bellman Errors 2 Min              2.50679e-09
Policy Action Mean               -0.0584351
Policy Action Std                 0.99568
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00697062
Test Rewards Std                  0.00460541
Test Rewards Max                  0.0192479
Test Rewards Min                 -0.0182516
Test Returns Mean                 1.16305
Test Returns Std                  0.396446
Test Returns Max                  1.61366
Test Returns Min                 -0.245413
Test Actions Mean                -0.0815119
Test Actions Std                  0.994483
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        12
Exploration Rewards Mean          0.00701945
Exploration Rewards Std           0.00439122
Exploration Rewards Max           0.0187122
Exploration Rewards Min          -0.000982195
Exploration Returns Mean          1.22957
Exploration Returns Std           0.147296
Exploration Returns Max           1.44897
Exploration Returns Min           0.972701
Exploration Actions Mean         -0.0168633
Exploration Actions Std           0.95948
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.16305
Number of train steps total  860987
Number of env steps total    862000
Number of rollouts total       5798
Train Time (s)                   37.0396
(Previous) Eval Time (s)          1.967e-06
Sample Time (s)                  25.9002
Epoch Time (s)                   62.9399
Total Train Time (s)         105469
Epoch                           430
---------------------------  ----------------
2018-05-20 01:33:54.146263 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #430 | Epoch Duration: 2017.0973589420319
2018-05-20 01:33:54.146389 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #430 | Started Training: True
2018-05-20 01:34:58.221834 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #431 | Epoch Duration: 64.07532930374146
2018-05-20 01:34:58.221997 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #431 | Started Training: True
2018-05-20 01:36:01.142603 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #432 | Epoch Duration: 62.92047905921936
2018-05-20 01:36:01.142860 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #432 | Started Training: True
2018-05-20 01:37:04.710570 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #433 | Epoch Duration: 63.567538261413574
2018-05-20 01:37:04.710813 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #433 | Started Training: True
2018-05-20 01:38:07.332973 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #434 | Epoch Duration: 62.62198495864868
2018-05-20 01:38:07.333201 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #434 | Started Training: True
2018-05-20 01:39:10.603323 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #435 | Epoch Duration: 63.26993274688721
2018-05-20 01:39:10.603495 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #435 | Started Training: True
2018-05-20 01:40:13.498021 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #436 | Epoch Duration: 62.89441657066345
2018-05-20 01:40:13.498205 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #436 | Started Training: True
2018-05-20 01:41:16.419452 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #437 | Epoch Duration: 62.92112636566162
2018-05-20 01:41:16.419687 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #437 | Started Training: True
2018-05-20 01:42:20.583346 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #438 | Epoch Duration: 64.16347551345825
2018-05-20 01:42:20.583520 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #438 | Started Training: True
2018-05-20 01:43:23.517343 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #439 | Epoch Duration: 62.933690309524536
2018-05-20 01:43:23.517522 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #439 | Started Training: True
2018-05-20 01:45:04.520547 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #440 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.00037964
QF2 Loss                          0.000257055
Policy Loss                      -0.55732
Q1 Predictions Mean               0.552896
Q1 Predictions Std                0.211068
Q1 Predictions Max                0.69723
Q1 Predictions Min               -0.511883
Q2 Predictions Mean               0.552992
Q2 Predictions Std                0.208607
Q2 Predictions Max                0.697108
Q2 Predictions Min               -0.483452
Q Targets Mean                    0.552367
Q Targets Std                     0.208525
Q Targets Max                     0.704569
Q Targets Min                    -0.496998
Bellman Errors 1 Mean             0.00037964
Bellman Errors 1 Std              0.00269095
Bellman Errors 1 Max              0.0300531
Bellman Errors 1 Min              3.9318e-09
Bellman Errors 2 Mean             0.000257055
Bellman Errors 2 Std              0.00152138
Bellman Errors 2 Max              0.0162491
Bellman Errors 2 Min              1.13813e-09
Policy Action Mean               -0.136743
Policy Action Std                 0.988703
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00645387
Test Rewards Std                  0.00394067
Test Rewards Max                  0.0166773
Test Rewards Min                 -0.00517878
Test Returns Mean                 1.04501
Test Returns Std                  0.531245
Test Returns Max                  1.55006
Test Returns Min                  0.00993386
Test Actions Mean                -0.111489
Test Actions Std                  0.991133
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        12
Exploration Rewards Mean          0.00706816
Exploration Rewards Std           0.00414525
Exploration Rewards Max           0.0178443
Exploration Rewards Min          -0.00310787
Exploration Returns Mean          1.2063
Exploration Returns Std           0.401411
Exploration Returns Max           1.62021
Exploration Returns Min           0.0205484
Exploration Actions Mean         -0.125215
Exploration Actions Std           0.951925
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.04501
Number of train steps total  880987
Number of env steps total    882000
Number of rollouts total       5913
Train Time (s)                   38.3201
(Previous) Eval Time (s)          2.14401e-06
Sample Time (s)                  25.6719
Epoch Time (s)                   63.9921
Total Train Time (s)         108127
Epoch                           440
---------------------------  ----------------
2018-05-20 02:18:12.594860 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #440 | Epoch Duration: 2089.0772318840027
2018-05-20 02:18:12.594983 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #440 | Started Training: True
2018-05-20 02:19:16.794926 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #441 | Epoch Duration: 64.19984102249146
2018-05-20 02:19:16.795087 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #441 | Started Training: True
2018-05-20 02:20:19.461232 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #442 | Epoch Duration: 62.66603469848633
2018-05-20 02:20:19.461417 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #442 | Started Training: True
2018-05-20 02:21:22.885139 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #443 | Epoch Duration: 63.42360329627991
2018-05-20 02:21:22.885405 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #443 | Started Training: True
2018-05-20 02:22:27.267672 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #444 | Epoch Duration: 64.38208818435669
2018-05-20 02:22:27.267901 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #444 | Started Training: True
2018-05-20 02:23:31.798794 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #445 | Epoch Duration: 64.53072953224182
2018-05-20 02:23:31.799023 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #445 | Started Training: True
2018-05-20 02:24:36.179080 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #446 | Epoch Duration: 64.3798885345459
2018-05-20 02:24:36.179250 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #446 | Started Training: True
2018-05-20 02:25:39.222101 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #447 | Epoch Duration: 63.04273176193237
2018-05-20 02:25:39.222277 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #447 | Started Training: True
2018-05-20 02:26:43.000406 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #448 | Epoch Duration: 63.7779757976532
2018-05-20 02:26:43.000641 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #448 | Started Training: True
2018-05-20 02:27:46.111418 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #449 | Epoch Duration: 63.11061096191406
2018-05-20 02:27:46.111594 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #449 | Started Training: True
2018-05-20 02:29:27.742626 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #450 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.0148542
QF2 Loss                          0.0152404
Policy Loss                      -0.526077
Q1 Predictions Mean               0.518587
Q1 Predictions Std                0.290634
Q1 Predictions Max                0.699232
Q1 Predictions Min               -0.699782
Q2 Predictions Mean               0.520988
Q2 Predictions Std                0.288489
Q2 Predictions Max                0.699521
Q2 Predictions Min               -0.70061
Q Targets Mean                    0.510267
Q Targets Std                     0.31245
Q Targets Max                     0.704937
Q Targets Min                    -0.804169
Bellman Errors 1 Mean             0.0148542
Bellman Errors 1 Std              0.163315
Bellman Errors 1 Max              1.85525
Bellman Errors 1 Min              1.5463e-10
Bellman Errors 2 Mean             0.0152404
Bellman Errors 2 Std              0.16521
Bellman Errors 2 Max              1.87679
Bellman Errors 2 Min              5.8846e-09
Policy Action Mean               -0.105505
Policy Action Std                 0.991056
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00817198
Test Rewards Std                  0.00576856
Test Rewards Max                  0.0258778
Test Rewards Min                 -0.000642435
Test Returns Mean                 1.20657
Test Returns Std                  0.219394
Test Returns Max                  1.83201
Test Returns Min                  0.761133
Test Actions Mean                -0.0899178
Test Actions Std                  0.994348
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        11
Exploration Rewards Mean          0.00717999
Exploration Rewards Std           0.0046506
Exploration Rewards Max           0.0226027
Exploration Rewards Min          -0.00248082
Exploration Returns Mean          1.36681
Exploration Returns Std           0.448316
Exploration Returns Max           1.81412
Exploration Returns Min           0.0605231
Exploration Actions Mean          0.0110563
Exploration Actions Std           0.959665
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.20657
Number of train steps total  900987
Number of env steps total    902000
Number of rollouts total       6024
Train Time (s)                   36.5774
(Previous) Eval Time (s)          2.25901e-06
Sample Time (s)                  27.4481
Epoch Time (s)                   64.0255
Total Train Time (s)         110588
Epoch                           450
---------------------------  ----------------
2018-05-20 02:59:13.462554 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #450 | Epoch Duration: 1887.35085439682
2018-05-20 02:59:13.462678 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #450 | Started Training: True
2018-05-20 03:00:17.576085 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #451 | Epoch Duration: 64.11328935623169
2018-05-20 03:00:17.576250 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #451 | Started Training: True
2018-05-20 03:01:22.931493 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #452 | Epoch Duration: 65.35509824752808
2018-05-20 03:01:22.931732 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #452 | Started Training: True
2018-05-20 03:02:27.860721 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #453 | Epoch Duration: 64.92879223823547
2018-05-20 03:02:27.861478 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #453 | Started Training: True
2018-05-20 03:03:32.267255 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #454 | Epoch Duration: 64.40556478500366
2018-05-20 03:03:32.267425 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #454 | Started Training: True
2018-05-20 03:04:35.865406 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #455 | Epoch Duration: 63.59785771369934
2018-05-20 03:04:35.865563 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #455 | Started Training: True
2018-05-20 03:05:38.371700 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #456 | Epoch Duration: 62.50601506233215
2018-05-20 03:05:38.371918 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #456 | Started Training: True
2018-05-20 03:06:40.799115 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #457 | Epoch Duration: 62.42702913284302
2018-05-20 03:06:40.799308 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #457 | Started Training: True
2018-05-20 03:07:43.718253 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #458 | Epoch Duration: 62.91882681846619
2018-05-20 03:07:43.718416 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #458 | Started Training: True
2018-05-20 03:08:47.826762 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #459 | Epoch Duration: 64.10823583602905
2018-05-20 03:08:47.826950 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #459 | Started Training: True
2018-05-20 03:10:30.572938 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #460 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000261772
QF2 Loss                          0.000323919
Policy Loss                      -0.466057
Q1 Predictions Mean               0.461177
Q1 Predictions Std                0.304455
Q1 Predictions Max                0.696332
Q1 Predictions Min               -0.623478
Q2 Predictions Mean               0.465767
Q2 Predictions Std                0.300482
Q2 Predictions Max                0.697201
Q2 Predictions Min               -0.612397
Q Targets Mean                    0.461524
Q Targets Std                     0.309302
Q Targets Max                     0.7028
Q Targets Min                    -0.674995
Bellman Errors 1 Mean             0.000261772
Bellman Errors 1 Std              0.00113839
Bellman Errors 1 Max              0.0117372
Bellman Errors 1 Min              6.47763e-10
Bellman Errors 2 Mean             0.000323918
Bellman Errors 2 Std              0.0012169
Bellman Errors 2 Max              0.00831685
Bellman Errors 2 Min              2.12835e-09
Policy Action Mean               -0.0644576
Policy Action Std                 0.997004
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00511311
Test Rewards Std                  0.00495415
Test Rewards Max                  0.0244173
Test Rewards Min                 -0.00874267
Test Returns Mean                 1.05177
Test Returns Std                  0.597109
Test Returns Max                  1.91321
Test Returns Min                 -0.123861
Test Actions Mean                -0.0220148
Test Actions Std                  0.997473
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        12
Exploration Rewards Mean          0.00566573
Exploration Rewards Std           0.00568189
Exploration Rewards Max           0.0262381
Exploration Rewards Min          -0.0106475
Exploration Returns Mean          1.08924
Exploration Returns Std           0.465769
Exploration Returns Max           1.51374
Exploration Returns Min          -0.0355305
Exploration Actions Mean         -0.0277477
Exploration Actions Std           0.95971
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.05177
Number of train steps total  920987
Number of env steps total    922000
Number of rollouts total       6134
Train Time (s)                   37.1132
(Previous) Eval Time (s)          1.965e-06
Sample Time (s)                  27.3808
Epoch Time (s)                   64.494
Total Train Time (s)         113337
Epoch                           460
---------------------------  ----------------
2018-05-20 03:45:03.213631 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #460 | Epoch Duration: 2175.3865654468536
2018-05-20 03:45:03.213753 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #460 | Started Training: True
2018-05-20 03:46:07.601890 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #461 | Epoch Duration: 64.38802933692932
2018-05-20 03:46:07.602057 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #461 | Started Training: True
2018-05-20 03:47:11.073716 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #462 | Epoch Duration: 63.47152829170227
2018-05-20 03:47:11.073897 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #462 | Started Training: True
2018-05-20 03:48:15.640256 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #463 | Epoch Duration: 64.56623315811157
2018-05-20 03:48:15.640452 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #463 | Started Training: True
2018-05-20 03:49:20.156561 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #464 | Epoch Duration: 64.51597785949707
2018-05-20 03:49:20.156730 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #464 | Started Training: True
2018-05-20 03:50:25.731990 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #465 | Epoch Duration: 65.5751440525055
2018-05-20 03:50:25.732155 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #465 | Started Training: True
2018-05-20 03:51:29.180363 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #466 | Epoch Duration: 63.4480984210968
2018-05-20 03:51:29.180567 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #466 | Started Training: True
2018-05-20 03:52:32.564599 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #467 | Epoch Duration: 63.38389229774475
2018-05-20 03:52:32.564825 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #467 | Started Training: True
2018-05-20 03:53:35.293992 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #468 | Epoch Duration: 62.72897434234619
2018-05-20 03:53:35.294170 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #468 | Started Training: True
2018-05-20 03:54:36.723192 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #469 | Epoch Duration: 61.428903341293335
2018-05-20 03:54:36.723357 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #469 | Started Training: True
2018-05-20 03:56:18.540536 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #470 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000325956
QF2 Loss                          0.000360862
Policy Loss                      -0.520891
Q1 Predictions Mean               0.517516
Q1 Predictions Std                0.251454
Q1 Predictions Max                0.690797
Q1 Predictions Min               -0.570917
Q2 Predictions Mean               0.517054
Q2 Predictions Std                0.251622
Q2 Predictions Max                0.691242
Q2 Predictions Min               -0.539538
Q Targets Mean                    0.517859
Q Targets Std                     0.25415
Q Targets Max                     0.697105
Q Targets Min                    -0.542144
Bellman Errors 1 Mean             0.000325956
Bellman Errors 1 Std              0.00217791
Bellman Errors 1 Max              0.0238796
Bellman Errors 1 Min              1.54112e-09
Bellman Errors 2 Mean             0.000360862
Bellman Errors 2 Std              0.00215728
Bellman Errors 2 Max              0.0212759
Bellman Errors 2 Min              9.60654e-10
Policy Action Mean               -0.0406501
Policy Action Std                 0.997373
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.0066788
Test Rewards Std                  0.00420475
Test Rewards Max                  0.0181122
Test Rewards Min                 -0.00357992
Test Returns Mean                 1.18695
Test Returns Std                  0.477917
Test Returns Max                  1.63144
Test Returns Min                  0.0729563
Test Actions Mean                -0.0230167
Test Actions Std                  0.996914
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        14
Exploration Rewards Mean          0.00803072
Exploration Rewards Std           0.00570111
Exploration Rewards Max           0.0253997
Exploration Rewards Min          -0.00159616
Exploration Returns Mean          1.27115
Exploration Returns Std           0.134916
Exploration Returns Max           1.46256
Exploration Returns Min           1.01835
Exploration Actions Mean         -0.0326365
Exploration Actions Std           0.960701
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.18695
Number of train steps total  940987
Number of env steps total    942000
Number of rollouts total       6236
Train Time (s)                   36.417
(Previous) Eval Time (s)          1.93602e-06
Sample Time (s)                  26.051
Epoch Time (s)                   62.468
Total Train Time (s)         116029
Epoch                           470
---------------------------  ----------------
2018-05-20 04:29:55.821748 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #470 | Epoch Duration: 2119.0982863903046
2018-05-20 04:29:55.821870 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #470 | Started Training: True
2018-05-20 04:31:00.883926 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #471 | Epoch Duration: 65.06195378303528
2018-05-20 04:31:00.884105 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #471 | Started Training: True
2018-05-20 04:32:04.171296 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #472 | Epoch Duration: 63.287081241607666
2018-05-20 04:32:04.171466 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #472 | Started Training: True
2018-05-20 04:33:09.223964 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #473 | Epoch Duration: 65.05237865447998
2018-05-20 04:33:09.224194 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #473 | Started Training: True
2018-05-20 04:34:13.605057 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #474 | Epoch Duration: 64.38067436218262
2018-05-20 04:34:13.605219 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #474 | Started Training: True
2018-05-20 04:35:18.423016 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #475 | Epoch Duration: 64.81768369674683
2018-05-20 04:35:18.423196 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #475 | Started Training: True
2018-05-20 04:36:23.860514 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #476 | Epoch Duration: 65.43720817565918
2018-05-20 04:36:23.860699 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #476 | Started Training: True
2018-05-20 04:37:30.469886 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #477 | Epoch Duration: 66.60907888412476
2018-05-20 04:37:30.470070 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #477 | Started Training: True
2018-05-20 04:38:35.703489 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #478 | Epoch Duration: 65.23330330848694
2018-05-20 04:38:35.703733 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #478 | Started Training: True
2018-05-20 04:39:41.501725 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #479 | Epoch Duration: 65.79782748222351
2018-05-20 04:39:41.501902 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #479 | Started Training: True
2018-05-20 04:41:30.018559 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #480 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000201906
QF2 Loss                          0.000445892
Policy Loss                      -0.487974
Q1 Predictions Mean               0.480123
Q1 Predictions Std                0.271955
Q1 Predictions Max                0.678673
Q1 Predictions Min               -0.884812
Q2 Predictions Mean               0.478554
Q2 Predictions Std                0.276
Q2 Predictions Max                0.678776
Q2 Predictions Min               -0.917401
Q Targets Mean                    0.481651
Q Targets Std                     0.270094
Q Targets Max                     0.685752
Q Targets Min                    -0.874686
Bellman Errors 1 Mean             0.000201906
Bellman Errors 1 Std              0.000565779
Bellman Errors 1 Max              0.00407395
Bellman Errors 1 Min              6.09681e-11
Bellman Errors 2 Mean             0.000445892
Bellman Errors 2 Std              0.00228374
Bellman Errors 2 Max              0.0186369
Bellman Errors 2 Min              1.15833e-09
Policy Action Mean               -0.017576
Policy Action Std                 0.997648
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00618485
Test Rewards Std                  0.00467693
Test Rewards Max                  0.0196536
Test Rewards Min                 -0.00621741
Test Returns Mean                 0.969959
Test Returns Std                  0.612605
Test Returns Max                  1.63282
Test Returns Min                  0.0113292
Test Actions Mean                 0.00789711
Test Actions Std                  0.997783
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        11
Exploration Rewards Mean          0.00592765
Exploration Rewards Std           0.00486343
Exploration Rewards Max           0.0181679
Exploration Rewards Min          -0.00729684
Exploration Returns Mean          1.04003
Exploration Returns Std           0.476618
Exploration Returns Max           1.53507
Exploration Returns Min          -0.0882433
Exploration Actions Mean          0.0162078
Exploration Actions Std           0.958451
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     0.969959
Number of train steps total  960987
Number of env steps total    962000
Number of rollouts total       6339
Train Time (s)                   40.453
(Previous) Eval Time (s)          2.15499e-06
Sample Time (s)                  28.9715
Epoch Time (s)                   69.4245
Total Train Time (s)         118996
Epoch                           480
---------------------------  ----------------
2018-05-20 05:19:23.251087 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #480 | Epoch Duration: 2381.749078273773
2018-05-20 05:19:23.251214 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #480 | Started Training: True
2018-05-20 05:20:30.206416 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #481 | Epoch Duration: 66.95508170127869
2018-05-20 05:20:30.206649 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #481 | Started Training: True
2018-05-20 05:21:38.505109 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #482 | Epoch Duration: 68.29829716682434
2018-05-20 05:21:38.505285 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #482 | Started Training: True
2018-05-20 05:22:45.599545 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #483 | Epoch Duration: 67.09415197372437
2018-05-20 05:22:45.599732 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #483 | Started Training: True
2018-05-20 05:23:51.309456 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #484 | Epoch Duration: 65.70960307121277
2018-05-20 05:23:51.309630 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #484 | Started Training: True
2018-05-20 05:24:54.668956 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #485 | Epoch Duration: 63.35920977592468
2018-05-20 05:24:54.669121 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #485 | Started Training: True
2018-05-20 05:25:56.882495 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #486 | Epoch Duration: 62.21325421333313
2018-05-20 05:25:56.882745 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #486 | Started Training: True
2018-05-20 05:26:59.713347 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #487 | Epoch Duration: 62.83041834831238
2018-05-20 05:26:59.713585 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #487 | Started Training: True
2018-05-20 05:28:02.001023 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #488 | Epoch Duration: 62.28726410865784
2018-05-20 05:28:02.001182 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #488 | Started Training: True
2018-05-20 05:29:09.882054 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #489 | Epoch Duration: 67.88075280189514
2018-05-20 05:29:09.882284 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #489 | Started Training: True
2018-05-20 05:30:57.795627 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #490 | Collecting samples for evaluation
---------------------------  ----------------
QF1 Loss                          0.000286955
QF2 Loss                          0.000274019
Policy Loss                      -0.524222
Q1 Predictions Mean               0.516115
Q1 Predictions Std                0.232533
Q1 Predictions Max                0.675529
Q1 Predictions Min               -0.578264
Q2 Predictions Mean               0.511292
Q2 Predictions Std                0.232685
Q2 Predictions Max                0.673965
Q2 Predictions Min               -0.586016
Q Targets Mean                    0.516382
Q Targets Std                     0.224954
Q Targets Max                     0.680271
Q Targets Min                    -0.529532
Bellman Errors 1 Mean             0.000286955
Bellman Errors 1 Std              0.00126007
Bellman Errors 1 Max              0.0113566
Bellman Errors 1 Min              2.41221e-09
Bellman Errors 2 Mean             0.000274019
Bellman Errors 2 Std              0.00119015
Bellman Errors 2 Max              0.0120117
Bellman Errors 2 Min              8.53007e-12
Policy Action Mean               -0.0260905
Policy Action Std                 0.998214
Policy Action Max                 1
Policy Action Min                -1
Test Rewards Mean                 0.00745193
Test Rewards Std                  0.00551506
Test Rewards Max                  0.0235075
Test Rewards Min                 -0.00696813
Test Returns Mean                 1.13845
Test Returns Std                  0.300576
Test Returns Max                  1.45655
Test Returns Min                  0.0548765
Test Actions Mean                -0.104155
Test Actions Std                  0.992169
Test Actions Max                  1
Test Actions Min                 -1
Num Paths                        15
Exploration Rewards Mean          0.00545922
Exploration Rewards Std           0.00605161
Exploration Rewards Max           0.0234009
Exploration Rewards Min          -0.00896025
Exploration Returns Mean          0.705331
Exploration Returns Std           0.585703
Exploration Returns Max           1.64218
Exploration Returns Min           0.0319091
Exploration Actions Mean         -0.093682
Exploration Actions Std           0.955802
Exploration Actions Max           1
Exploration Actions Min          -1
AverageReturn                     1.13845
Number of train steps total  980987
Number of env steps total    982000
Number of rollouts total       6464
Train Time (s)                   39.1608
(Previous) Eval Time (s)          3.44301e-06
Sample Time (s)                  29.4787
Epoch Time (s)                   68.6395
Total Train Time (s)         121587
Epoch                           490
---------------------------  ----------------
2018-05-20 06:02:35.012422 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #490 | Epoch Duration: 2005.1299862861633
2018-05-20 06:02:35.012546 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #490 | Started Training: True
2018-05-20 06:03:39.336870 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #491 | Epoch Duration: 64.3242118358612
2018-05-20 06:03:39.337114 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #491 | Started Training: True
2018-05-20 06:04:42.623283 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #492 | Epoch Duration: 63.286006927490234
2018-05-20 06:04:42.623454 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #492 | Started Training: True
2018-05-20 06:05:49.347271 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #493 | Epoch Duration: 66.72368144989014
2018-05-20 06:05:49.347436 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #493 | Started Training: True
2018-05-20 06:06:53.180029 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #494 | Epoch Duration: 63.832475423812866
2018-05-20 06:06:53.180276 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #494 | Started Training: True
2018-05-20 06:07:58.112384 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #495 | Epoch Duration: 64.93190741539001
2018-05-20 06:07:58.112558 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #495 | Started Training: True
2018-05-20 06:09:01.349664 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #496 | Epoch Duration: 63.23698925971985
2018-05-20 06:09:01.349841 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #496 | Started Training: True
2018-05-20 06:10:04.692082 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #497 | Epoch Duration: 63.34212350845337
2018-05-20 06:10:04.692249 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #497 | Started Training: True
2018-05-20 06:11:07.840314 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #498 | Epoch Duration: 63.147934913635254
2018-05-20 06:11:07.840554 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #498 | Started Training: True
2018-05-20 06:12:12.003853 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #499 | Epoch Duration: 64.16312909126282
2018-05-20 06:12:12.004025 UTC | [name-of-td3-experiment_2018_05_18_20_15_40_0000--s-0] Iteration #499 | Started Training: True
